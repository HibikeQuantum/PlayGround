diff --git a/Bear/CSS.md b/Bear/CSS.md
new file mode 100644
index 0000000..652765d
--- /dev/null
+++ b/Bear/CSS.md
@@ -0,0 +1,5 @@
+# CSS
+
+#Devops/language
+
+* 부모의 CSS 속성이 없으면 자식에 % 밸류가 동작하지 않는다. 기준이 부모다.
\ No newline at end of file
diff --git a/Bear/Data.md b/Bear/Data.md
new file mode 100644
index 0000000..256e460
--- /dev/null
+++ b/Bear/Data.md
@@ -0,0 +1,20 @@
+# Data
+
+#Devops/data
+
+
+---
+
+## Data Structure  session (2019)
+
+**summary**
+
+* 알고리즘을 생각할때 첫 생각은 자료구조로 시작한다.
+
+* 미로찾기에 stack을 쓴다. 막히면 pop 하다보면 성공한 방법만 나온다.
+
+* 자바스크립트 array는 linkedList로 만들어짐
+
+* 결국 자료구조는 알고리즘을 구성하는 방법이자 데이터의 형태이기도 하다.
+
+* Graph를 사용하면 엣지의 가중치에 따른 요금차이 구현이 가능.
\ No newline at end of file
diff --git a/Bear/Terraform.md b/Bear/Terraform.md
new file mode 100644
index 0000000..4aa7db5
--- /dev/null
+++ b/Bear/Terraform.md
@@ -0,0 +1,29 @@
+# Terraform
+
+#Devops/language
+
+### tfvar 문제
+
+```
+
+*.tfvars // 이렇게 선언하고
+
+  compute_platform = "Server"
+
+
+
+mina.tf // 이렇게 사용. 결국 var를 정의하는 여러 방법 중 하나
+
+  compute_platform = local.compute_platform
+
+
+
+```
+
+  
+
+
+
+
+---
+
diff --git a/Bear/last_commit_message.txt b/Bear/last_commit_message.txt
index 35f3dd5..9391927 100644
--- a/Bear/last_commit_message.txt
+++ b/Bear/last_commit_message.txt
@@ -1 +1 @@
-Wed Jul 27 10:56:15 KST 2022 Update Bear notes content automatically by BEAR_AUTO_PUBLISH App
+Wed Jul 27 12:00:24 KST 2022 Update Bear notes content automatically by BEAR_AUTO_PUBLISH App
diff --git "a/Bear/\342\230\204\357\270\217Trouble Shotting BOX.md" "b/Bear/\342\230\204\357\270\217Trouble Shotting BOX.md"
new file mode 100644
index 0000000..e3a6cc9
--- /dev/null
+++ "b/Bear/\342\230\204\357\270\217Trouble Shotting BOX.md"	
@@ -0,0 +1,87 @@
+# ☄️Trouble Shotting BOX 
+
+배경: path('timeinput/', views.time_input , name="timeinput")
+
+해결: 자꾸 timeinput args를 못찾아서 헤맸는데 timeinput/<int:shop> 이라 되어 있어서 못찾은거임. 프레임워크 사용규칙을 몰라서 생긴일.
+
+
+
+문제: RDS에 접근 못하는데
+
+해결: SG가 이상하게 설정되어 있었음. 0.0.0.0/0 설정을 거부하는 상태. 지우고 다시 하니까 됨. (버그)
+
+
+
+문제: 파이프 깨짐 에러 발생
+
+해결: pipe = socket 고로 broken pipe error = "클라이언트가 연결을 시도하려 했을 때 서버의 소켓이 닫혀있어서 연결을 할 수 없어서 뜨는 에러" 
+
+이 사람의 경우 테이블 수정에 대해 migration이 되지 않은 상태. 디버그 모드를 끄게 되면 잘 처리할 수 없음을 기억!
+
+
+
+배경: Bastion 호스트 구현 실습
+
+문제: 이상하게 통신이 안됨
+
+해결: inbound NACL에서 외부 source를 차단하고 있었기에 yum 요청에 대한 응답을 막고 있었음.
+
+
+
+0514
+
+문제: Nginx BAD_GATEWAY 문제, nginx 모듈 못찾는 다고함.. 
+
+해결: conf 파일에서 경로를 변수로 넣으니까 되네.
+
+개선: 무조건 따라하기 전에 무엇을 하는지 정확히 알아야 한다. 특히 Nginx처럼 문법이 까다로운놈은. 
+
+ 
+
+0515
+
+문제: 경로를 변수로 넣으면 nginx -t 는 넘어가는데 실제 req가 오면 에러가 발생한다. 결국 제대로 넣는 수 밖에 없다! 위에서 한건 임시 방편 
+
+해결: http:*/unix:*
+
+개선: 코드는 무조건 확실하게 확인!! 잘 안보였음 : 콜론이 빠져서 안된거였음.
+
+
+
+문제: insominia 에서 보내면 broken pipe 에러 발생
+
+해결: preference 설정에서 응답대기시간 연장
+
+개선: 단어의 맥락을 이해는 디버깅의 시작
+
+
+
+문제: 'utf-8' codec can't decode byte 0xb0 in position 67: invalid start byte
+
+해결: IDE에서 해당 파일의 인코딩을 UTF-8로 변경
+
+개선: 사람눈엔 같아보여도 컴퓨터 눈엔 다른거다.
+
+
+
+문제: 사용하고자 하는 변수에 값이 들어가지 않음
+
+해결: 코드 실행순서 변경
+
+os.environ.setdefault("DJANGO***SETTINGS***MODULE", 'order.settings') 
+
+→ 환경변수를 컨트롤 하는 패키지와 코드들이 순서대로 있는건 기본
+
+            {'input': "- Not Strike~”, 'expected': “~~ Not Strike-"}
+
+0607 - 느닷없는 정보가 결과 리포트 이메일에 들어가있어 문제가 됨.
+
+해결: 내가 잘 파악하지 못한 배열에 '-'으로 저장하던 로직에 메시지는 다다익선이라고 'info_msg··· '을 적음. 그걸 참고하는 다른 로직에서 가지고가 정보를 보여줘서 평소와 다르니 에러인줄 파악함. 실제 비즈니스 로직이었으면 심각한 문제였다. 로직을 고칠때 배열이 어디서 쓰이는지 다 알고 쓰자.
+
+
+
+0705 - 함수가 실행안되고 있었는데 레겍스가 왜 패턴을 못잡을까 고민하고 있었다. 기본을 생각하자.
+
+
+
+#Devops/T-Shotting
\ No newline at end of file
diff --git "a/Bear/\342\233\223IT base Tool.md" "b/Bear/\342\233\223IT base Tool.md"
new file mode 100644
index 0000000..e4fa750
--- /dev/null
+++ "b/Bear/\342\233\223IT base Tool.md"	
@@ -0,0 +1,292 @@
+# ⛓IT base Tool
+
+## Git 의 내부구조
+
+```git
+
+	.Git 
+
+		/Obejct	(실데이터)
+
+		/Ref		(브랜치 및 최신 커밋값)
+
+		/logs
+
+		HEAD		(현재 로컬저장소가 가르키는 커밋)
+
+```
+
+
+
+## 슬로기운 Git 탐구생활
+
+* 일반
+
+`git rm -r —cached ` -> ‼️ 뭐하는거더라
+
+`git stash` 명령어를 실행하면 현재의 변경사항이 저장되고 워킹디렉토리는 HEAD 상태로 돌아가게 된다. 그리고 다시 스태시된걸 엎어서 작업으로 돌아오는 방식으로 브랜치간 이동을 자유롭게 한다. 
+
+
+
+* git branch 옵션
+
+```git branch -b toy1
+
+git checkout master
+
+git pull —rebase upstream master     // 업데이트된걸 다시 덮어쓰기
+
+````
+
+
+
+* git rest 옵션
+
+```
+
+git reset —soft 스테이징된걸 끄집어 내린다.  헤드^를 붙이면 커밋롤백 + 스테이징상태 => 잘못 커밋했을때 다시 하기좋겠다.  + 스테이징된거 끌어 내릴떄.
+
+git reset —mixed [default] 하면 스테이징에서 끌어내린다. 헤드를 붙이면 커밋롤백 + 언스테이지 => 커밋 조차도 잘못 했을때 스테이징에서 끌어내릴떄.
+
+git reset —hard 하면 스테이지 끌어내리고 파일도 바구고 다
+
+```
+
+
+
+### 오브젝트 분석
+
+`git count-objects -vH`
+
+
+
+## Tmux
+
+* 백그라운드에서 여러가지 세션을 유지하고 접근하고 동시에 볼 수 있게 해줌.
+
+
+
+## Gitlab CI 워크숍 자료
+
+* [https:*/workshop.infograb.io/gitlab~~ci/00***workshop***info/](https://workshop.infograb.io/gitlab~~ci*00***workshop***info/) 
+
+* SPRING 코드 따라서 플로우를 따라해보기 좋음.
+
+
+
+## GitHub Actions
+
+* Market place가 있는걸 뺴면, 빌트인 템플릿이 없고
+
+* CICD 를 하기 위해선 추가적인 조치가 필요하고 설정도 다 해줘야 한다. CI가 코드를 기준으로 자동으로 환경을 설정을 해주는것과 많은 차이가 있다.
+
+* 콘테이너 등록이 CICD에 통합되어 있지 않다. Gitlab은 통합됨.
+
+
+
+## Circle CI
+
+* 빌드/배포를 실행하기 위해 리소스를 대여해주는 방식으로 수익을 얻는다.
+
+* 잡플로우는 텍스트 형식으로 컨트롤할 수 있고 웹사이트에서 제공하는 메뉴에서 조작한다.
+
+* 초기에 어울리는 서비스인듯
+
+
+
+## jetty
+
+* 제티는 자바 HTTP (웹) 서버이자 자바 서블릿 컨테이너이다. 웹 서버가 보통 문서를 사람들에게 제공하는 것과 관련된 반면, 제티는 대규모 소프트웨어 프레임워크에서 기계와 기계의 커뮤니케이션에 사용된다.
+
+
+
+## HSQLDB (Hyper SQL Database, 하이퍼 SQL 데이터베이스)
+
+* 자바로 작성된 관계형 데이터베이스 관리 시스템.  인메모리, 파일기반 둘다 지원
+
+사용예: 오픈오피스 베이스, 리브레오피스 베이스, 스탠드얼론 롤러 데모, Jitsi VoIP 
+
+
+
+## in SVN, Replace와 modify의 차이
+
+* Item has been replaced in your working copy. This means the file was scheduled  for deletion, and then a new file with the same name was scheduled for addition 
+
+in its place.
+
+
+
+* 지라 CLI
+
+	* API 문서  [https:*/bobswift.atlassian.net/wiki/spaces/JCLI/pages/1059397481/getIssueList](https://bobswift.atlassian.net/wiki/spaces/JCLI/pages/1059397481*getIssueList) 
+
+	* - -outputFormat
+
+		* 1 - standard fields, 2 - standard fields plus custom fields, 3 - standard fields plus security fields, 4 - standard fields plus security fields and custom fields, 101 - simple text list of issue keys only, not CSV for this special case, 102 - key and summary fields, 998 - all fields including link information but excluding custom fields, 999 - all fields including link information and custom fields
+
+		* 포맷마다 주는 정보가 다르다.
+
+
+
+
+
+## 톰캣은 java코드를 실행하는 순수 java http 웹 서버
+
+* 그 톰캣의 코어 컴포넌트가 카탈리나 
+
+* 재스퍼는 JSP전담
+
+
+
+## Catalina
+
+* 톰캣을 쓰는 어플리케이션들은 카탈리나.sh 를 자신의 쉘로 감싸서 서비스한다.
+
+
+
+## gradlew
+
+유닉스용 wrapper 실행 스크립트이다. 컴파일, 빌드 등을 하는 경우 사용한다. ./gradlew {task} 형태로 실행한다.
+
+Graddle은 사용자 지정 task도 지원한다.
+
+
+
+* /builld.gradle 이 뼈대, 모듈별로 .gradle을 가질 수 있다.
+
+
+
+
+
+# Virtual OS
+
+* Container 에서 실행되는 명령어는 Host-OS의 스케쥴에서 실행됨
+
+* Hypervisor : 하드웨어 스케쥴링을 커널대신 해주는 도구
+
+* VM이란 무엇인가? 왜 도커가 나와도 VM은 쓰는가?
+
+: 머신이 죽거나 확장켜야할 때 컨테이너를 관리해줄 기술이 필요하다.
+
+* 도커 오버헤드 0% ~ 5%
+
+* VM은 OS를 구분되게 사용하기 위해서 쓰이는것. 커널을 공유하지 않아서 보안성이 높음.
+
+* 도커는 커널을 공유하기 때문에 Docker 에 윈도우를 돌리게 되면 제약이 걸린다. (OS커널에 대한 별도 작업 필요)
+
+
+
+## ORACLE ALTER LOG
+
+* 시스템, 에러 메시지가 남는 로그
+
+
+
+## 프로메테우스
+
+* 쿠버네티스에 특화
+
+* 각 서버에 대해 풀링 방식으로 데이터를 저장
+
+
+
+## Grafana
+
+* 쌓인 데이터를 시각화함..
+
+
+
+## Wide column DB
+
+* 로우마다 다른 컬럼을 가질 수 있음
+
+* 한마디로 스킴리스
+
+* join이 안되고 transaction안됨
+
+* 확장성과 빠른 성능 (짱인데)
+
+* 카산드라, HBAS
+
+* 로깅에 최적화
+
+
+
+## Doc DB
+
+* Wide column 장점
+
+* 쓰기가 까다롭고, join가능
+
+* 대부분의 app에 범용
+
+
+
+## Graph
+
+* SQL + NoSQL 장점
+
+* Graph QL은 클라이언트측에서 자유롭게 데이터를 다루게 하기 위한 뭔가.. 편의 위주의 디비인듯
+
+
+
+## Search
+
+* 엘라스틱서치 장문의 스트링 검색에 최적화
+
+* update에 압도적으로 좋지않음
+
+
+
+# CICD
+
+## Jenkins
+
+* 젠킨스가 별 하찮은 이유로 잡이 실패하는 경우에 대한 설명
+
+"Jenkins is executing shell build steps using *bin*sh -xe by default. -x means to print every command executed. -e means to exit with failure if any of the commands in the script failed." 그렇기 때문에 만약 에러를 무시하고 진행할 필요가 있다면 다음 처럼 에러 코드를 반환하지 않도록 처리하면 된다.
+
+```
+
+set +e
+
+your code
+
+set -e
+
+```
+
+
+
+
+
+# BUILD
+
+## Maven
+
+### sonar
+
+The SonarScanner for Maven is default scanner for Maven projects. The ability to execute the SonarQube analysis via a regular Maven goal makes it available anywhere Maven is available (developer build, CI server, etc.) ~~> 현재 OSS~~OM에선 코드인스펙트를 하고 보고서를 작성하는 용도로 사용중이다. 현재 프로젝트에서 사용중인 `pom.xml`을 보면 `<ruleset>.xml</>`을 지정해준다. 안에 보면 리턴하지 않는 함수, 선택지가 하나뿐인 case등에 대해 경고를 하는 룰이 지정되어있다.
+
+
+
+### Release vs Snapshot
+
+* RELEASE 최종 배포될 때 사용, Artifact의 수정이 거의 없을 때 사용한다. (로컬에 있으면 로컬에 것을 사용한다)
+
+* SNAPSHOT Artifact를 개발중에 다른곳에서도 자주 사용할 때 사용한다. Artifact의 수정이 빈번할 경우 사용한다. 왜냐하면 항상 원격레포지터리에서 받아온다. 
+
+* `mvn deploy`를 이용해 RemoteRepository 에 배포할때도 동작하는 특성이 다르다. Release는 시맨틱버전에 따라 생성되므로 동일 아티팩트를 덮어쓰기 하는 반면, Snapshot은 고유네임을 유지하도록 빌드번호가 붙으므로 항상 새로운 쓰기가 된다.
+
+
+
+### JAVA XML 파싱 (SAX parser 활용)
+
+
+
+
+---
+
+
+
+#Devops/tools
\ No newline at end of file
diff --git "a/Bear/\353\213\250\354\226\264.md" "b/Bear/\353\213\250\354\226\264.md"
new file mode 100644
index 0000000..8f7b28e
--- /dev/null
+++ "b/Bear/\353\213\250\354\226\264.md"
@@ -0,0 +1,5 @@
+# 단어
+
+부불망빈. Shirtsleeves to shirtsleeves 
+
+#blog
\ No newline at end of file
diff --git "a/Bear/\353\214\200\353\251\230\355\203\210 \352\263\265\352\262\251 \353\260\251\354\226\264\353\254\264\352\270\260.md" "b/Bear/\353\214\200\353\251\230\355\203\210 \352\263\265\352\262\251 \353\260\251\354\226\264\353\254\264\352\270\260.md"
new file mode 100644
index 0000000..dd66473
--- /dev/null
+++ "b/Bear/\353\214\200\353\251\230\355\203\210 \352\263\265\352\262\251 \353\260\251\354\226\264\353\254\264\352\270\260.md"	
@@ -0,0 +1,8 @@
+# 대멘탈 공격 방어무기
+
+#mind
+
+
+---
+
+“올바로 동작하지 않더라도 걱정말아라. 모든 것이 그랬다면, 넌 직업을 잃었을테니까. - 모셔의 법칙(Mosher’s Law)”
\ No newline at end of file
diff --git "a/Bear/\353\257\270\352\265\255\355\232\214\355\231\224 \354\230\201\354\226\264\353\254\270\353\262\225.md" "b/Bear/\353\257\270\352\265\255\355\232\214\355\231\224 \354\230\201\354\226\264\353\254\270\353\262\225.md"
new file mode 100644
index 0000000..302990f
--- /dev/null
+++ "b/Bear/\353\257\270\352\265\255\355\232\214\355\231\224 \354\230\201\354\226\264\353\254\270\353\262\225.md"	
@@ -0,0 +1,55 @@
+# 미국회화 영어문법
+
+#Book
+
+
+---
+
+## CH01 관사, 직감으로 해결 Articles
+
+* 가산 명사 앞에만 부정관사가 온다. 
+
+* 불가산 명사라도 갯수를 명확히 하기 위해선 부정관사를 쓴다.
+
+* 불가산명사는 복수형이 없다.
+
+* 셀 수 있음. 구체적 단위가 있음 -> 가산명사
+
+## CH02 Indefinite Articles
+
+개념적 추상적
+
+## CH03 ZERO ARTICLE 무관사
+
+* 개념적, 추상적
+
+## CH04 Abstract nouns 추상명* 개별성을 가질때 a, the를 쓴다.
+
+## CH05 집합명사 collective nouns
+
+* 보기드물게 집합명사를 복수를 쓰는 북미지방도 있다. 아니면 다 영국
+
+* 조직원들의 숫자가 많아도 조직은 하나
+
+* Birds of a feather flock together ≈ 유유상종
+
+* a ( ) 집합명사 단수동사
+
+## 전치사 Prepositions
+
+with, on, about
+
+* write가 어떤 방법으로 쓰이고 이런거랑 쓰면 이런뜻이고 이런걸 도움이 안된다. 전치사가 필요한 이유는 의미를 명확하게 하기 위해서다. 도구인지, 주제인지, 종이인지. 전치사가 동사의 뜻을 좌우함을 느껴.
+
+
+
+
+---
+
+## 학습이론
+
+Learning, Acquisition 은 다르다. 오로지 습득만이 자연스럽고 유창한 대화를 가능케 한다. 그 핵심은 meaningful interaction in the target language. (엔데버의 수련방법처럼) 연장이 손에 익으면 의식적 노력 없이도 자연스럽게 된다.
+
+
+---
+
diff --git "a/Bear/\353\263\200\355\231\224\355\225\230\353\212\224 \354\204\270\352\263\204\354\247\210\354\204\234.md" "b/Bear/\353\263\200\355\231\224\355\225\230\353\212\224 \354\204\270\352\263\204\354\247\210\354\204\234.md"
new file mode 100644
index 0000000..7e0b576
--- /dev/null
+++ "b/Bear/\353\263\200\355\231\224\355\225\230\353\212\224 \354\204\270\352\263\204\354\247\210\354\204\234.md"	
@@ -0,0 +1,542 @@
+# 변화하는 세계질서
+
+#Book
+
+
+
+* 한정된 상황에서는 한정된 가능성만 존재하기 때문에 1) 상황을 제대로 파악하고 2) 인과관계를 정확히 이해하고 있으면 다음 단계를 예측하고 현명한 판단을 할 수 있다. 
+
+* 부 = 구매력, 부의 창조 = 생산성 향산 ( 따라서 투자는 번영의 선행지표) 
+
+* 초기신흥국, 후기신흥국(소득과 생산성이 동시에 증가하는 시기), 최전성기( 중요한건 강대국이 되는 요인을 얼마나 유지하느냐), 초기쇠퇴국가(가난하지만 부자라고 생각한다)
+
+* 쇠퇴국가는 중앙은행이 돈을 찍기 시작하고 저금리를 유지하기 때문에 통화가치가 절하되고 자산의 수익률이 떨어진다.
+
+* 사회의 창의력이 혁신이 생산성을 좌우한다.
+
+* 귀족들이 세금 징수권에 저항하였고 이것이 최초의 의회가 된다. 결국 권력자들의 공간..
+
+* 부와 권력을 소유하는 계층은 계속 바뀌지만 그 변화의 과정은 오늘날도 크게 다르지 않다. 처음엔 협상을 통해 평화롭게 하다가 내란과 혁명이 동반된다. 
+
+* 국가 내부의 질서는 권력과 부를 위한 투쟁을 통해 미래에도 계속 변화한다. 따라서 부와 권력의 역학 관계를 파악하는 것은 중요하다. (AI와 정보기술 개발자)
+
+* 전통적인 좌파는 탐욕스런 자본가보다 교사, 소방관, 육체, 노동자들이 더 사회에 공헌하고 있다고 생각한다.
+
+* 우파는 수준 높은 공교육이 사회의 생산을 높히는데 도움이 되는데도 그걸 중요하게 생각하지 않는다.
+
+* 저자의 정치관. “정책 입안자들에게 가장 중요한 과제는 평등과 안전을 해치지 않고 자본주의에 기반한 경제 체재를 구현해서 생산성과 생활 수준을 향상시키는것” 
+
+* 부채는 소유권에 우선한다.
+
+* 세상에 존재하는 통화와 신용에는 딱히 정해진 양이 없다. 만약 중앙은행이 돈을 퍼주고 상환의무를 없애버리게 되면 어떤일이 벌어질까. 코로나 때 벌어진 일들이 이것이다. 이런 행동의 피해자는 중앙은행외에 현금성 채권자산을 보유하고 있으며 구매력을 유지할 수익을 얻지 못한 이들이다.
+
+* 최악의 재무 상황에서 어디까지 버틸 수 있는지 계산해보라. (작은 개인부터 단체 국가까지)
+
+* 각국 정부가 찍어내는 돈이 모두 동일한 가치를 지니는건 아니다. 
+
+* 기축통화를 가질때는 우월적인 구매력을 가질 수 있지만 기축국의 지위를 잃게되면 타격이 매우 크다.
+
+* 돈은 교환의 매개수단, 부의 저장 수단(부의 취득과 소비 사이의 과정)
+
+* 대부분의 통화와 신용(요즘 정부가 발행하는 화폐)는 자체로는 가치가 없다. … 효율적인 자원 배분과 생산성을 향상시키는 것에서 이익이 있다. 문제는 주기적으로 무너지는 점.
+
+* 중앙 은행은 통화량과 신용의 공급을 조정하믕로서 금융과 재화 서비스에 대한 수요와 공급을 조정할 수 있다. 다만 완벽한 조정이 아니기에 교대로 발생하는 불황과 호황을 볼 수 있다. 
+
+* 통화의 신용과 수요보다 더 많은 공급이 이뤄지면 높은 인플레이션이 발생 이를 통화인플(Monetary Inflation)
+
+* 통화 인플레이션 +  재화서비스에 대한 수요가 약하고 자산매각이 발생이 동시에 일어나면 디플레이션(인플레이션형 불황) -> 일본의 상황
+
+* 재화의 가격과 재화의 가치는 혼동된다. 집값이 올라도 여전히 당신의 집은 같은 집이다.
+
+* 경제가 돌아가는 상황을 분석할때 중요한 것은 통화와 신용을 풀면 경기가 부양되지만, 다시 거두어들일 때는 경기가 침체된다는 것이다. 이런 이유로 통화, 신용, 경제 성장이 오르내리는 것이다. 
+
+**통화를 통한 강장제는 자산의 가격과 양을 주기적으로 오르락 내리락하게 만들고**‘단기’ 부채 사이클*의 상승과 하락 국면은 8년에 걸처 일어난다.
+
+* 이런 사이클이 영원하지는 않다. 장기 부채사이클은 50-75년에 걸쳐 진행된다. 중앙은행이 가진 강장제가 병에 꽉 차있을 때 시작한다. (과도한 부채가 구조정되어) 이때가 여유가 있단거고 강장제가 다 떨어지면 사이클이 끝난다. 즉 실물경제의 성장을 견인할 통화와 신용을 창출할 능력을 상실할 때 끝난다는 말이다.  
+
+* 현재 진행중인 장기부채 사이클은 1945년 브레턴우즈에서 시작되었다. 
+
+**신용의 창출이 실제 경제 활동의 증가보다 더큰 폭으로 금융자산의 가격을 상승시키킬때, 채권자산을 가진 사람은 (임대인)은 다른 부의 저장수단으로 가고 싶어 한다.**현금과 채권자산으로 부를 인식할 수 없다는 인식이 만연하게 되면 장기 부채 사이클이 끝나고 통화 체제의 구조조정이 다시 시작된다.*
+
+* 장기부채 사이클
+
+	1. 부채가 없거나 저고, 화폐는 경화
+
+	2. 경화에 대한 불만으로 화폐출현
+
+	3. 부채의 증가 ( 실제 경화보다 더 많은 지불요구서가 유통), 이로인해 1) 채무조정 2) 중앙은행이 화폐를 찍어내야하는 상황이 된다. (돈이 희석되므로 화폐를 들고 있는 사람이 손실)
+
+	4. 부채위기, 채무불이행선언, 통화가치하락으로 통화량 증가, 경화와의 단절, 자국 화폐의 부채는 가치를 하락 시킬 순 있지만 외화 부채는 채무 불이행 밖에 없다.
+
+	5. 법정통화가 발행되고 통화가치가 하락. 신용을 창출하기 위해서가 아니라 직접 정부가 재화 서비스를 구매에 사용하기 위해 화폐를 발행. 2020년 4월 9일 화폐를 찎어내 부채를 구입 (부채의 화폐화)는 돈을 가진 사람에서 돈을 필요로 하는 사람에게 이전시키는 효과적인 조치. (이것이 항상 화폐를 찍어 가치를 떨어트리는 이유) 이를 리플레이션 Reflation. 장기 부채 사이클 초기에는 리플레이션이 경제에 양호한 효과를 준다 하지만 금리 인하를 할 여유가 없고 부채규모가 커지면 경기 약세를 동반한 인플레이션이 발생하게 된다. ··· 부채의 가치를 떨어트리는 것이 부채로 인한 부담을 줄이는 가장 간편한 방법. 그래서 현금은 안전 자산이 아니게 된다. 정치인들이 현실적으로 쓸 수 있는 이자 부담을 줄이는 방법은 세금이전과 화폐발행. 모노폴리에서 파산할때마다 은행이 더 많은 돈을 발행해 참가자에게 나눠주는것이다. 
+
+	6. **다시 경화로 복귀** 신용의 가치가 떨어지면 뱅크런이 시작된다. 경질자산 또는 다른 자산으로 갈아타거나 다른 나라로 이주. 그래서 정부는 경질자산, 외환투자, 해외 투자를 금지한다. 요약하면 장기부채 사이클 초반에는 채권자산이 유리, 후반부에는 수익이 높다해도 채권자산을 보유하는게 위험하다. 폭탄이니까. 구약에도 희년이라는게 있었다. 경화, 실물대비 미지급금이 최대치를 기록하면 위험한 상태이지만 사람들은 그걸 눈치채지 못한다. 돈을 빌려서 얻은 보상을 누려왔기 떄문이며 마지막 폭발로 부터 기억이 희미해져서 있기 때문이다. 
+
+	7. 마지막에 벌어지는 일들. 채무조정과 통화 체제의 조정은 몇 개월에서 몇 년동안 걸리며 파급효과는 장기간 지속된다. 이런 위기가 체제를 붕괴시키진 않는다. 
+
+* 대마불사의 믿음이 무너지면 안되니 지원한다. 
+
+
+
+# 4장 통화가치의 변화
+
+* 인플레이션보다 금리가 높다면 통화가치는 하락하지 않는다.
+
+* 1907 금융 공황은 00년대 신용 대출에 의존한 주식투자 붐으로 인한 은행과 증권사의 몰락에서 시작되었다. 중국 고무공장 거품도 1910년에 터졌다. 이런 상황에서도 어떤 나라의 통화가치는 지지되기도 했다. 아닌 케이스가 있다면 남북전쟁 전쟁자금을 대기 위한 달러 평가절하, 스페인 재정위기, 은화 하락으로 인한 일본의 통화 평가절하(1880년)
+
+* 1914년 세계대전으로 인한 부채로 경기가 침체되고 패전국의 통화가 붕괴되었다. 독일은 역사적 하이퍼 인플레이션
+
+* (미국이 채권국으로 막대한 이득을 거둔 상태에서) 1918년 새로운 질서가 시작되자 미국에선 광란의 경기호황이 시작되었다. 이는 부채증가, 자산버블, 빈부격차로 이어졌다. 그러나 33년에는 전 세계적으로 부채위기로 인해 경제가 위축되고 모든 나라가 통화를 대량발행하였다(평가절하) 이게 2차 세계대전으로 이어졌다.
+
+* 1950년 중반까지 달러와 스위스 프랑이 환율의 절반을 유지한 유일한 통화. 이후에는 꾸준히 금과 비교한 수익률은 감소하고 있고 (이는 실질금리 감소와 맥락을 같이 한다)
+
+* 현금실질수익률(소비자물가지수 대비)는 세계대전때 꺽이고 경제호황기(평가절하없이 경제가 잘 성장한) 에 점차 증가하는 모습을 보인다. 그리고 08년 기준으로 꺽였다.  -> 현금을 부의 저장수단으로 쓰는건 리스크가 크다 (절반은 떨어졌고 절반은 높았다, 특히 부채사이클 후반은 더 그렇다)
+
+* 돈을 찍어내는건 채권자들에겐 악재고 채무자들에겐 호재다. 채무경감 효과로 경제가 성장하고 채권자산이 절하되니 채무에서 벗어남다른 인플레이션 헤지자산을 살 수 있다. 다만 총채적으론 통화의 붕괴가 다가오니 좋진 않다. 
+
+****통화로부터의 탈출과, 그 통화의 평가절하는 일반적으로 심각한 부채문제가 생길 때 발생한다.* 큰 전쟁에 참가한 네덜란드, 영국, 미국 화폐의 평가절하 더욱이 패전했을땐 더 큰 충격이 벌어진다. 그렇게 서서히 기축통화의 지위를 잃는다.
+
+* 경제력과 군사력이 평가절하의 결과를 가름한다. 길더화는 영국과의 전쟁에서 패배함으로서 몰락했다. 영국은 서서히 그 과정이 진행되었다. 같은 기간 동안 달러 표시 자산보다 현저히 저조한 수익률을 보였다. 미국은 33년, 2000년 이후 평가절하가 있었지만 기축통화 지위를 유지하고 있다.
+
+****기축통화의 지위를 상실 하는 시점은, 신흥국에게 경제적-정치적 우위를 상실하며 국력이 쇠약해질때 그리고 중앙은행이 통화를 발행해 정부 부채를 인수하여 ‘부채를 화폐화’할때이다. 이렇게 되면 재정적자와 수지적자의 폭을 매꿀 수 없어 통화로부터의 탈출이 지속되고 통화 약세를 피할 수 없다.*
+
+# 내부 질서와 혼란의 빅 사이클
+
+* 국가 내에는 다른 사람고 어떻게 어울리냐는 규범- 질서가 있다. 이것에 따라 결과가 달라진다.
+
+* 내부질서 사이클의 6단계 (새질서 새지도자, 자원배분체계, 평화와 번영, 부채 과다 빈부 격차, 금융상황 악화, 혁명과 내전), 전체 사이클을 한 바퀴 도는데 100년이 걸린다. 이 안에서도 단기 부채 사이클과 좌파우파를 반복하는 정치적 사이클도 있다. 
+
+* 상대적 사이클, 절대적 사이클 (중국은 상대적 사이클에서 계속 쇠퇴하다가 최근에 급부상했다)
+
+* 위험신호비율로 본 역사적 내전 발생 가능성 미국은 60-80%, 내전 발발률은 17% (???)
+
+* 2단계
+
+	* 체제의 성공적인 안착을 위해서는 체제 덕분에 대부분의 사람들 특히 중산층이 번영을 누려야 한다. 이는 아리스토텔레스가 정치학에서 강조한 말이다.
+
+* 4단계
+
+	* 올바른 사고방식을 가진 잘 훈련된 지도자, 리콴유, 높은 교육 수준을 유지하고 규율을 잘 지키며 강인한 성격을 갖도록 정책을 유지.
+
+* 5단계
+
+	* 내전이 임박, 오늘날 많은 나라가 이렇다 (음… 어떻게 불평등으로 인해 내전이 일어날 수 있을까) (한편으론 많은 국가들이 한번에 이런 사이클에 들어갔다는것은 브레턴우즈 체제아래 많이 커플링된 상태라는 것을 뜻하기도 할듯).
+
+	* 혁명의 발발을 알려주는 가장 정확한 지표는 심각한 빈부 격차와 정부의 재정파탄
+
+	* 차입 한도와 구매력이 떨어지면 중앙은행 외엔 아무도 국채를 구입하려 하지 앟는다. 이때 세금인상 긴축 재정, 또는 통화발행으로 국채를 사들일때가 중요한 지점이다. ··· 이 통화를 가진 사람들은 세금을 더 내면서 공공서비스의 질이 떨어지는 것을 견딜 수가 없다. 
+
+	* 연방정부가 돈을 찍어내 부채를 상환하고 더 많은 지출을 감당할 동안 달러화 및 달러 표시 채권 자산을 가지고 있는 사람들의 구매력은 떨어진다.
+
+	* 정부 부채를 갚고 재정 적자를 해소하기 위해 더 많은 세금을 내야한다는 것을 알게 되면 부자들은 살던 곳을 떠나는 공동화 현상이 발생한다. ( Hollowing-out) 이것이 지금 미국의 주와 주 사이에 벌어지는일 (실리콘밸리에서 텍사스로)
+
+	* 가장 부유한 코네티컷의 고등학생 22%가 Disengaged, Disconnected 상태. 이런 사이클이 어떤 결과를 낳을지 예측도 못하고 있다.
+
+	* 성공의 필수 요소는 창출된 부채와 현금을 이용해 생산성을 높이고 적정 투자 수익률을 확보하는 것이다. 이것이 없다면 통화가치가 하락과 구매력 하락을 피할 수 없다.
+
+	* 향락적 소비 (부자는 자기 돈으로 원하는 곳에 소비할 수 있다고 생각한다, 빈자는 그렇지 못한데 이런 향락적 소비는 분노를 유발하는 것 외에도 생산성을 감소시킨다)
+
+	****사회가 어떤 곳에 돈을 쓰느냐는 중요하다. 생산성 수입의 증가를 낳는 투자 상품에 소비하면 사치품에 소비할 때보다 밝은 미래를 향해 전진한다.*
+
+	* 내부 질서 사이클의 초기에는 … 갈 수록 관료주의가 팽배하여 합리적 정책 결정에 방해가 된다.
+
+	* 포퓰리즘은 신호다. 5단계에선 중도파가 남아있지만 6단계에 가면 더 이상 찾아 볼 수 없다.
+
+	* 계급투쟁(Class Warfare) 집단의 구성원들을 정형화된 타입으로 보는 경향이 늘어나고 악마하게 된다. 
+
+	* 진실이 사라진 언론
+
+	* 희미해진 준법정신과 원초적 투쟁, 손해를 감수하더라도 법과 규칙을 준수하는 것이 중요하다고 생각할때 체제는 작동한다. ··· 승리만이 최후의 목적이 되면 비윤리적인 투쟁은 폭력적으로 변한다. 모든 사람에게는 투쟁하는 목적이 있고 어떤 것도 서로 합의할 수 없다면 시스템은 내전이나 혁명에 빠지게 된다.
+
+	* 5단계 후반에는 사법제도와 경찰력을 지배하는 권력이 이를 무기로 사용하며 , 사설 경호원들이 많아진다. 시위는 다발적이고 폭력적으로 변한다.
+
+	* 원칙 <<의심스러우면 탈출하라>. 내란이나 전쟁에 휘말리고 싶지 않으면 사정이 좋을때 탈출해야한다. 국가는 자본을 통제하고 탈출을 봉쇄한다.
+
+	* 민주주의 가장 큰 위협은 분열되고 상반되는 의사결정 때문에 비효율적으로 체제가 운영되다가 국가가 제대로 돌아가기를 바라는 요구에 의해 인기있는 독재자가 나타나 혁명을 일으키는 것이다. 
+
+	* 5단계에는 강인한 중재자 (Strong peacemaker)가 나타나 국가를 단결하고 반대파를 설득해 모든 사람이 공정하고 올바르다고 생각하는 새로운 질서를 수립해야한다.
+
+## 	6단계 내전 상태
+
+* 내전과 혁명은 어떻게 발생할까? 모든 혁명의 성공 여부는 경제적 성공에 달려있다. 전체적 부가 늘어나고 분배가 잘 이루어지면 모든게 좋고 내전은 시작이다. … 하지만 빅 사이클 안에서 이를 경험하는 사람들은 큰 그림을 볼 수 없다. … 내전과 혁명을 이끄는 사람들은 대개 고등교육을 받은 중산층 … 
+
+* 거의 모든 내전은 자신에게 결과를 유리하게 이끌기 위해 외세를 개입시킨다. 내전과 혁명의 시작은 명확하지 않다. 혁명의 한가운데 있을 때 진행 중임을 명확히 알 수 있다.
+
+* 내전을 치르는데 가장 적합한 지도자는 따르고 싶은 장군이다. 각 계층의 지지를 얻어 여러 유형의 전투에서 승리할 수 있는 지도자다. 전투는 참혹하므로 승리하기 위해서는 무슨 짓이라도 할 만큼 냉혹해야 한다.
+
+**결론**
+
+상황이 바뀌면 접근 방식도 달라져야 한다. 즉 최적의 방식은 상황에 따라 유동적이고 상황은 계속 변한다. 고집스레 체제가 항상 최고라고 믿는 것은 잘못된 일이다. … 상황에 잘 적응하도록 끊임없이 체제를 개혁하는 것이다. … 역사를 통해 가장 명확하게 알 수 있는 것은 숙련된 협력 관계를 통해 한정된 파이를 키워 분배함으로써 공생 관계를 구축하고, 모든 사람이 행복하게 사는 것이 부와 권력을 쟁취하기 위해 한쪽이 다른 편을 굴복시키는 내전보다 훨씬 유익하고 덜 고통스럽다는 사실이다. 
+
+
+
+# 6장 국제 질서와 혼란의 빅 사이클
+
+* 국내 질서와 국제 질서가 구별되기 시작한 것은 최근의 일이다. *국제 관계가 훨씬 더 양육 강식의 법칙에 의해 좌우된다는 것*을 제외하고 비슷하다.
+
+* 모든 지배체계에는 모두가 인정하는 사법 입법 경찰력 벌금 및 구금 등 이 존재하지만 국제관계에서는 존재하지 않거나 효율적으로 동작하지 않는다. … 국제질서는 국제법이 아니라 정글의 법칙을 따른다.
+
+* 전쟁의 5가지 종류. 무역/경제 전쟁, 기술 전쟁, 지정학적 전쟁(영토와 동맹에 대한 분규로 전쟁이 아닌 협상과 (명시적 또는 암시적)약속으로 해결한다, 자본전쟁(기관과 정부에 대한 자금과 신용 공급 중지같은 조치로 해외 자본 유입금지처럼 금융 수단을 통해 발생하는 전쟁), 군사 전쟁
+
+* 사이클을 보면 상당기간 평화와 번영을 누린 후 잔인하고 폭력적인 국가 간의 경쟁이 발생한다. 강대국은 약소국의 희생으로 번영을 누리므로 모든 국가가 동시에 번영을 누리는 것은 아니다. (1840~1949년 중국 굴욕의 세기 백년국치)
+
+* 총(군사력), 버터(사회가 필요로 하는 생필품)을 제공하지 못하면 반대 세력의 도전에 직면하게 된다. … 경쟁국보다 더 많은 지출을 할 수 있는 경제적 여유야 말로 강대국에 있어 가장 중요한 요소이다.
+
+* 전쟁의 대가는 굉장히 크다. 공생하는 결과를 얻기 위해서는 상대방에게 가장 중요한 것과 내게 가장 중요한 것을 파악해서 그것들을 교환할 수 있도록 협상해야한다.
+
+* 승리란 소중한 것을 잃지 않으면서 중요한 것을 얻는 것이다. 승리가 주는 이득은 더 많은 생명과 재산을 잃는다면 이는 어리석은 일이다. 그럼에도 어리석은 전쟁이 일어나는 이유는?
+
+	* 죄수의 딜레마, 치고 받는 과정에서 발생하는 격화, 항복했을 때 영향력 축소로 인해 치러야 할 대가, 신속한 의사결정을 방해하는 잘못된 정보
+
+* All is fair in love and war
+
+****영국군은 불공정하다고 불평했다. 독립군은 영국군이 어리석다고 생각했고 전쟁에서 이겼다. 전쟁의 승리로 독립과 자율르 얻었으니 전투의 룰을 바꾼 것쯤은 아무것도 아니 게 되어버렸다. 원래 세상은 그렇게 돌아간다.*
+
+* 힘을 키우고, 힘을 존중하면서 현명하게 이용해라.
+
+* 젤렌스키가 생각나네) 힘을 존중 할 줄 알아야 한다. 절대 이길 수 없는 전쟁에서 무리하게 맞서는 것은 바보 같은 짓이므로 협상으로 최선의 대안을 찾아야 한다.(물론 순교자가 되겠다면 다른 도리가 없다. 이는 전략적으로 현명한 선택이 아니며 어리석은 자존심 싸움에 불과하다)
+
+**힘으로 원하는 것을 뺏지말고, 관대함과 믿음을 보여줌으로써 공생 관계를 수립하는 데 더 효과적이며 공멸보다 더 많은 것을 가져다 준다. 다른 말로 하드 파워보다는 소프트파워가 효과적이라는 이야기다. … 일반적으론 힘을 보유하는 것이 바람직하지만 불필요한 힘을 갖지 않는 것도 중요하다. 힘을 유지하려면 자원, 특히 시간과 돈을 사용하지 않을 수 없기 떄문이다. 또한 힘에는 책임이 따른다.**권력이 없는 사람이 권력이 있는 사람보다 훨씬 만족스런 삶을 살고 있다는 것을 알고 놀란 적이 한두 번이 아니다.*
+
+* 일본은 불황으로 수출이 감소하자 31년에 부도가 났고 금본위제를 폐기하고 변동 환율을 도입했지만 통화 가치의 감소가 너무커 구매력이 고갈되었다. 좌익 우익의 투쟁이 격화. 자원을 확보하기 위한 전쟁이 시작되었다. 
+
+* 관세 전쟁을 벌이면 수출이 감소하고 세계적인 불활을 일으킨다. 다만 관세로 인해 보호받는 집단에게는 이익이고 지도자에 대한 지지도가 올라간다.
+
+* 불황이 닥쳐 빈부 격차가 너무 커지면 부를 재분배하는 혁명적 조치가 취해진다. 평화적인 방법은 부자 증세, 통화량 증가를 통해 부채의 가치를 낮추는 것이고, 폭력적 방법은 강제 자산 몰수 같은 것이다. 
+
+* Hotwar 이전의 경제적 무기를 통한 전쟁, 자산동결 자본시장 접근 봉쇄, 금수조치 밍 무역차단
+
+* 인도차이나 공격 뒤 미국은 일본의 자산동결과 파나마 운하 접근 근지, 일본수출입 금지에 따라 5개월 뒤 진주만이 터진다. 미국은 일본의 확장을 경계했고 저런 경제 제재조치는 때릴테면 떄려보라는 도발이었겠네.
+
+* 전쟁에서는 고통을 인내하는 능력이 고통을 가하는 능력보다 훨씬 중요하다.
+
+**전시의 경제 정책**
+
+* 거의 모든 분야에서 돈이 묶이고 금과 은이 법정화폐의 역할을 한다.
+
+* 전쟁의 승패에 따라 주가가 오르고 내린다. 미드웨이 해전 이후 연합국의 주가는 오르기 시작했다. 부자들의 부를 보호하는것 보다 필요로 하는 곳으로의 재분배가 우선이 되므로 세금이 급격하게 올라간다. 때문에 채권 자산을 모두 팔고 금을 사야한다. 돈을 찍어내 자금을 조달하므로 통화 가치가 떨어지고 신용거래가 정지되기 때문이다.
+
+**결론**
+
+* 모든 강대국은 최전성기가 있고 쇠퇴한다. 하지만 높은 생산성을 유지하면서 수입이 더 많고, 국민 모두에게 혜택이 돌아가는 시스템이 있고 경쟁국과 공생하는 방법을 찾아 유지한다면 쇠퇴는 일어나지 않을 것이다.  … 미국은 최장기간 강대국의 지위를 유지하는 국가 중 하나가 되었다.
+
+# 빅 사이클로 판단하는 투자
+
+* 모든 시장은 기본적으로 4개의 결정 요인에 의해 작동한다. 즉 성장률, 물가 상승률, 리스크 프르미엄, 할인율이다.
+
+* 전쟁중에도 주식시장이 열려있었던 미국과 영국을 많이 참조하지만 이것은 잘못된 표본이다. 전쟁 중 사실상 모든 부가 파괴되거나 국가에 압수되었다는 사실을 기억해보라. 몇 나라에선 자본가들이 살행당하거나 투옥당했다. 
+
+* 극단적인 호황과 불황은 반복되며 지금은 불황과 구조조정으로 반복되는 말기에 와있음을 알 수 있다. 
+
+* 1350년 최초의 금융자산이 탄생했다.
+
+* 신용을 창출한다는 의미는 약속을 대가로 구매력을 창출하느 것이므로 단기적으로는 경기 부양 장기적으로는 불황을 낳는다. 
+
+**투자자 관점에서 본 빅사이클에 대한 자세한 설명**
+
+* 요즘에는 투자의 리스크를 안는것보다 수익을 내지 못한다.  투자자가 감내하는 가장 큰 리스크 3개, 포트폴리오가 수익을 가져자 쥐 못하는 경우, 포트폴리오의 파산, 수익을 세금으로 뺏기는 점.
+
+* 1900년까지의 경제 호황으로 유럽 국가간엔 평화가 유지되고 힘의 균형이 이루어졌따. 부채가 커지고 빈부격차가 나긴했지만 번영이 계속 유지될것 처럼 보였다. (백년평화) -> 거대한 전환에서도 다룬데
+
+* 그리고 최악의 수익률 구간이 도래했다. 가장 최악의 형태의 사유재산 몰수는 빈부의 격차가 커서 계급 갈등이 최고조에 달하거나 공황, 전쟁때 도래한다.
+
+**대형 자본시장 복습**
+
+* 사이클 하락 시에는 금융자산의 실질 수익률이 마이너스를 기록하고 불활이 닥친다. 반자본주의, 반자본가 사상이 득세한다. 최고조에 다를때 까지. 금융자산이 많아지면 화폐 채권수익이 떨어진다.
+
+* 통화의 평가절하 기간엔 경화와 경질자산의 가치가 상승한다. … 상승국면에서는 금융화폐와 금융재산이 실질화폐와 실질자산보다 더 증가한다.                       
+
+* 현재 명목 예금금리가 역대 최저점에 근접했다는 것은 무엇을 말하는가. 장기간 채권에 투자해도 원금을 돌려 받을 가능성이 떨어진다는 것이다. 그러므로 적은 이자를 받느니 아무것이라도 사서 인플레이션에 대비하는게 낫다.
+
+**결론**
+
+여기까지가 투자의 관점에서 본 1900년 이 후의 빅 사이클 500년 전으로 돌려도 이런 사이클이 반복되어 왔다. 45년 전 끔찍한 기간은 빅 사이클의 과도기의 전형적 현상. 새로운 질서가 정착하면 엄청난 호황이 온다. 
+
+# 2부
+
+
+
+# 8장 지난 500년의 요약
+
+1부가 내가 생각하는 영구기관의 작동 방식. 2부에선 영구 기관이 500년 동안 한 일을 보여 줄 것이다. 
+
+* 1500년, 훨씬 세계가 크고, 가문이 영토를 사스리며, 과학이 없었다. 지금보다 훨씬 더 불평등했다.
+
+* 근대 이전 최강의 국가 중국
+
+* 가장 중요한 변화는 사람들의 행동 양식 변화를 초래한 사고방식의 변화였다. 그중에서도 특히 부와 권력을 어떻게 분배 할것인가에 대한 생각이 바뀌었다. 역사는 여기서부터 시작된다. … 진화와 사이클에 주목하라.
+
+**상업혁명(1100~1500)**
+
+오스만투르크로 인해 막힌 육로교역을 대체하기 위한 해상 교역과 공화정 모델을 따른 도시정부들은 창의적이고 민심을 읽을 줄 알았기 때문에 상인 계급이 탄생할 수 있었다.
+
+ 능력을 중요시하는 정부 체제와 선진회계, 신용대출시장, 채권시장이 있었다. 적정한 이율에 돈을 빌릴 수 있는 능력은 베네치아에 큰 도움이 되었다. 전쟁에 몇 번 패배하고 디폴트를 선언했지만 유동적 채권시장은 다른 국가에서 활성화 되었다
+
+**르네상스 시대**
+
+르네상스는 역사상 가장 위대한 자기강화 사이클 중 한다. 창의력과 상업이 서로를 강화시켜 경제 호황이 위대한 진보를 가능케 했다. … 귀족층의 생활 수준이 급격하게 향상되었지만 번영이 지속되면서 사치와 퇴폐 풍조가 만연하고 경쟁력을 상실하면서 쇠락하게 된다.
+
+**대항해와 식민주의**
+
+가격혁명, 수 백년간 안정적이던 물가가 수십년마다 2배씩 폭등, 중국과 일본은 무슨 이유에서인지 고립 정책으로 방향을 선회한다.
+
+**종교개혁**
+
+군주, 귀족, 교회가 공생하는 관계였던 구질서가 무너진 사건. 긴 내전과 독일의 분열을 나았고 새로운 질서는 평화와 번영의 시대를 낳았다.
+
+**30년 저쟁 후의 새로운 세계질서(베스트 팔렌조약)**
+
+**자본주의의 탄생**
+
+공개적 주식시장, 자원 배분의 효율성 향상, 자본시장 사이클의 탄생, 암스테르담 즈권거래소, 영란은행의 역할이 시장을 시작시켰다. 
+
+**과학혁명(1500~1600)**
+
+논리적 추론에 의한 진리탐구, 권위에 대한 도전, 과정의 표준화, 생활수준의 향상. 특히 영국이 가장 혜택을 보았다. 이런 사상과 방법론들은 계몽주의를 통해 많은 분야로 확대되었다.
+
+**1차 산업혁명**
+
+중앙정부의 관료조직, 생산수단을 소유한 자본가들에게 권력이 집중되었다.
+
+**계몽시대와 혁명의 시대 (1600~1700)**
+
+혁명이 있었지만 질서의 회복에 대한 염원에서 나폴레옹이 나타났다. 
+
+**나폴레옹 전쟁과 이후의 새로운 국제질서(1803~1815**
+
+* 영국과 우방국이 나폴레옹을 쓰트러진 전쟁. 빈회의가 지배적인 국가의 탄생을 견제하게 되며 영국이 강대국으로 부상했다. 팍스 브리타니카
+
+아시아로 진출하는 서양 강대국들(1800~)
+
+**2차 산업혁명(1850~1900)**
+
+증기기관, 전기, 전화, 기계의 혁신이 20세기 초까지 이어졌다. 이 중심엔 미국이 있었고 많은 부와 빈부 격차, 잉여 자본이 생겨났고 도금시대로 이어졌다.
+
+**공산주의의 탄생(1848)**
+
+산업혁명의 열매를 노동자가 아닌 자본가들이 독점하는 세태에 대한 반발. 
+
+# 빅 사이클로  본 네덜란드 제국과 길더화의 부상과 쇠퇴
+
+1625년 ~ 1795 년 까지 네덜란드 제국
+
+* 독립 후 개방적이고 창의적인 사회가 되었다.. ( 중요한 부분, 전통주의의 유혹에 굴욕하면 역사의 패배자가 된다) 새로운 사상, 사람, 기술에 대한 개방성이 빠른 성장의 배경
+
+* 네덜란드 GDP의 1%에 달했던 동인도회사의 배당금. 투자를 받고 할 수 있는 시스템이 발명.
+
+* 위폐를 어느정도 막은 암스테르담 은행. 이 금융시스템으로 인해 길더화는 기축통화가 되었다.
+
+**베스트팔렌 조약**
+
+* 루터교를 믿는 스웨덴과 칼뱅주의의 네덜란드가 연합한 이유는 종교이념보다 돈과 지정학적 이유였다. 
+
+* 가장중요한건 이 조약을 통해 오늘 알고 있는 국가의 경계가 정해져서 그 안에서 스스로 결정할 수 있는 주권이 주어졌다는 것이다. 이렇게 민족과 국익의 개념이 탄생했다.
+
+* 전쟁은 상상하기 힘들 정도로 참혹하기 때문에 질서를 수립하기 위한 조약이 성립되고 다음 전쟁까지 평화의 시대를 구가하게 된다.
+
+* 황금시대가 오자 국민들이 편안한 삶을 원하고 재정상태가 악화, 다른 제국이 부상한다.
+
+* 전 세계에 걸친 부의 망을 보호하는 군사비용때문에 부채가 폭증
+
+* 1688년 영국의 경쟁력이 상승하자, 네덜란드 상인들은 런던으로 옮겨갔고 네덜란드는 분열하기 시작했다. 
+
+* 손실과 부책이 커지자 돈을 더 찍어내 부채를 없애게 되고 예금 인출 사태로 이어진다.
+
+* 은행이 동인도회사를 살리기 위해 화폐를 찍는다(관치구만 이것도)
+
+* 동인도회사 주식. 첫 50년 8000% 수익. 다음 50년 1000% 수익, 다음 50년 900% 수익, 다음 50년 휴지조각 … My opinion >> 부와 가치를 다루는 패러다임의 변화에서 나오는 폭발적 수익률과  더 세련되고 강력한 영국의 패러다임에 의한 몰락. 뭔가 비트코인이 생각나는걸
+
+
+
+# 영국
+
+* 초기과학 사상. 새로운 인간 중심 철학의 핵심은 사회가 이성과 과학에 근거하여 정부의 권력은 신이 아닌 국민에게서 나온다는 사고방식에 있다. 이 시기엔 토론과 회의가 권장. 기초 교육이 개선되고, 인쇄물을 통해 사상이 복브되고, 국경을 초월한 엘리트 계층이 정치 사회 사상을 논할 수 있는 공론장이 마련되었다. 여기서 오늘날까지 서구권에서 중요하게 여기는 주요 사상과 개념이 만들어졌다. … 이런 변화들이 즉각적인 경쟁 우위가 되진 않았지만 점차 법치주의를 존중하는 체제가 경쟁우위를 가지게 되었고 영국제국의 부상으로 이어졌다.
+
+**산업혁명**
+
+* 이제 권력은 중앙관료와 자본가의 손에
+
+* 나는 1700년대에 네덜란드와 프랑스 대신 영국에 투자할 수 있었을까?
+
+**프랑스는 왜 실패했을까?**
+
+* 프랑스는 교육의 중심. 1673년부터 주식시장을 운영했다. 미시시피 주식회사는 망했다.
+
+* 금융에서 영국에 뒤쳐졌기 때문에 더 높은 이율로 돈을 빌리고 세금에 더 많이 기대야했다.
+
+* 높은 세금과 기근이 프랑승 혁명의 조건이 되었다. (kth-오늘날 혁명이란게 일어날 수 있을까? 정말 최악의 국가를 제외하곤 잘 일어나지 않을것 같은데) 경화 화폐를 도입하고 하이퍼인플레이션 후 채무불이행을 선언한 뒤 이 난리가 끝나게 된다.
+
+* 빈회의 이후 모든 조건에서 정점에 오른 영국. 전세계를 지배하거나 말도 안되는 짓도 할 수 있게됨 (중국에 아편 수출..)
+
+* 장기간의 호황 뒤에는 파산이 생긴다.
+
+**경쟁력저하**
+
+1870~1910년까지 발명품 비율에서 영국이 뒤쳐지기 시작한다. 추월한 국가는 미국과 독일. 영국이 자국 산업을 재편하는데 실패하자 2차 산업혁명에서 뒤쳐진것.
+
+**불평등 심화**
+
+이런 쇠퇴가 시작될 시점에 1%는 75%의 부를 가지고 있었다. 상위 10%는 93%를 가졌다.
+
+치고 나오는 독일의 힘과 군비확장에 영국도 발을 맞춰야 했기에 군사비용의 부담이 커져갔다. 그리고 1차 세계대전으로 엄청난 소모전 끝에 맺어진 베르사유 조약은 새로운 세계 질서를 수립했다.
+
+* 경제공황 상태에서 영국과 미국은 자유민주주의를 지킬 수 있었지만 그렇지 못한 취약한 국가들은 포퓰리즘 독재자들이 통제권을 장악하고 제국을 확장할 방법을 모색한다.
+
+* 미국이 전쟁승리로 지배적인 제국이 되고 부와 권력의 전환이 이루어졌다. 영국도 이겼지만 막대한 부채로 인해 비용이 더 큰 덩치 제국이 되었다. 당장 기축통화의 지위가 사라지진 않았다. 45년 이후 60년대 까지 가파르게 줄어들었다. 파운드화의 채권을 가지고 있는게 불리하단걸 채권자들을 알게 되었고 몇번의 평가절하가 일어나면서 가치는 점점 떨어졌다. 그리고 그 자리는 마르크화가 대체하였다.
+
+* 영국이 전쟁 떄문에 규제로 유동성을 막아놓았고 다시 규제를 풀어야했을때 평가절하가 시작되었다. 영국총리는 애국정신을 강조했고 그러자 가치 하락은 가속화 되었다. 태환을 멈추자 파운화 자산을 매입한 해외 투자자들은 손해를 입었다. 파운드화의 평가절하가 되었고 이런 경향은 파운드화의 가치를 달러로 보장하지 않는한
+
+# 11장 빅 사이클로 본 미국과 달러화의 부상과 쇠퇴
+
+* 무역보다 늦게 발전한 뉴욕의 금융업. 1913년 연방 소득세가 도입되며 연방은행이 생겼다. 
+
+* 도금시대 그리고 1차 세계 대전. 1914~18년 전쟁이 끝나자 평화의 시대가 도래했고 투기자산(주식)을 매입하려는 부채가 생겨났다. 이 부채를 줄이기 위한 긴축이 대공황의 시발점이었다.
+
+* 2차 대전 이후 미국의 전쟁은 엄청난 비용이 드는 행위였따. 그럴만한 가치가 있었을까? 러시아는 미국과 군사적으로 경쟁하고 제국을 유지하는데 돈을 쓰다 파산했다.
+
+* 세계 부채가 많아지면 통화 가치를 절하하는게 모든 정부에 득이 된다. 그러한 시기에 금이나 디지털 자산이 선호될 수 있지만, 정부는 이러한 대체통화를 완전히 금지할 수 는 없어도 불법으로 취급할 가능성이 크다. 불태환 통화에 기반한 통화 신용 체제가 무너지면 결국 태환통화 체제로 향한다.
+
+* 저렴한 주택대출은 주택 시장의 호황을 일으킨다. … 마셜플랜의 지출은 인플레이션이 아무리 높아도 금리는 허용할 수 없는 수준까지 오르지 않았으며 정부의 정책은 국채보다 다른 투자 선택지가 더 매력적으로 보이지 않도록 했다. 평화의 시기에 번영은 새로운 빅 사이클의 시작이다. 
+
+* 달러 채권에 적힌 이자 때문에 세계 국가들은 금 보유고를 줄이고 달러 채권을 늘렸다. 이런 흐름은 은행의 실질 보유 자산(금)을 초과하는 돈을 발행했다는 사실이 밝혀질때 끝난다. 
+
+* 금태환이 약속이 끝나고 10년 동안 스태그플레이션이 발생했고 다른 산업화 국가들이 세계적인 경쟁력을 갖추게 되었다.
+
+* 정부가 돈을 찍어 부채를 매입하면 채권가격은 떨어진다. 금리가 떨어진다.
+
+* 70년대의 인플레이션은 약 14퍼센트. 그동안 금값은 급등했고, 원자재갸 값이 인플레이션을 추월했다. 금과 원자재의 수익이 30% 15%를 기록했다. 주식의 명목 수익률 5%와 국채 수익률 4%를 무색하게 만드는 수치였다.
+
+### 브레튼우드 체제이후
+
+* 전 세계가 불태환 통ㄹ화 체제로 전환되면서 그 기타 통화 주식 등 모든 자산군의 가치가 하락했다. … 미국인들은 인플레이션을 처음엔 잘 알지 못했지만 알게된 이후에는 급여를 받는 즉시 물건을 구매하여 인플레이션을 앞지르려 했다.
+
+* 이 시기 각국엔 혼돈을 바로 잡을 보수주의 정권을 선출했다. 
+
+****경제와 정치는 좌파와 우파 사이에서 양극단을 다양하게 오고 가는데, 특히 한쪽이 너무 곽겨해지고 다른 한쪽에서 벌어진 문제에 대한 기억이 희미해질때쯤이면 다시 변활르 거친다.* 넥타이 폭과 스커트 길이가 시간이 지나면서 계속 바뀌는 패션 유행과도 같다.
+
+* 1982년 멕시코 디폴트에 반등한 주식시장. 돈을 잃은 레이 달리오. 중앙은행이 부채에 표시된 통화를 찍어내고 부채를 재조정 할 수 있다면 부채 위기가 체계적으로 관리될 수 있고 위험하지 않다.
+
+* 중앙 은행이 통화와 신용을 창출 할때는 더 공격적으로 자산을 소유하는것이 현명한 대처 방법이다. 
+
+* 인플레를 극복하기 위해 긴축통화정책을 하게되면 달러는 강세를 보인다. 이떄 신흥국이 쓰러진다. 
+
+* 미국의 중사층을 대체한 신흥국의 기계와 노동자.
+
+* 공직자들은 유권자들은 돈이 어디에서 오는지 신경쓰지 않는다. 어디에 쓰는지만 신경쓴다. 따라서 공직자들도 그렇게 행동한다. 
+
+* 양극화되는 정당. 1900년 부터 1960년 까지는 공화당과 민주당의 이념의 격차는 크게 다르지 않거나 줄어 들었고 정당이념에 따른 의원 선출 비율도 낮았다.
+
+* 중앙은행 재무 상태는 전수준 30%를 추월했다. 다만 유럽중앙은행이 60% 일본이 120%를 추월했다.
+
+* ‼️ 통화와 신용이 크게 증가하면 그 가치는 떨어지고 다른 투자자산의 가치가 오른다.
+
+* 미국은 빅사이클내 70±10% 위치에 도달한 상태. 5단계에서 6단계로 확대되는 증표. 규칙이 무시되고, 양측이 서로 감정적으로 공격하고, 유혈사태가 발생하는 것
+
+# 12장 빅 사이클로 본 중국과 위안화의 부상
+
+* (이 장을 내지 않았으면 하는 주변 사람들의 우려에 대해) “정직하게 의견을 내지 않는 것은 내 자존심이 허락하지 않는다. 나는 비판을 두려워하지 않으며 오히려 기꺼이 받아들인다. … 나는 직접적인 경험과 연구를 통해 내 관점을 개발하고, 배운 내용을 기록하고, 똑똑한 사람들에게 그 결과물을 보여주며 스트레스 테스트를 진행한다.”
+
+* 전쟁에 승리하는 것과 제국을 안정화 시키기 위한 사람들을 모으고 통합하는 일은 다르다. 
+
+* 왕조 쇠퇴의 패턴. 재분배로 시작했지만 결국엔 토지의 불평등. 통화 발행에 따른 인플레이션. 통치 체제와 기반시설은 왕조 초반 시기에 상승하다 점차 하락한다. 개국군주들에 비해 후반기 황제로 갈수록 경직되고 보수적인 통치자가 호화로운 생활과 대외 무역 지원을 축소했다. 열악한 조건과 커다란 부의 격차가 봉기의 원인이 된다. 상업, 기술 구사력보다 학문을 선호하는 고립주의와 유교의 영향이 중국의 경쟁력을 약화 시키고 외세에 패하는 결과를 낳았다.
+
+* 식량수입국인 중국. 불안정한 식량과 대기오염. 이로 얻은 교훈을 현재 지도자들에게 교훈을 주었고 정치적 참사가 반복되지 않도록 보호 장치가 마련되었다. 
+
+* 미국인들이 충동적이고 전술적이라면 중국인들은 전략적이며 미래에 원하는 것을 계획한다.
+
+**중국의 교훈과 운영 방식**
+
+* 존 페어뱅크 중국의 세계 질서. 첫째 중국문화지역. 내륙아시아 지역. 외곽 야만인 (일본, 동남아시아, 유럽)
+
+**중국의 통화와 경제역사**
+
+* 최초의 법정 화폐 1100년 중국이 시작
+
+* 경화와 지폐 통화의 싸이클
+
+* ‼️ 원칙 국내 부채 문제가 발생했을 때 자본 통제가 적용되는 통화를 보유하고 있다면 얼른 빠져나와야 한다. 평가절하 되기 쉽다
+
+**쇠퇴 (1800~1949)**
+
+* 1840년 부터 1949년까지 중국은 계속해서 쇠퇴의 길, 혹독한 빅사이클을 경험했다.
+
+* 2차 대전이 끝나고 남은 외국인들이 다 송환되자. 부와 권력을 어떻게 재분배할지 내전이 일어났 1946년 3월 31일 - 1950년 5월 1일
+
+**마르크스 레닌주의**
+
+자본주의에 대한 저자와 마오쩌둥의 생각 차이와 그 결과는 진실을 바라보는 시선의 중요성을 알려준다.
+
+* 저자와 마르크스가 세상을 바라보는 시선은 (루핑을 통해, 변증법적 유물론을 통해) 세상이 발전한다는것은 비슷하다. 근본적 차이는 무엇을 선택하고 무엇이 수행되어야 한다고 생각하는지다. 
+
+* 덩샤오핑 “물질적 풍요가 있어야 비로소 능력에 따라 각자에게 필요레 따라 각자에게”라는 공사주의 사회의 원칙이 적용될 수 있다. 사회주의는 공산주의 첫 단계이다 라고 말했따. 
+
+1단계 기반구축 (~76년)
+
+2단계 덩샤오핑
+
+* 하나의 중국을 확인받고 외국으로부터 배워 공산주의식 자본주의를 도입.
+
+* 철밥통을 깨트리고 의욕을 떨어뜨리는 고용보장과 기본혜택을 제공하지 않았다. 인센티브 기반 보상으로 교체하기 위한 포석, 세계화도 도움이 되었다.
+
+* 중국과 미국의 공생관계, 싼 소비제를 수출하고 중국인이 저금한 돈을 미국이 중국으로부터 돈을빌려 (미국이 채권을 팔아) 물건을 사는 모습을 생각해보라. 기축통화국의 채권으로 저축하는 신흥국은 기축통화국을 과잉부채로 이끌 수 있다. 
+
+* 덩샤오핑이 죽었을떄 미국과 충돌할뻔했던 3차 대만해협 위기. 25년이 지난 지금은 어떻게 될까?
+
+* 강대국과 신흥국의 무역은 공생관계다. 배움 그 이상의 의미가 있다. 그리고 그건 불리해질때까지 유지된다. 
+
+* 08년 번영이 끝나고 국내 국제적 분쟁의 시대로 도입
+
+* 중국의 반자본주의적인 전쟁에 대한 저자의 생각. “모든 국가의 지도자가 통화 정책과 재정 정책을 관리하고 조정함으로서 국가와 자본주의 사이에서 적절한 균형을 찾으려 한다는 사실을 알아야 하며, 정부 정책의 숨은 의도를 이해하기 위해 노력해야 한다” … 겉보기에는 커다란 모순(마르크가 말하는 변증법) 같아도 그속에 존재하는 일관성을 알차리기 쉽지 않다. 
+
+* “그들에게 자본주의는 국민 대부분의 생활 수준을 높이는 수단이지, 자본가를 섬기기 위한 것이 아니다.” “중국인이 미국식 서구식 접근 방버을 따르기 위해서 그들의 방식을 포기할 것이라고 기대해선 안된다. 오히려 우리도 그들의 방식을 연구해 배울 점을 찾아야 한다.”
+
+* STEM 졸업생 수는 미국의 3배.. (..) 80년 이후 미국에서 3차 교육인구가 68% 늘동안 중국은 2272% 늘었다.
+
+## 미 중 관계와 전쟁
+
+* 운명적 힘이 미국을 강하게 만들고 중국을 약하게 만들었고 또 지금은 미국을 쇠퇴하고 중국을 부상하게 만들고 있다.
+
+* 달러가 기축통화가 된것은 세계적으로 대성공을 거두었기 떄문이다. 덕분에 나머지 국가로부터 과도하게 돈을 빌릴 수 있었지만 재정적으로 취약해졌다. 부채를 화폐화 하면서 실질적으로 마이너스 금리를 지불한 탓에 채권국(중국)도 취약해진건 마찬가지다.
+
+
+
+## 내 생각들
+
+1. 이 책은 우파의 주장과 좌파의 주장이 어떻게 현실에서 반영되고 동작하는지 균형있게 보여준다. 좋다..
+
+2. 만연한 현대의 타락한 모습들이 원래 역사상 항상 팽배했던것은 아니며 그것에도 정도와 단계가 있음을 알려준다. 굉장히 좋은 지적.. 나는 항상 원래 그렇다고 믿는게 강헀다.
+
+3. 중국의 GDP 추월 시점은 2030년
+
+4. 인도가 일본을 추월할 시점은 2025년
+
+5. 생산수단이 자원과 노동력, 웹, 웹의 알고리즘, AI
+
+
+---
+
+# 장작위키 또는 인터넷 검색 결과
+
+## 패권경쟁에 대한 분석
+
+### 중국우위론 
+
+* 막대한 구매력-> 이게 지속되거나 압도적이게 되면 무슨일이 벌어질까..? 미국의 외교실패, 철도인프라 우위, 비교적 최신식 인프라, 중국에 들어가는 인재들(파일럿)
+
+### 미국우위론
+
+* 소프트파워, 군사력, 지정학적 우위, 중국보단 나은 사회체계에 대한 신뢰, 비교적 나은 빈부격차, 학문기술의 우위, 인재유입
+
+
+---
+
+
+---
+
+
+---
+
+중요한 컨셉
+
+**부채의 화페화** 돈을 찍어내 일단 쓰는것으로 정부가 부채나 세수 증가없이 구매력을 얻는 행위.
+
diff --git "a/Bear/\354\234\240\353\213\211\354\212\244 \352\263\240\352\270\211 \354\211\230\354\227\220 \353\202\230\354\230\244\353\212\224 \354\232\264\354\230\201\355\214\201.md" "b/Bear/\354\234\240\353\213\211\354\212\244 \352\263\240\352\270\211 \354\211\230\354\227\220 \353\202\230\354\230\244\353\212\224 \354\232\264\354\230\201\355\214\201.md"
new file mode 100644
index 0000000..ea56e46
--- /dev/null
+++ "b/Bear/\354\234\240\353\213\211\354\212\244 \352\263\240\352\270\211 \354\211\230\354\227\220 \353\202\230\354\230\244\353\212\224 \354\232\264\354\230\201\355\214\201.md"	
@@ -0,0 +1,24 @@
+# 유닉스 고급 쉘에 나오는 운영팁
+
+#Devops/language #Book #project
+
+
+---
+
+1. `cp` 같은걸 사용하는 배치를 작성을 할때 항상 --verbose 옵션을 사용하기를 권장. 어차피 로그를 열어볼일은 잘 없지만, 열어보게 될 일이 생길땐 최대한 자세한 내용을 원한게 될테니까 말이다.
+
+2. 배치쉘이 1초간에 같은 이름으로 여러 파일을 작성가능성이 있다. 이에 대한 예외 처리를 통해 이름 뒤에 시퀀스를 붙이거나 천천히 실행하도록 조치를 해야한다.
+
+3. 파일시스템에 대한 염려없이 일단 로그를 저장하게 만든 시스템이 다운되는 경우가 많다.  그래서 운영을 할때 파일이 자동으로 증가하는 영역이 있다면 미리 삭제하는 배치작업을 만들어놓는게 매너.
+
+4. `rm -rf $tmpDir/` 이렇게 코드를 짰는데 $tmpDir 에 참조할 변수가 없으면 `rm -rf /`		이 된다. 정말 조심 이런 에러를 막기위해 set -u 를 하면 참조실패할때 스크립트를 종료시켜버리는 기능이 존재한다.  → Shell option
+
+5. 웹서버를 공격할때 RFC(Request for Comments)를 위반한 요청이 온다. (RFC에 기반하여 HTML 프로토콜이 작성되었다) 그러면 첫번째 요청의 헤드가 이상하게 온다. (그럼 웹 서비스 로그도 이상하게 남겠지) 그래서 로그를 감시할때 좀 예외케이스를 주의할 필요가 있다.  광 범위하게 500번대 에러를 돌려주는 리퀘스트를 필터링 하려면 awk ‘$NF-1) >= 500 {print $}
+
+
+
+
+
+
+---
+
diff --git "a/Bear/\360\237\207\272\360\237\207\270\354\235\264\355\225\264\355\225\230\352\270\260.md" "b/Bear/\360\237\207\272\360\237\207\270\354\235\264\355\225\264\355\225\230\352\270\260.md"
new file mode 100644
index 0000000..43c7795
--- /dev/null
+++ "b/Bear/\360\237\207\272\360\237\207\270\354\235\264\355\225\264\355\225\230\352\270\260.md"
@@ -0,0 +1,7 @@
+# 🇺🇸이해하기
+
+1 inch = 2.54cm
+
+
+
+#living/nation
\ No newline at end of file
diff --git "a/Bear/\360\237\207\273\360\237\207\263 \354\236\240\354\226\270.md" "b/Bear/\360\237\207\273\360\237\207\263 \354\236\240\354\226\270.md"
new file mode 100644
index 0000000..d99d47d
--- /dev/null
+++ "b/Bear/\360\237\207\273\360\237\207\263 \354\236\240\354\226\270.md"	
@@ -0,0 +1,96 @@
+# 🇻🇳 잠언
+
+#mind/잠언
+
+
+---
+
+"한시간의 소중함을 알지 못하면 하루의 소중함도 알지 못한다."
+
+
+
+"그럼에도 인간에게서 눈을 돌리지 말아주세요. 원래 그러한 법이라며 포기하지 말아주세요. 타인에게 정이 식는 것은 간단하며 타인을 미워하는 일은 훨씬 더 간단한데도 타인을 계속해서 사랑한다는건 너무나도 어려운 일이니까."
+
+
+
+"진보의 이상, 인간 감정의 실존성, 낙관은 사람의 꺼지지 않는 영원한 바람이며 지금을 살고자 하는 모든 인간이 소망하는것이다."
+
+
+
+"진심으로 믿는 마음이 너의 마법이다"
+
+
+
+"자기신뢰와 타자신뢰와 같이 있으면 어떤 교우도 어떤 사랑도 가능하다."
+
+
+
+"네가 손안에 뒤엉킨 천 가지 만 가지를 쥐고 있으면 사업도 복잡한 천 가지 만 가지로 꼬이게된다. 그러나 바늘 하나에 실 하나만 들어갈 수 있다​"
+
+
+
+"지금 만났던 미래 꼭 만나고 싶어요."
+
+
+
+"미래를 상상하는 것보다 중요한 건 현재를 파악하는 힘과 문제를 해결하는 상상력"
+
+
+
+"이성과 감성이란 이름의 신성은 인간 안에서 영원히 갈구된다. 그 갈망을 인생속에서 풀어 내는게 인생의 궁극적 과제"
+
+
+
+"있어 보이고 대박날 생각만 하고 있으니 손이 안움직이고 부담스러운 글이 나온다. 내가 생각하고 느낀걸 써야지."
+
+
+
+"나라의 GDP나 GNP가 올라간다고 자신의 생활이 바뀌지는 않는다. 그게 시장에서 돈의 생리다. 자신이 사회에서 가치있는 생각과 행동을 하고 그것을 전파하게 될 때 돈이 생긴다."
+
+
+
+"영원한 강자도 영원한 패자도 없어서 재미있는게 삶"
+
+
+
+"영원한 명제나 생각은 없다. 매 순간 새롭게 해석되어 새로운 가치를 부여받는다. 완벽하고 영원한 답을 한방에 찾으면 그게 가치있을거란 플라톤적 사고는 짧은 생안에선 답변 받을 수 없는 시도다. 단방에 해결할 수 없는 문제를 해결하기 위해선 매일 싸울 수 있는 문제와 씨름하는게 최선이다." (울타리치기)
+
+
+
+"잡기는 시간을 TV보다는 조금은 더 주체적으로 보내는 의미밖에 없다. 더 나은 일을 찾아라. 내 안의 공허함은 나아가서 능동적인 과업과 그것을 남들과 공유할 수 있을 때 해결된다."
+
+
+
+"나는 사람들이 내가 가진 이 느낌을 알아줬으면 좋겠어 너무나.."
+
+
+
+"나도 여자랑 잘해보고 싶은 마음이 있구나"
+
+
+
+"도망치지 않고 직면하는 것만으로도 인생의 정말 많은 점이 개선될것이다. 영어회화를 못하는 One Okay Rock 타카가 영어를 잘하게 된것은 순전히 노력"
+
+
+
+"진짜가 뭔지 너무 고심할 필요는 없다. 삶은 진짜다"
+
+
+
+"성공의 시작은 자신의 능력을 신뢰하는것으로 시작한다. 신뢰안하면 아무것도 안된다."
+
+
+
+"나쁜 소식을 듣는다고 멈추면 안된다. 그게 언덕을 향해 돌을 민다는 의미다. 밀고 싶을때만 밀면 돌에 깔린다."
+
+
+
+"원하는 것을 위해 기꺼이 포기하는게 인생이다. 무엇을 원하는지 부터 확실하게 하라. 인생 모든걸 걸어서 라도 얻고 싶은것. 그게 인생의 등대다."
+
+
+
+"모두가 각자의 게임을 하고 있다. 누구나 배드엔딩은 싫어한다."
+
+
+
+"랜드솔 월세가 나의 게임인지 방배동 월세가 나의 게임인지.”
\ No newline at end of file
diff --git "a/Bear/\360\237\214\247 (1) Devops Mainline.md" "b/Bear/\360\237\214\247 (1) Devops Mainline.md"
new file mode 100644
index 0000000..4657a58
--- /dev/null
+++ "b/Bear/\360\237\214\247 (1) Devops Mainline.md"	
@@ -0,0 +1,6486 @@
+# 🌧 (1) Devops Mainline
+
+#Devops #Mainline
+
+설명 - 강의 들으면서 최대한 중요한 내용만 골라서 코어를 뽑아내려는 방식으로 메모, 실용적 팁, 경험이 들어간걸 적는다.
+
+
+
+# 《Part 1》
+
+* 시작 - 데브옵스의 고객은 개발자, 그들이 운영에 참여할 수 있는 환경을 제공한다.
+
+* 데브옵스의 커리어 범위
+
+	* 네트워크, 개발 및 배포 플래폼, 오케스트레이션, 관측 , 클라우드 플래폼, 보안 플랫폼, 데이터 플랫폼,  서비스 운영
+
+	* 보안 플랫폼, 데이터 플랫폼도 포함하지만 일단은 조금씩 분리됨
+
+	* 네트워크 엔지니어, 시스템 엔지니어가 오면 네트워크도 분리됨.
+
+	* 다 연관이 있기 때문에 기본은 알되 하나는 전문성을 가지면 좋겠다.
+
+* 데브옵스의 실천!‼ (데브옵스 핸드북 참고)
+
+	* 문화의 성숙도를 평가할 수 있는 지표를 설정하고 추적하자
+
+
+
+## Devops 로드맵
+
+* 언어 선택에 중요한 기준 
+
+	* 서비스들이 서드파티 지원을 할때 언어 (Go, Python, Node.js  3강)
+
+* 컨테이너 기반으로 하다보면 initd, systemd 볼일이 잘 없음
+
+* OS는 AD를 운영할게 아니면 리눅스 중심으로 하고 BSD는 필요없다.
+
+* Jenkins는 역사가 오래된 만큼 기본, Gitlab CI 가 컨테이너 최적화
+
+* elastic Stack 을 하면 모니터링은 다 들어가있음
+
+* Jager 오픈소스에서 많이 New Relic은 유료
+
+* 오픈소스는 Prometheus 유료는 Datadog
+
+* 데브옵스 커리어
+
+	* 다른 부서가 하는 일을 이해하고 있어야 하기에 진입이 쉽지 않다.
+
+	* 흉내만 내는건 할 수도 있지만 안정화, 자동화, 비용
+
+	* 기술 도입은 신중히
+
+	* 장애가 발생하면 근본 원인을 찾고 (Root Cause)을 찾고 장애 기록(Post-mortem)을 남기는 습관을 기르자. 왜?를 통해 업무를 강화
+
+	* 깊게 공부를 하게 되면 처리 시간이 늦어진다. 대충 처리하고 나면 남는게 없다. 이직을 하거든 이전 조직에서 깊게 다루어 본 문제로 신뢰를 얻고 새로운 문제에 도전해보자.
+
+	* 정말 잘 하고 싶다면 영어는 필수다. 공식 문서를 읽는 습관, 질문을 하고 답변하자.
+
+	* 잘하는 사람들이 가득한 환경에 뛰어 들어야 한다.
+
+* 업무영역
+
+	* 개발 인프라에 대한 관리 및 형상관리,효율개선
+
+	* SW개발, 인프라 지원팀과 연락 역할
+
+	* 개발 흐름을 이해하고 CICD 유지 및 개선
+
+* 필요기술
+
+* Eng : CIDE파이프라인, 클라우드 서비스 이해, Docker, Linux, 스크립트, Ansible, 소스제어(gitlab), 모니터링 서비스
+
+* Principal : 성가 평가 책임을 가진 팀 리딩 역할, Linux 기반 환경 개발 및 테스트 변경 및 구성에 대한 이해, 클라우드 환경에 대한 구축 경험 및 이해, CICD 운영, 디자인 패턴 및 리팩토링 경험, 성능 조정 및 병목현상 및 문제 분석에 대한 지식, VPN, CIDR 네트워킹 지식
+
+
+
+## AWS
+
+* 사용중이지 않은 Elastic IP는 요금
+
+* EC2 네트워크 수신은 공짜, 송신은 1기가까지 공짜
+
+* VPC 리소스들
+
+**VPC, subnet, route Table, VPC peering, DHCP options, Virtual Gate, Internet Gateway** ⇒  비용 X
+
+```diff
++ `NAT Gateway, PrivateLink, Site to Site VPN
+```
+ 과금
+
+
+* IAM
+
+	* 많은 리소스를 생성해도 과금 없음
+
+	* 
+```diff
++ User, Group, Role, Policy
+```
+
+
+* "공짜 서비스로 IaC를 연습하자"
+
+* AWS 멀티 사용자 프로파일이 필요할 수가 있다. 
+
+	* .*aws*config
+
+	* aws sts get~~caller~~identity
+
+****calculator aws* 이런 서비스도 존재한다. 
+
+	* 실습할때도 실무할때도 항상 계산하도록
+
+* 하나의 서비스에 여러 서비스가 얽혀있어서 리소스 잔여물을 처리하기가 힘들다. AWS-NUKE 로 한번에 처리 가능
+
+
+
+
+---
+
+
+
+# 《Part 2》
+
+* 강사: 송근일 (당근, 카사코리아 인프라 디렉터) 
+
+* 이렇게 잘나가는 사람도 헤매고 고통스러워한다. 나라고 별 수 있겠냐 연습하고 스스로를 단련시켜서 당황하지 않는 수밖에
+
+
+
+## 《Chapter 1 - AWS basic》
+
+
+
+* AWS 에서 제공하는 서비스
+
+	* 컴퓨팅 서비스 Elastic Computing 2
+
+	* 네트워킹 서비스 Route53, VPC, AWS Direct Connect, AWS ELB
+
+	* 스토리지/DB 서비스 RDS, DynamoDB, AWS ElasticCache, S3는 파일형식에 구애 받지 않는다.
+
+	* 데이터 분석 & AI Redshift (분석특화 스토리지), EMR(대량 데이터 처리), Sagemaker(분석을 위한 환경제공)
+
+
+
+네트워크 
+
+* IPv4
+
+	* network bit, host bit
+
+	* A,B,C 작은 네트워크 많은 호스트 ~ 많은 네트워크 적은 호스트 세번째 옥탯까지 네트워크를 표현하면 C!
+
+	* 네트워크를 쪼개기 위한 Subnet. CIDR 표기로 대역을 쪼갠걸 표현 /25는 2^7개의 호스트를 가지겠지. 네번째 옥탯으로 시작 네트워크를 알 수 있다.
+
+* VPC(Virtual Private Cloud)
+
+	* Availability Zone
+
+		* 서브넷은 하나의 AZ에만 속할 수 있다.
+
+		* AZ 하나에 여러개의 서브넷이 있을 수 있다.
+
+* Private subnet
+
+	* 인터넷 불가
+
+	* 얘한테는 0.0.0.0/0 라우트 테이블이 없어서 못나간다.
+
+	* DB를 여기에 배치한다.
+
+	* 그래도 인터넷과 통신이 필요하다. 이때 퍼블릭으로 경유해 통신을 한다. 이걸 가능케 하는게 NAT Gateway, NAT instance
+
+	* 실제로 바로 가는게 아니라 라우터가 퍼블릭서브넷 안의 NAT 게이트웨이로 보낼뿐.
+
+* Public subnet
+
+* NACL
+
+	* Stateless, Access block 가능
+
+	* 프로그램의 요청과 응답의 포트는 다르다. (임시포트 1024-65535)
+
+	* Rule number 에 의해 우선순위가 결정된다.
+
+* Security Group (VPC의 상태값이라 보면 된다)
+
+	* Statefull
+
+	* outbound에 정책이 없으면 원래 응답을 할 수 없다 (예를 들어 1024) 하지만 스테이트풀하니까 응답할땐 허용함. 
+
+* Bastion host
+
+	* 인터넷에서 프라빗호스트로 접근하기 위한 호스트
+
+* VPC endpoint 
+
+	* 서비스에 비공개로 연결할 수 있다. 리소스와 통신하는데 IP가 필요없다.
+
+	* 중간 매개체
+
+		* 프라이빗 서브넷도 aws의 여러 서비스와 연결이 필요한데 그걸 가능케함.(AWS 서비스도 일종의 인터넷) 
+
+		* interface endpoint: private ip를 만들어 서비스로 연결햄. 뒷구멍
+
+		* gateway endpoint: 추가적으로 라우팅 테이블에 추가해줌. (S3, DynamoDB). 중립 지역에 별도의 게이트 웨이.
+
+* NAT 나 IG를 통해서 AWS와 통신하는건 비추천. 트랙이 노출이 됨
+
+	* 노출 안시시키기 위해 Gateway endpoint 사용
+
+	* 서비스는 s3를 위한 엔드포인트.
+
+	* 프라이빗 서브넷을 선택
+
+
+
+## 《Chapter 2 - Backend Development》
+
+### Django
+
+* 개념
+
+makemigrations - 스키마 업데이트
+
+migrate - Django 스키마 업데이트
+
+시리얼라이저: DB에 있는 값을 사용하기 편하게 JSON으로 바꿔주는 도구
+
+* 공개키 등록
+
+* 서버에서 keygen rsa 해서 나온 pub 값을 repository 디플로이 키에 등록했고
+
+* keygen  email 서명으로 나온 pub 값을 깃허브 계정 ssh 키에 등록했다.
+
+* 이를 통해 사용자와 리포지터리 배포관리자가 보안에 합의했음을 증명.
+
+* 배포 명령어
+
+```shell
+
+virtualenv -p python myenv
+
+pip3 install -r requirements.txt
+
+>> "You already have Python3 but don't care about the version"
+
+sudo ln -s /usr/bin/python3 /usr/bin/python
+
+# 위 명령을 통해 python3 소프트링크를 python 에 링크
+
+
+
+PIP도 아래와 같이 해도 되는데 pip3를 쓰면 되니까 굳이 할 필요는 없다.
+
+sudo apt install -y python3-pip
+
+sudo ln -s /usr/bin/pip3 /usr/bin/pip
+
+```
+
+
+
+## 《 Chapter 3 - Manual deploy 》
+
+* 순서
+
+```
+
+Ubuntu LTS v22 생성
+
+// ... keygen rsa 생성 ...
+
+git clone ${repo}
+
+sudo apt update
+
+sudo apt install python3-pip
+
+pip3 --version
+
+sudo apt-get install libmysqlclient-dev
+
+sudo apt-get install python3-dev
+
+pip3 install -r requirements.txt
+
+sudo apt-get install python3-tk
+
+```
+
+
+
+* without nohup) 백그라운드 실행하고 터미널 유지하는 방법
+
+1.  [COMMAND] + ’ &’
+
+2. `disown -h`
+
+   →  "-h  mark each JOBSPEC so that SIGHUP is not sent to the job if the shell receives a SIGHUP"
+
+###  Load Balancer
+
+* Application load balancer 장점은 패킷을 까서 분기를 만드는것 (로드밸런스 기능 + sticky Session 보장)
+
+	* 이런 로드밸런스 그룹의 한 서버가 죽으면 세션이 다 날라가는 문제가 생긴다.
+
+	* 이때 WAS간 Session Clustering 을 해놓으면 세션이 이관된다. (톰캣 가능)
+
+
+
+* ROUTE53
+
+	* 개념
+
+		* NS	호스트하는 서버
+
+		* SOA=CNAME 다른 도메인 이름과 일부 리소스로 트래픽 라우팅
+
+		* A IPv4 실제 라우팅 정보
+
+* Certificate manager + ROUTE 53
+
+	* HTTPS 를 하기 위한 조건
+
+	* 제대로 하지 않으면 HTTPS 통신은 블로킹
+
+
+
+0. ROUTE 53에서 도메인 이름을 지정하면 검증을 하는 과정에 들어간다.
+
+1. 검증이 끝나면 CNAME 을 라우트53에 추가하면 된다. 
+
+2. 이제 SSL 인증서가 발급된다.
+
+
+
+실제 실습:
+
+* 인증서등록 - 로드밸런서(443) 추가 - SSL 인증서 등록
+
+
+
+* Cloudfront
+
+	* Cache + CDN 서비스
+
+	* 똑같은 작업을 반복하는 것이 비효율적이므로 그걸 해결하기 위한 캐싱
+
+		* 처음엔 no Hit, origin이 계산한다. 그리고 distribution에서 저장한다.
+
+		* 다음 요청 부터는 Hit
+
+	* 만약 유저가 바뀌었다면? 다른 값을 뿌려야한다. 
+
+		* Cache가 있다면 잘못된 정보를 주지 않기 위해 주기적으로 갱신해야한다.
+
+		* 그래서 오래 동안 안바뀌는 경우에 주로 캐시서버를 사용한다. 아닌경우엔 간격을 짧게 관리한다.
+
+	* CDN(Content delivery Network)
+
+		* 어디에서 요청하더라도 빠른 속도의 서비스 제공Edge Location
+
+	* CDN 실습
+
+		* CNAME 과 SSL을 이용하여 생성한 다음 
+
+		* Route53에서 로드밸런서 대신 CDN의 CNAME으로 연결해준다.
+
+	* CDN Dist 생성
+
+		* 로드밸런서를 Origin Domain 으로 선택한다. 
+
+		* ROUTE53에선  로드밸런스를 바라보는 CDN별칭을 선택한다.
+
+	* CDN Cache Policy
+
+		* mimi, max, Default TTL을 지정할 수 있었다
+
+		* 최근에 신규 정책이 생기면서 recomendation 이 됨
+
+		* 클라이언트 쪽에서 TTL 을 설정할 수 있는데 그걸 무시하는게 여기서 설정하는 TTL
+
+		* 5초 ~15초 설정을 해도 충분히 도움이 된다.
+
+
+
+* 어플리케이션 구동
+
+	* 동적파일을 나눠주는 WAS를 스케일아웃 하는것 보단  WEB서버를 스케일아웃하면 편하다. 자동으로 배포가 된다! (nginx + django 앱 폴더 끝!) 
+
+* NGINX 
+
+* Gunicorn
+
+* WSGI 서버: uWSGI, gunicorn, Apache/mod-wsgi를 많이 사용하는데, uWSGI 같은 경우에는 고성능 서버 성능을 지니고 있으며, gunicorn 같은 경우에는 보통 수준의 성능이지만 설치와 관리가 간단하다
+
+	* 웹서버와 웹 애플리케션의 인터페이스를 위한 파이선 프레임워크 WSGI. 이런게 nginx랑 연동되서 돌아가나봄.
+
+	* wsgi 만 있어도 동작은 하지만 SSL 과 정적 파일을 지원하지 않으니 nginx를 사용하는 것. 특히나 유닉스 소켓을 사용하면 성능이 월등이 좋아진다.
+
+	* 잘 보면 WSGI 서버가 .sock 파일을 생성하고 nginx 에서 저 소켓으로 트래픽을 보냄
+
+```nginx
+
+server{
+
+  listen 80;
+
+  server_name *.compute.amazonaws.com;
+
+  location / {
+
+    include proxy_params;
+
+    proxy_pass  [http://unix/home/ubuntu/django_nginx/](http://unix/home/ubuntu/django_nginx/) 
+
+```
+
+
+
+```gunicon
+
+[program:gunicorn]
+
+directory=/home/ubuntu/django_nginx
+
+commnad=/usr/bin/gunicorn --workers 3 --bind unix:/home/ubuntu/django_nginx/app.sock django_nginx.wsgi:application
+
+autostart:true
+
+autorestart:true
+
+stderr_logfile=/logs/gunicorn1.err.log
+
+stdout_logfile=/logs/gunicorn1.out.log
+
+``` 
+
+
+
+**배포 명령** 
+
+```shell
+
+sudo gunicorn --bind 0.0.0.0:8000 django_nginx.wsgi:application
+
+python3 manage.py runserver 0.0.0.0:8000
+
+gunicorn --bind unix:/home/ubuntu/django_nginx/app.sock django_nginx.wsgi:application
+
+```
+
+
+
+* 우분투 systemd 만들어서 관리하기
+
+```shell
+
+vi /etc/systemd/system/gunicorn.service
+
+sudo systemctl start gunicorn
+
+sudo systemctl enable gunicorn
+
+systemctl status gunicorn
+
+```
+
+이 작업을 하고 나면  systemctl restart nginx … 등의 컨트롤이 가능해짐
+
+
+
+* DOCKER 개론
+
+	* VM
+
+		* 하나의 서버 내에서 확실하게 구분 (HVM) but 비효율
+
+		* 유동적으로 Power Weight 를 조정할 수 없다. 
+
+	* DOCKER
+
+		* 하나의 서버 안에서도 환경이 독립될 필요가 있다.
+
+		* 개발에서든 배포에서든 그래서 만들어짐
+
+		* 프로세스 취급하므로 효율적으로 자원사용
+
+* Docker-Compose
+
+	* 쓰는 프로그램이 다른 성격일 경우 컨테이너간 상호작용이 필요하고 그 역할을 하는게 컴포즈. 도커를 둘러싸고 관계를 정의.
+
+
+
+* Docker 실습 과정
+
+```shell
+
+curl -fsSL https://get.docker.com/ | sudo sh
+
+sudo usermod -aG docker $USER
+
+uwsgi.ini  //소켓 위치와 uwsgi 가 실행되는 위치를 명시
+
+```
+
+
+
+
+
+## 《 Chapter 3 - 중규모 아키텍트 》
+
+* ECS (elastic container service)
+
+	* ECR elastic container registry VS docker Registry
+
+	* ECS 를 쓰면 EC2를 띄우고 그 안에 도커를 실행하는걸 관리해줌.
+
+	* AWS Fargate : EC2를 TASK 로 감싸고 클러스터가 TASK 를 감싸서 유저가 직접 EC2를 관리안하게 해줌 
+
+	* 컴포즈가 필요할땐 ECS- CLI 로 관계관리 가능
+
+
+
+* ECS practice
+
+	* 클러스터 생성 (Cluster는 작업으로 구성)
+
+	* 네트워크 전용으로 구성. EC2	는 안쓸꺼니
+
+	* ECS 인스턴스는 EC2 인스턴스와 동일
+
+	* 『시작 호환성』 > EC2 는 고전적 방법 (EC2 하나에 여러 도커를 실행)
+
+	* 『작업크기』 각 작업이 사용할 리소스 레벨을 지정할 수 있다. 
+
+		* 여기서 사용할 컨테이너를 지정한다.
+
+	* 만들었으면 작업을 실행한다. 작업 갯수, 실행할 클러스터, 네트워크 모두 지정
+
+	* 실행하면 배포가 된다. (각자 IP도 할당받고)
+
+
+
+* 도커 컴포즈 작업 (YML) 작성을 CLI로 작성한다. 
+
+* Docker 밑작업
+
+* sudo usermod -G [그룹] [계정] 2차 그룹 1개
+
+* sudo usermod -aG [그룹] [계정] 2차 그룹 여러개 허용
+
+* 2차 그룹에 속한다고 그룹이 변하진 않는다.
+
+
+
+* CLI를 통해 작업정의 생성
+
+* JSON 파일들을 모아놓는 디렉토리를 생성
+
+* 작업정의에 사용한 파라미터 ECS Task definition
+
+	* family 작업의 이름
+
+	* task role 작업실행역할(IAM)
+
+	* Container definition
+
+* 실행하는 계정이 ECR에 접근할 권한 + 클러스터가 태스크에 접근할 실행권한(execution role)도 필요하다.
+
+* 파게이트를 생성하고 서비스도 해야한다. (VPC에 연결)
+
+`ecs create_service —cluster [NAME] ~~-service-name --task~~definition ~~-vpc~~configuration`
+
+* 지우게 되면 ECS 도 같이 관리해주므로 EC2 에는 남는게 없다.
+
+* 작업정의된건 비용이 안든다. 실행중인 작업만 신경써
+
+
+
+* (직접 컴포즈를 작성하지않고) AWS CLI 를 통해 도커컴포즈 만들기
+
+	* ECS vCPU 20개면 한달에 80만원
+
+	* ECS CLI 가 별도로 존재, 도커 컴포즈와는 문법이 다름
+
+	****GPG*로 퍼블릭키를 통해 ECS CLI 에 권한 부여
+
+		* `gpg ~~o ecs~~cli [URL ecs~~linux~~latest.asc]`
+
+		* `gpg ~~-verify ecs~~cli.asc *user/local/bin*ecs-cli`
+
+
+
+```shell
+
+docker tag docker [sserver/django] [ecr]
+
+docker push [ecr-url]
+
+docker tag docker [server/nginx] [ecr-url]
+
+docker push [ecr-Surl]
+
+
+
+aws iam attach-role-policy 
+
+
+
+esc-cli up --empty --cluster [이름]  //빈 클러스터 생성
+
+ecs-cli configure profile --profile-name song ~~~
+
+ecs-cli configure --cluster [name] --default-launch-type [타입] --region [리전] --config-name [
+
+	// 프로파일로 설정값들을 만들어놓을 수도 있다. (액세스 키, 시크릿 키)
+
+	// 프로파일은 프로파일일뿐. 실행이 아니다 .
+
+ecs-cli configure default --config-name cli-config
+
+ecs-cli configure profile default --profile-name song
+
+
+
+vi docker-compose.yml 	// ECS-CLI 는 문법 다른거 알지!?
+
+	// depends_on 도커에선 쓰지만 ECS-CLI 는 없다 이런게
+
+vi ecs-params.yml
+
+ecs-cli compose --fiele docker-compose.yml --ecs-params ecs.yml service create --launch-type FARGATE
+
+	// 이렇게 실행하면 비어있는 ECS 에 서비스를 생성한다.
+
+```
+
+
+
+AWS-KMS  Key management service
+
+	* 데이터 암호화 과정을 직접 구현할 수도 있다. 하지만 KMS 쓴다.
+
+	* 서버 사이드의 암호화는 AWS에서 다 하는중
+
+	* 관리하는 암호키를 CMK Customer Master key 라함
+
+	* hardware security modules 저장소에 저장함.
+
+	****Cloud-trail*로 어떤 key를 어떻게 사용하는지 로그 남김
+
+* Datakey 는 4KB보다 더 큰 파일에 사용
+
+	*  플레인 데이터 키, 엔크립트티드 데이터 키 두개가 존재.
+
+	* 플레인 데이터 키는 항상 사용후 바로 삭제, 암호화된 키만 저장
+
+	* CMK만 들고 있으면 결국 데이터는 안전하다.
+
+	* CMK는 리전에 종속된다.
+
+	* KMS는 CMK만 제어한다.
+
+* 파이선은 백단에서 데이터암호화를 해주는데 node.js는 직접 해줘야함.
+
+* AWS encryption Python. 파이선을 먼저 썰치하고 설치 권함
+
+* 파이선예제
+
+	* client 객체 생성
+
+	* AMK arn 복사하고
+
+	* cyperText, Header 정보도 리턴한다.
+
+	* 암호화하면 BASE64로 일단저장
+
+	* 클라이언트에 공개되는 코드인데 하드코딩된 만약 호스트 주소를 숨기고 싶다? 그러면 암호화를 해놓는거다. 
+
+	* boto3, 액세스키, 등등 모두 이렇게 사용하면 좋다.
+
+****비용*
+
+	* 2만건 액세스 무료. 1$ 0.03$, KMS 1개 1$
+
+
+
+CodeCommit
+
+* something not good git-hub but it has good point about connecting code deploy.
+
+
+
+* AWS CodeDeploy 구성 절차
+
+	* ECS, Lambda, ECS 배포 플래폼 선택
+
+	* 디플로이먼트 타입스 & 그룹스
+
+	* IAM, Service role
+
+	* 비용
+
+		* 배포 서버당 0.02달러. AWS 서버는 공짜.
+
+
+
+* 코드디플로이 튜토리얼
+
+	* aws iam create-policy Policy.json 생성
+
+	* aws iam list~~attached-user~~policy 생성된 정책을 IAM 적용
+
+	* aws iam create-role
+
+	* aws iam attach~~role~~policy
+
+	* 코드디플로이 - 어플리케이션 생성
+
+	* 코드디플로이 - 배포그룹 생성 ( 배포를 어디에 해야할지 설정)
+
+	* 코드디플로이 - 서비스 롤 입력, 에이전트 설정, 로드밸런스 설정
+
+	* 그룹을 만들고 나면 배포그룹안에 있는 EC2에 대해 배포가 진행된다.
+
+	* 배포생성 - 배포그룹 선택 - 어플리케이션을 깃헙에 저장 - repo 이름 커밋 ID 입력 (우측 상단 nuj91281)
+
+	* 이제 코드를 끌고와서 배포를 하는데.. EC2로 하면 이것저것 CLI 로 건들게 많으니 불편하다. ECS로 하면 좋지
+
+	* YAML 파일을 사용해 앱의 실행 중단 등의 시나리오 처리를 할 수 있다.
+
+
+
+
+
+# 《 PART 3 》
+
+
+
+## CHAPTER 1
+
+
+
+RabbitMQ 
+
+* Asynchronous Messaging
+
+	* 메시지 처리는 REST API로도 할 수 있지만 귀찮아! 그걸 해주는 브로커
+
+	* PM과 비슷한 역할을 하는 브로커 메시지 전달에만 집중
+
+* MicroService Architecture
+
+	* 독립된 DB를 쓰고 DB consistency 작업도 해준다. 이것도 MQ로 한다.
+
+
+
+* 개발 - 장고
+
+* pika 래빗 클라이언트
+
+* py → viewsets 패키지
+
+	* class를 선언해놓고 5가지 함수를 구현한다. (http 각 메서드에 해당하는)
+
+	* urls.py 에는 라우팅 인자에 ShopViewSet.as_view({}) 를 넣는다.
+
+* class ShopSerializer(serializers.Modelsirializer):
+
+	* class Meta:
+
+		* model = Shop
+
+		* fields = '_***all***_'
+
+		* 이렇게 하면 디비 내용을 객체처럼 다룰 수 있다. 장고 ORM의 정수
+
+
+
+* 개발환경구축
+
+도커 --volume: 이 옵션을 사용하여 로컬 디렉터리의 특정 경로를 컨테이너 내부로 마운트할 수 있습니다. 
+
+이걸 통해 도커안에서 뭘 변경해도 바로 로컬에 반영이 되고 DB 도 마찬가지다..
+
+	****매번 개발환경을 셋팅해야하는 참사는 이제 없다(!‼)*
+
+
+
+* 개발 - 플라스크
+
+	* 라이브러리
+
+SQLAlchemy // ORM
+
+Flask-Migrate  // model을 디비와 동기화
+
+Flask-Script // 
+
+request  // html 요청을 쉽게 사용할 수있도록
+
+
+
+* 플라스크 코드
+
+@app.route('/')
+
+def index():   // 단순간결하다!
+
+
+
+* SQLAlchemy로 모델을 정의할때 다른 DB와의 연동을 위해 id 를 autoincrement=false로 관리
+
+* 마이그레이션을 위해 'flask***migrate, flask***script 사용'
+
+* 마이 그레이션 절차
+
+	* docker-compose exec [name] sh	//마이그레이션을 위해 인스턴스에 접속
+
+	* python manager.py db init
+
+	* python manager.py db migrate
+
+	* python manager.py db upgrade
+
+
+
+* CloudAMQP - rabbit 클라우드 서비스
+
+
+
+* 개발 - 메시지큐 (오더)
+
+
+
+```python
+
+producer.py // 작성, 피카 사용, 발급받은 URL params 로 connection
+
+connection.channel()
+
+def publish()
+
+	channel.basic_publish(exchange='', routing='order', body='hello')
+
+//이제 프로듀서를 main.py 에서 import 하여 추가하면 실행시 프로듀서도 실행된다.
+
+
+
+consumer.py
+
+	channel = connection.channel()
+
+	channel.quere_declare(queue='order')
+
+// order'큐를 선언한다.
+
+
+
+def callback(ch, method, perperties, body):
+
+	print("received")
+
+
+
+channel.basic_consume(queue='order', on_message_callback=cacllback, auto_ack=True)
+
+// 큐를 받으면 콜백을 실행한다.
+
+// ack해주면 이제 메시지는 클로즈
+
+
+
+exec backend 
+
+python consumer.py
+
+"started consuming"
+
+//컨슈밍 시작. 이제 API 호출하면 프로듀스하고 컨슈밍도 된다.
+
+```
+
+
+
+
+
+* 개발 - 메시지큐 (보스)
+
+	* 이제 ORDER에서 boss queue 로 생성하면 BOSS 에서 받는걸 볼 수 있다.
+
+	* consumer.py producer.py	는 업데이트 했으면 다시 켜주고
+
+
+
+* 도커컴포즈
+
+	* 도커파일에서 python manage 삭제하고 대신
+
+docker-compose.yml
+
+command: 파라미터를 통해 자동실행하게 만든다.
+
+	* queue 서버를 추가한다.
+
+command python consumer.py 로 실행
+
+depends_on
+
+	-db
+
+	* 이렇게 앱 2개, 프로듀서, 컨슈머 다 셋팅하고 컴포즈하면 전부다 다 실행
+
+
+
+* BOSS 개발
+
+@dataclass					// 아래 양식으로 사용하기 위한 데코레이터
+
+class Shop(db.model):		// 상속 받아야함!
+
+	id int
+
+	title: str
+
+	image: str	// 대충 쿼리를 사
+
+	return jsonify(Shop.query.all()) 	// 모든 데이터 get
+
+// SHOP을 처리할 수 있는 ORM dataclass를 추가
+
+
+
+* 데이터 복제처리
+
+	* 구조 변경 처리를 하고 MQ로 consume 한 뒤 똑같은 내용이 디비를 변경하도록 처리
+
+	* 자신이 사용하는 디비를 변경하고 그 사실을 MQ에 날리고 consumer가 자기쪽 DB도 바꾸는 흐름
+
+
+
+마이크로서비스 - 아키텍트와 실행방법
+
+	* 규칙
+
+	* 독립성이 최우선(domain drive)
+
+	* API 설계(URI은 팀간 협업의 베이스라인 이므로 꼭 FIX )
+
+	* 데이터 스키마를 효율적으로 관리(중복 최소화, 만약 image를 가진다면 참고하는 디비의 ID값만 가지게 설계)
+
+	* 독립적으로 스케일링 (목적에 맞게 설계, 
+
+	* 회사의 서비스가 90%이상 정해지기 전에 마이크로 서비스는 애로가 많다. 폐인 포인트가 없으면 모놀리식이 좋다.
+
+* 강사님의 테스트 프랙티스
+
+	1) End to End 테스트 환경 구축
+
+		* 이때는 기존 테스트 서버를 하나 더 짠다.
+
+		* 마이크로 서비스는 테스트 환경 구축이 까다롭다.
+
+	2) 테스트서버 배포를 통해 배포 전에 문제를 캐치 (강사님은 3일동안 QA기간을 가짐) 이렇게 한달 하다가 다음단계로 넘어감
+
+	3) 테스트 시나리오 구성 (기획자가). 에러 빈도, 에러 중요도, 
+
+	4) 테스트 서버에 업로드 후 1일간 테스트 시나리오 테스트 (수동)
+
+	5) 테스트 서버에 업로드 후 1일간 테스트 시나리오 테스트 (자동)
+
+	My opinion - 이건 우츠쿠시이.. 하다. 왜 전 회사에선 이렇게 안했을까... ㅠㅠ
+
+* 배포정책
+
+	* 호스트 하나에 여러개 서비스를 배포
+
+		* 관리용이, 독립성이 떨어짐, 자원 최적화 불가(CPU많이 쓰는 서비스, 메모리 많이 먹는서비스 다 다르다)
+
+	* 호스트 마다 하나의 서비스 하나 배포
+
+		* 가상머신 기반 or 컨테이너 기반 컨테이너가 좋지! 서버리스도 있다~(서버환경을 신경안써도 되니 서버리스) CPU 메모리 사용량에 따라 지불|
+
+* 조직원들을 설득
+
+	* 변경을 바로 적용할 수 있게 되야하니 개발자들은 귀찮다.(프로젝트성으로 일할때가 예측성이 높다)
+
+* 마이크로서비스 도입때 겪은 문제점
+
+	* 조그마한 코드 수정도 배포하기 위해 복잡한 프로세스+오랜 시간 필요
+
+	* 디버그 하기가 까다로움 
+
+	* 너무 거대해서 한 눈에 안 잡힘 (서비스와 서비스의 관계를 고려해야할 점이 많아진다. 복잡도 증가)
+
+	* 정말 좋은 CI/CD 파이프라인 없으면 고전한다.
+
+	* CICD를 제대로 활용하지 못하는 경우
+
+	* 테스트가 약함, 마이크로서비스를 하면 data consistency 문제가 추가된다
+
+	* 수집하는 구조를 짜고 저장(S3), 엑셀로 데이터를 보게 할 필요도 있다. 그리고 Mysql 에 올려서 검색.. 이런식으로 짰다. 그리고 슬랙에 Event 전달. 
+
+	* 각 서비스들이 ECS, EC2 등등 여러 환경에서 도는데 성능을 체크하는것도 중요하다.
+
+	* 정확한 업무분장이 필요하다.
+
+
+
+Codebuild
+
+* buildspec.yml
+
+	* 당연히 빌드 해주고, 테스트도 해준다.
+
+Codedeploy
+
+
+
+
+
+* 로그 관리
+
+* 결국은 백트래킹(문제를 추적하는 과정)
+
+* 그래서 S3에 로그를 저장할것이다. (이게 실무에서 하는 방법)
+
+ 
+
+* 테스트
+
+    from django.test import TestCase
+
+    class ShopModelTest(TestCase):
+
+    	def test***sample(self): 			// 이름은 test***로 시작해야한다.
+
+    		temp = True
+
+    		self.assertIs(temp, True)	// 두 인자 같은지 비교
+
+    다시 빌드하고
+
+    python manage.py test user_order	//디비를 만들고 테스트까지 진행해서 결과 보여줌.
+
+⇒  이제 YAML'에서 테스트 명령어만 넣어주면 된다! 결과값과 출력값을 업로드하고 분기점 관리하면 디플로이 과정에 테스트가 들어가게 된다.
+
+
+
+CodeBeanStalk 콩줄기, EB, (free for aws resource)
+
+* ECS, EC2로 배포할때 번거로움을 대신 해줌. 백단에서 fargate 또는 인스턴스를 컨트롤 해줌.
+
+* 사용
+
+~/eb-flask$ eb init ~~p python~~3.7 flask~~tutorial -~~region us~~east~~2
+
+~/eb~~flask$ eb create flask~~env
+
+~/eb-flask$ eb open
+
+~/eb~~flask$ eb terminate flask~~env
+
+~/eb-flask$ eb deploy
+
+
+
+* 생성시 선택가능 항목
+
+	* 웹서버 환경, 앱 이름, 플랫폼 선택(파이선 버전), 어플리케이션(샘플,코드업로드)
+
+* 바로 배포 가능. 간단해 보이지만 뒤에선 EC2와 보안그룹이 돌고 있다.
+
+* 파이선은 안되지만 JAVA는 WAR 파일로 배포가능함
+
+* 배포 과정
+
+	0. EC2생성
+
+	1. apt update, python3 설치,  export PATH=$PATH:*opt/aws/eb/linux/python2.7*
+
+	2. export PATH=~*.local*bin:$PATH
+
+	3. curl ~~O  [http:*/bootstrap.pypa.io/get-pip.py](http://bootstrap.pypa.io*get~~pip.py) 
+
+	4. pip3 install awsebcli ~~-upgrade -~~user // awscli 도 설치
+
+	5. awscli configure
+
+	6. 처음에는 느리지만 적응되면 EC2에 직접 배포하는것 보다 빨라진다.
+
+	7. 가상환경 만들기 install virtualev
+
+	8. virtualenv ~/eb-virt
+
+	9. source ~*eb-virt/bin*activate
+
+	10. pip install django==2.2
+
+	11. django-admin startproject ebdjango
+
+	12. cd ebdjango
+
+	13. pip freeze > requirements.txt
+
+	14. mkdir .ebxtensions & cd .eb
+
+	15. vi django.config
+
+		1. option settings:
+
+  aws:elasticbeanstalk:container:python:
+
+  WSGIPath: ebdjango.wsgi:application
+
+  /public: *public  /*왼쪽으로 접근하면 오른쪽으로 처리한다.
+
+	0. vi setting.py & allowed_hosts = "*"
+
+	1. cd .. & deactivate  // 가상환경 exit
+
+	2. eb init ~~p python~~3.6 django-tutorial  // 배포할 EB환경을 생성한다. 이게 거의 80%
+
+	3. eb init
+
+	4. eb create django1-env // 환경을 셋팅. 이제 ctrl + c 해서 나가도 실행은 됨. 로그를 보면 SG가 만들어지는것도 보인다.
+
+	5. eb status
+
+	6. eb deploy  // 결과값에 보이는 cname 이 서비스되는 서비스 (eb open로도 다시 배포 가능?)
+
+	
+
+### Code pipeline (Code build + Code deploy)
+
+* 젠킨스는 AWS에서도 쓸 수 있지만 서클 CI는 안됨
+
+0. 생성 - 이름, 서비스역할 (새, 기존), 아티팩트 스토어 사용자지정위치, 
+
+1. 소스공급자 지정 ( 모든 트리거는 repository 의 역할 ), 깃헙도 되고 S3, ECR도 가능
+
+	1. 레포지터리 선택
+
+	2. 브랜치 선택
+
+	3. 변경감지옵션 (웹후크: 변경시 먼저 해달라고 요청함, AWS CodePiepline 얜 스스로 감시함)
+
+	4. 빌드스테이지 추가 (빌드 절차가 담긴 build.yaml 업로드)
+
+	5. 배포스테이지 추가 (배포공급자- beanstalk, 리전, 앱 이름, 환경이름)
+
+2. 이제 소스를 끌고 오는 등의 절차가 시작된다. 
+
+3. 이제 커밋만 하면 알아서 배포까지 진행! 
+
+
+
+### 서버리스 아키텍트
+
+* 개요
+
+	* 마이크로 서비스의 철학은 쓸만하지만, 서버리스는 약간 의문이다. 잘못쓰면 실이 더 많을때도 있다. 
+
+	* 여러 종류가 있다. 추상화된 서버를 빌려서 쓰는 형태. Lambda, Goole Firebase
+
+	* 장점: 확장에 유연, 장애처리 불필요, 개발에만 집중, 트래픽 변화에 유연
+
+	* 단점: 비쌈, 느림(셋팅까지 0.8초) , 장기적 작업에 안맞음, 함수처리결과를 별도로 저장해야함.
+
+적합한 시스템 
+
+	* 쓰기 좋은 예제: 누스 분석 시스템, 가끔 발생하는 이벤트에만 동작하면 된다
+
+* 종류
+
+	* BaaS(backend as a service)
+
+		* customizing 어려움, 엄청난 개발속도
+
+	* FaaS(Function as a service)
+
+		* 그냥 함수, 트리거되면 실행된다.
+
+**Lambda**
+
+	* 요금
+
+		* 요청수, 실행시간 기준으로
+
+		* 100만건, 40만초까지는 무료
+
+		* 128MB, 1ms 마다 0.0000000..21 USD
+
+* 개요
+
+	* 람다의 트리거 소스 (S3, RDS, DynamoDB, API Gateway)
+
+	* 15분 제한시간
+
+	* 더욱더 독립적이기에 관리하기가 더 까다롭다 (에러가 어디서 났지? 어디서 끊어졌지?)
+
+	* 실행할때 콘테이너가 만들어지고 패키지를 옮기고 이 과정을 콜드스타트(0.8초)
+
+		* 10분정도 이내에 호출되면 웜스타트(no delay)
+
+	* 따라서 B2C플로우 과정에는 사용하지 않는걸 추천한다.
+
+	* 그냥 임의로 불러서 대기 시키는 방법이 있긴하지만 
+
+	* 컨테이너 최대 갯수제한 (1000개), 넘어가면 대기를 하게 된다. 그래서 매우 주의해서 사용
+
+
+
+## AWS***API***Gateway
+
+* 요금
+
+	* 프리티어 - 수신 API 100만개, 수신 HTTP 100만개, 메시지 100만개, 연결시간 7.5million
+
+	* API 100만건당 1.23 달러 
+
+		* [한유저가 하루에 접속해서 100번 호출한다고 하면.. 10만명이 사용한다면 12.3$ 한달 375$
+
+	* API 단계별로 캐싱을 한다. 
+
+		* 0.5g 하루 0.5$ 한달 15$ 
+
+		* 1.6g 하루 1$ 한달 30$
+
+		* 6.1g 하루  4.8$	한달 146$
+
+* 대체 가능한 오픈소스: 크라켄D
+
+* 서비스 개요
+
+	****API를 손쉽게 생성, 게시, 유지관리, 모니터링 및 보안 유지할 수 있는 완전관리형 서비스*
+
+	* 프론트에서 URL을 호출하는데 백엔드 호스트 주소가 변하게 되면 까다롭다. 그래서 그냥 무조건 게이트웨이로 가게하면 변경이 자유로워진다. 
+
+		* gate*a → .com		gate*b → org  이렇게 라우팅 가능
+
+	* 서비스의 구조가 자주 바뀔 수 있는 마이크로서비스의 경우 더 유용하다.
+
+	* 람다를 트리거하기 위해선 필수
+
+	* 제공 하는 서비스 대분류
+
+		* HTTP API: 단순하고 싸고 빠르다.
+
+		* REST API: 복잡하고 비싸고 느리다.
+
+		* Web-socket API
+
+* CORS 과정을 상세하게 컨트롤 할 수 있다.
+
+	* Cross origin HTTP request
+
+		* case 1) 다른 도메인에서 호출한다.  `http:*/fc.com 에서  http:/*fc.org를 호출한다?`
+
+마이크로 서비스라면 이런걸 또 허용해야겠지(Standard 함수) ⇒  이런걸 허용하기 위한 인증작업을 CORS(cross origin resource sharing) 이라 한다. 
+
+		* case 2) 다른 포트
+
+		* case 3) 다른 프로토콜 http, https, ftp
+
+	* 실제 호출 과정
+
+		* 권한 체크 《클라이언트 → 서버》
+
+			* 요청내용: OPTIONS
+
+			* GET, Content~~Types, Authorization, x-api~~key
+
+			* "난 너 URI 에 이런 타입으로 하고 싶어!"
+
+		* 허용 《클라이언트 ← 서버》 
+
+			**요청내용: Access Method : GET, POST  , Content~~type, Access-Control-Allow~~Origin:**
+
+			**"GET, POST 된다. 내가 허용할 오리진은** 이다."
+
+		* 실제 API콜 《클라이언트 → 서버》 
+
+* Canary 배포
+
+	* 버그관리
+
+		* 일부 유저에게만 업데이트된 버전을 노출시켜 리스크를 관리
+
+		* 유저가 카나리 버전과 구버전에 골고루 노출된다. 종속되진 않음.
+
+		* 요구 사항을 통과하면 프로덕션 릴리즈로 승격
+
+	* AB 테스트
+
+		* e.g 배너사이즈를 여러가지로 노출시켜서 어떻게 반응하는지 보고 싶으면 kanary 배포 사용가능.
+
+* 실습 
+
+	* 목표: 경로를 생성하고 Lambda 와 연결
+
+	* 우선 '경로' 생성 e.g) *shop*
+
+		* method, URL path 입력
+
+		* 『통합 연결』 
+
+			* 통합대상: http URI, Lambda, Step function 등등 지원 
+
+			* 여기서 람다에 연결
+
+
+
+## AWS_Lambda
+
+* 생성
+
+	* 블루프린트, 함수 컨테이너, 리포지터리 찾아보기 여러가지 형태의 시작 템플릿 지원
+
+	* 기본 패키지는 있지만, 없는것도 있다.
+
+* 메인 화면의 기능
+
+	* 수정 후 『Deploy』 을 눌를 때마다 lastest 버전 생성
+
+* 동작특성
+
+	* 여기서 표준입출력을 쓰면 로그의 Functions log 에 뜬다. 
+
+	* 과금은 Build duration 기준
+
+* 테스트 이벤트 구성
+
+	* 이벤트 템플릿 : 호출할 인자를 사전에 구성, 여기서 설정하는 event → 함수의 event 인자
+
+* 트리거
+
+	* 여러가지 이벤트 소스를 설정할 수 있다. (여기선 API_Gateway 와 연결)
+
+* 로그
+
+	* 클라우드 와치에서는 람다함수의 업데이트 버전마다 로그를 관리하고 있다.
+
+	* AWS X-ray 라는걸 쓰면 분석하기 좋다
+
+* 권한
+
+	* 함수에도 ARN 을 붙여서 액세스 통제를 할 수 있다.
+
+* 버전관리
+
+	* 『작업-새 버전 발행』 을 통해 버전을 생성한다.
+
+	* 별칭 연결하여 prod로 들어오면 1로 실행하게끔 할 수 있다.
+
+	* 가중치 기반 별칭: 버전별로 가중치 설정
+
+
+
+### AWS***API***Gateway - (2) HTTP API 셋팅 실습
+
+* 경로 포맷 
+
+	* shop*{id} 			/* 패스 파라미터
+
+		* 이게 요청되면 람다에서 받는 함수의 인자가 궁금해진다. 
+
+⇒ jsonformatter 를 이용한다.
+
+		*  [pathparameter.id](http://pathparameter.id)  항목
+
+	* shop*1?filter=1	/* 쿼리 파라미터
+
+		* queryStringParamerts.filter 항목
+
+
+
+### API_Gateway - (3) REST API 셋팅 실습
+
+* Canary 배포전 설정
+
+	* 새 하위 리소스
+
+		* shops
+
+	* 메서드 생성
+
+		* GET
+
+			* Lamba 연결 이때 별칭(prod)으로 관리한다. 
+
+			* canaryFunction:prod
+
+		* 배포 스테이지 생성 (first)
+
+			* 스테이지 변수 
+
+				* name: prod_name
+
+		* 배포 스테이지에 리소스를 배포한 것이다.
+
+			* *first*shops
+
+			* 이렇게 배포가 제일 앞에
+
+* 람다 함수의 기능을 통해 Canary 실행
+
+* 버전 1, 2가 있는 상태에서 별칭의 설정을
+
+	* 1의 가중치를 10%
+
+	* 2의 가중치를 90% 설정
+
+
+
+### API_Gateway - (4) APIGW를 통해 카나리 실행
+
+* Stage configure → 『canary』  생성
+
+	* 셋팅
+
+		* lambda: new, stable 존재
+
+		* GW: 생성 → Lambda 함수 입력시 
+
+lamdaFunction:${stageVariable.version}
+
+		* 변수로 입력 그 후 CLI 에서 권한을 입력해줘야한다.
+
+			* aws lambda add~~permission --function~~name … func:stable
+
+			* aws lambda add~~permission --function~~name …  func:new
+
+	* 스테이지 생성
+
+		* 스테이지 변수 생성
+
+			* version
+
+				* stable
+
+		* canary
+
+			* 카나리 지정된 요청 배분율 10%
+
+			* second로 지정된 요청 배분율 90%
+
+				* canary 재정의 값은 new로 설정
+
+		* GUI환경에서 람다로 하는게 퍼미션 과정이 없어서 좋다...
+
+
+
+### API_Gateway - (5) CORS 관리
+
+* 『활성화』 를 통해 정책을 덮어쓴다.
+
+	* Allow Headers는 기본값 쓰면 되고
+
+	* Origin 값이 주요한 변경 대상
+
+* 통합 응답
+
+	* 메서드 응답을 하기전 전처리
+
+	* Options 를 호출하면 헤더, 메서드, 오리진 값을 돌려준다.
+
+* 메서드 응답
+
+	* 각 응답 상태에 대한 헤더 메서드 오리진 등등을 컨트롤 가능
+
+* 이제 람다함수에는 headers: { 'Content-Type': ... , 'Origin': ... , '} 값을 작성해줘야 한다. 제대로 동작한다. 형식을 지키지 않으면 다 에러남.
+
+
+
+## AWS_Lambda - (2) 동시성과 람다의 세부 기능
+
+* 동시성 
+
+	* 전략 A
+
+		* 미리 컨테이너를 지정받아 할당하면 콜드스타트를 방지할 수 있다.
+
+		* 2019년도에 도입된 기능, EC2보다 비쌀 수도 있음
+
+	* 전략 B
+
+		* 5분마다 한번씩 Trigger 시키기 (그냥 EC2 고려)
+
+	* Coldstart의 시간을 결정하는 가장 중요한 요소는 lambda 함수 코드 사이즈 (특히 라이브러리)
+
+	* 모든 API를 람다로 구현 해놓으면 1000개의 람다 컨테이너 한계가 올 수 도 있다.
+
+		* 『Reserved concurrency』  설정을 통해 함수 별로 컨테이너 갯수를 컨트롤 할 수 있다.
+
+* 버전관리와 Alias (별칭)
+
+	* 버전에 대해 별칭을 달 수 있다. (포인터 처럼 동작) 
+
+		* API 게이트 웨이에서 별칭을 호출하게끔 설정하고, 람다에선 별칭은 필요에 따라 매번 버전을 설정~
+
+	* 버전 하나에 대해 두개의 별칭을 다는게 저번에 배운 기법
+
+* 환경변수 설정
+
+	* 민감 정보를 숨기기 위해 람다에 종속된 환경변수 설정관리
+
+* Layers
+
+	* 복잡성이 높은 함수를 쓴다고 하면 각 함수를 모두 라이브러리를 업로드 해줘야하는 문제가 생기고 용량도 커진다.
+
+	* 똑같은 환경셋팅을 여러번하는 문제를 처리하기 위한게 Layers 하나의 레이어에 여러개의 함수가 연결하면 별도로 셋팅을 할 필요가 없다.
+
+* Step function
+
+	* 예를 들어, 업로드 , 저장, 사람이 관여하는 검수절차, 권한 오픈 등의 절차를 컨트롤, 꽤나 좋다! 시각화도 잘된다.
+
+	* 이런 플로우 컨트롤에 의한 비즈니스 로직을 앱으로 직접 짜려면 피곤하다.
+
+		* 각 서비스가 독립적이기 때문에 시각화도 가능하다.
+
+* EFS (elastic file system)
+
+	* 람다가 너무 독립적이기 때문에 필요한 파일 시스템
+
+	* 각 함수는 512mb의 FS을 할당받는다. 너무 작고 휘발되.
+
+	* 강제 stateless
+
+	* 이걸 이제 state 관리하기 위해 EFS가 존재한다. 같은 파일시스템을 각 함수에 제공
+
+	* 계산하고 파일을 쓰는 작업은 EC2에서 EFS에 진행하고 람다에선 읽는 구조로 하는걸 추천
+
+
+
+#### Lambda - (3) 실습
+
+* 버전 
+
+	* 새 버전을 발행해도 항상 :latest 로 명칭된다.
+
+	* 별칭은 버전에 대한 포인터 역할을 한다. << 중요!
+
+* 『환경변수』 설정
+
+	* 코드를 빠르게 재활용하려면 환경변수 관리는 필수
+
+	* {secret:song} // 이렇게 넣고
+
+```python 
+
+import os
+
+def lambda_function(e, c):
+
+	print(os.getenv("secret"))
+
+```
+
+	* 프린트하면 나오고, 환경변수 메뉴에서도 보이잖아.. 제대로 하려면 IAM role 통해서 접근 통제하거나 KMS를 통해서 암호화된 값을 쓴다.
+
+* Layers (계층) configure
+
+	* summary 함수가 깔고 앉은 환경 
+
+	* 20개의 함수에 대해 zip을 관리하는건 미쳤어 (.py + zip)
+
+	* 실제 사용 과정
+
+		* pip install requests 		// 이렇게 하면 기존 깔리는 경로에 설치
+
+		pip install -t requests * // 현재 경로에 인스톨
+
+이제 python 폴더에 들어가면 설치한 패키지가 보이고 이걸 ZIP 생성
+
+	* 업로드하고 실행환경 파이선 선택
+
+	* Add Layer
+
+		* AWS 계층, 사용자 지정계층(zip)
+
+		* import requests 하면 잘 동작하는걸 볼 수 있다.
+
+
+
+### Lambda - (4) EFS 실습
+
+* EFS (Elastic File System) 
+
+	* Summary: 람다의 사용성을 올리기 위해 업데이트된 기술
+
+		* Elastic Block Store는 EC2에 마운트되는거..
+
+	* 『액세스 포인트』 설정
+
+		* 별칭: Message
+
+		* Root DIR : /message
+
+		* 사용자 ID 및 그룹 : 1001, 권한 750
+
+	* 네트워크에서 서브넷(+SG)을 설정하면 접근통제 관리
+
+	* 권한 설정
+
+		* 람다(함수) → 권한 → 역할 → allow VPC, allow EFS role 
+
+		* 람다(함수) → VPC 및 SG 설정
+
+	* Config → File system → Add params
+
+		* EFS: first, 
+
+		* 액세스 지점: Message, 
+
+		* Mount: *mnt*msg
+
+	* 실제 사용 예제
+
+import fncntl
+
+with opern(MSG***FILE***PATH, 'r') as msg_file:
+
+msg.file.write(new_message+'\n')
+
+	* EC2에서도 EFS접근 가능하다. 람다는 쓰기에 적합하지 않으니 쓰기는 EC2에서
+
+
+
+## AWS***Step***Functions  
+
+* 개요
+
+	* 함수 arm 기준으로 스텝을 식별
+
+* 셋팅
+
+	* 디폴트 role이 있진 않아서 직접만들어야 한다.
+
+	* IAM → 이름: StepFunctionRole / 붙이는 정책 AWSLamdaRole: 모든 기능에 allow 'w'
+
+* 상태머신 (State Machine)
+
+	* 시각적으로 설계, 코드로 워크플로 작성(이걸로 실습, JSON 코딩)
+
+	* Type 별로 분기문 만들고 끝내는 플로우 예제
+
+		* 'Choice', 'Pass',
+
+```step
+
+"Choices": [
+
+{ variable: "$.type", "StringEquals": "first", "next": "lambdafunc1"},
+
+{ variable: "$.type", "StringEquals": "second", "next": "lambdafunc2"}
+
+]
+
+```
+
+
+
+```
+
+* "lambdafunc1": {
+
+  "Type": "Task",
+
+  "Resource: "arn.....",
+
+  "End": ture
+
+}  …… 중략
+
+```
+
+* 권한 설정 → 기존역할 (StepFunctionRole)
+
+* 상태 머신 시작 시키기
+
+	* { "type": first }
+
+	* 이제 플로우에서 함수의 흐름을 시각적으로 볼 수 있다.
+
+
+
+
+
+## AWS_DynamoDB  - (1) 개념
+
+* 등장배경
+
+	* 데이터를 받기전 스키마를 설정
+
+	* 데이터의 형태가 다양해 지면서 요구를 수용하기 어려움
+
+	* 요즘엔 데이터 베이스 때문에 투자받는다. 그래서 뭐든 저장한다. 나중에 필요해지면 그때 가공하면 된다. 
+
+	* 애널리틱스 앱을 가동시켜 정보를 수집한다.
+
+	* S3 → Redshift → AWS Athena → AWS SageMaker
+
+일단 저장하고 필요할때 꺼내서 분석
+
+	* 비슷한 서비스로는 MongoDB (그래서 그때 @Jun이 컴포지션 인덱스를 물어본거구만)
+
+* 특징
+
+	* PK로 찾을때 빠른 쿼리 속도, 확장유연, AutoScaling, RDS보다 쌈, S3가 제일싸고. 형식의 자유에 반비례하는 가격, JOIN  및 Transaction 불가능, 필터링은 가능하나 느리다. 
+
+	* 액세스 패턴을 잘 알때 이상적인 서비스(PK키 성능이 좋으니)
+
+		* 예를들어 PK로 해놓은 주문번호가 아니라 지역으로 찾아야한다면 느려지겠지
+
+* DB Components
+
+	* Table
+
+	* Item (≈ row) 컬럼 제약이 심하지 않다.
+
+	* Attribute (key/value 로 구성된 컬렉션) 자유롭게 쓰면 됨
+
+	* index 굉장히 중요하다.
+
+		* Partition Key
+
+		* Sort Key
+
+		* Primary Key (Partition + Sort)
+
+		* GSI(Global secondary Index) - 필터링 해야할 필요가 있는 항목에 설정하여 attribute 에서 사용하지 않도록 유도. 비유연성을 해소
+
+	* index에 지정한 컬럼들은 필수
+
+		* 예를 들어 오더아이디가 2개가 들어온다 치자.  똑같은 오더에 대해 반품 등 요청에 의해 똑같은 키가 사용되면 sort키를 활용한다. 두키의 결합은 UNIQ 해야함. "파티션에 들어가서 Sort key로 찾는다."
+
+
+
+### DynamoDB - (2) 실습
+
+* 테이블 생성 practice 
+
+	* 테이블 이름, 파티션 키:OrderID, 정렬 키:date
+
+	* 온디맨드, 프로비저닝 (프로비저닝은 미리 할당, 트래픽이 예상 가능할때 써야한다)
+
+	* 읽기용량, 쓰기용량(목표 사용률을 넘기면 확장) 보통 읽기를 AutoScailing
+
+	* 보조인덱스로 쓰고 싶은게 있으면 GSI 사용 (나중에 등록가능)
+
+	* CMK도 필요에 따라 아마존에 매니지를 넘기거나 직접 컨트롤 가능
+
+* 개요, 인덱스, 모니터링, 글로벌 테이블, 백업, 
+
+	* 모니터링 설정하려면 CloudWatch에 권한주기
+
+* 『항목생성』 방법은 두가지
+
+	* JSON 형식
+
+		* "s" → 스트링이란 뜻
+
+	* 양식형식도 가능
+
+* 탐색
+
+	* 『스캔』 탐색, 웹 GUI에서도 왠만한건 다된다. 『쿼리』
+
+	* 파이선으로 하게되면 boto3 패키지로 컨트롤
+
+		* 파이선으로 하게 되면 코드로 컨테이너 객체를 생성해내는 과정이 있어서 내용이 길어진다.
+
+* in Lambda by javascript
+
+	* at first Allow DB access to Function(arm)
+
+	* in Lam function
+
+```javascript
+
+const AWS = require('aws-sdk')
+
+const ddb = new AWS.DynamoDB.Dcounment({'region':'asis'})
+
+export.handler = asyn (event, context, callback) => {
+
+  const requireId = context.awsRequestId;
+
+}
+
+await createMessage(requireId).then(()=>{
+
+  callback(null, {
+
+    statusCode: 201,
+
+    body: '',
+
+    heders: {
+
+     ...}
+
+  });
+
+}).catch((err) =>{
+
+  console.log(err)
+
+})
+
+});
+
+// 오랜만에 하니까 기억난다.. export 를 통해 미들웨어 로직을 추가하는것 처럼 사용한다 람다에선 js를 promise를 처리하고 콜백을 실행하면 끝!
+
+function createMessage(reuqestId){
+
+  const params= {
+
+    Tablename: 'Oders',
+
+       Item: {
+
+         'OrderId': requestId,
+
+         'Date': '20110101'
+
+       }
+
+}
+
+return ddb.put(params).promise();
+
+```
+
+* in Lambda by Python
+
+	* pip install boto3
+
+	* 대충 이건 해봐서 잘 알아
+
+
+
+## AWS-SAM AWS Serverless Application Model
+
+* 개요
+
+	* 서버리스 개발을 위해 필요 한 기능들을 코드로 관리
+
+	* Lambda 콘솔에서 하던 일들을 CLI 환경에서 체계화
+
+	* 배포할때는 CLI, SAM Install, Docker 를 쓸 수도 있지만 자체 기능으로 배포!
+
+	* 서버리스 개발할때는 집중적으로 쓰게될 서비스
+
+* 실습
+
+	* sam init
+
+		* SELECT zip or Image
+
+		* zip을 이용하면 타입과 샘플 코드 선택
+
+		* 여기서 신경써야 할것은 template.yaml
+
+			* 람다 함수를 만드는 define 이 들어있음
+
+	* sam build
+
+		* 배포 가능한 형태로 소스를 빌드하고 Staging폴더 (여기선 /build )에 복사함.
+
+	* sam deploy --guided
+
+		* 필요한 롤등 모두 실행되고 생성되고 서비스 되는 부분까지 다 출력됨.
+
+
+
+
+
+_____________________________________________________________
+
+
+
+# 《PART 4》
+
+## CHAPTER 1 소개 및 설치
+
+### 챕터 개요 - (1) 코드를 통한 인프라 관리 (IaC)
+
+* 형상관리툴은 OS 내부에서 환경을 셋팅하기 위한게 태초의 의도였으나 기능이 확장되어서 인프라 관리 툴들과 겹치게 됨.
+
+* 테라폼은 인프라 문제를 가장 잘 해결할 수 있다.
+
+* IaC 목적
+
+	* a. infrastructure Templating
+
+b. Manage infra
+
+c. install app and one time config
+
+d. Deploy config and changes post install
+
+* 장점과 방법
+
+	* 휴먼 에러 방지, 재사용성, 일관성
+
+	* 버전관리 시스템과 융합 → 코드리뷰, 변경내용추적, 버전관리, 협업
+
+	* declarative config/ Imperative config
+
+		* 1) 원하는 상태를 정의
+
+		* 2) 순차적으로 명령어를 수행
+
+
+
+IaC Infrastructure as Code
+
+ARM Temlplate, Terraform, Pulumi, CludFormation
+
+
+
+형상관리 Configuration Management
+
+* 필요한 소프트웨어를 설치하고 설정으로 관리
+
+	* Ansible, Puppet, Chef, Salt Stack
+
+
+
+이미지 빌드
+
+* EC2, Virtual Box, Docker에서 사용가능한 머신 이미지를 빌드하는것
+
+* Packer, AWS EC2 Image builder(AMI 전용)
+
+
+
+설치
+
+사전 빌드된 걸 받는 설치방법
+
+받아서 직접 코드를 빌드하는 HomeBrew
+
+
+
+## CHAPTER 2 테라폼을  이용한 인프라 관리
+
+@Terraform_v1.2 [*Users/kth/document*학습자료 참고]
+
+* 워크스페이스간 동일한 패키지가 설치되는 문제를 컨트롤하기 위해 plugin-cache 를 설정 (중복을 피할 수 있음) ~/.terraform.c
+
+* 개요
+
+	* Write → Plan → Apply
+
+	* HCL 사용
+
+	* provider agnostic : 프로바이더로부터 의존적이지 않다. 이걸로 AWS 코드가 다른 프로바이더에 적용된단 말은 아니고 작성은 할 수 있단거지
+
+* Registry Doc 매일 보게 될 문서 (Provider가 제공하는 문법 + Module)
+
+	* Module 만약 한 EC2를 openVpn 서버로 사용하게 된다면 이 안에 SG, EBS 볼륨.. 다 들어가겠지 이걸 만들때마다 정의하면 피곤하니까 그룹핑해서 하나로 만들어놓음. 재사용높임
+
+	* 어떤 인풋과 아웃풋, 어떤 리소스를 가지는지 문서에서 확인가능
+
+* Terraform Document
+
+	* 여기도 자주 봐야해!‼ (configure lang)
+
+	* 협업을 하게된다면 PR을 할때 plan 결과를 코멘트를 달아주도록 설정 가능
+
+* Terraform Cloud (≈Atlantis)
+
+	* comment 대신 『Action Check』 뷰가 생김. 코멘트하고 승인하고 Apply 과정을 팀과 협력으로 가능 
+
+* 개념
+
+	* 워크스페이스: 인프라를 관리하기 위한 프로젝트의 단위
+
+		* 처음엔 하나 였다가 기업의 서비스가 복잡해지면 워크스페이스를 쪼개서 하게 된다. 
+
+		* 변경사항을 추적하기 위해 상태(state)를 관리 (e.g tfstatus)
+
+			* 워크스페이스가 상태의 단위
+
+### 실습
+
+	* lock.hcl 
+
+		* 디펜던시 락시키는 용도, 협업시 유용
+
+	* terraform.tfstate
+
+		* 로컬에서 관리되는 테라폼 상태파일
+
+		* 이걸 이용해 메인.tf 를 비교함
+
+	* resource
+
+		* data "local_file" "bar" // 리소를스 읽고
+
+		* data "" // 리소스를 출력한다. EOT 파일 입력 시작 끝
+
+	* aws set get~~caller~~identity
+
+		* 인증 설정 확인
+
+	* 《replaced》 상태 → 파괴하고 다시 생성됨
+
+		* 아무 생각없이 적용하면 큰일난다.
+
+		* 옛날에 kkj 님 생각나네 ㅋㅋ
+
+	* data "aws_vpcs" "this" {}  // 해당 리전의 vpc 리스트를 가져온다.
+
+output "vpcs" { value: data.aws_vpcs.this } // 출력
+
+	* 『terraform destroy』
+
+	* SUMMARY
+
+		* 정의 → 플랜 → 적용
+
+		* 플랜에서는 각 단계에서 나오는 diff 메시지와 destroy 항목을 볼 수 있다.
+
+
+---
+
+## HCL 기초문법
+
+* 가장 기초가 되는 구조
+
+```
+
+<BLOCK TYPE> "<BLOCK LABEL>" ... { // 레이블은 0개 이상이다. 각 블록마다 다르다.
+
+	 ARGUMENT = "VALUE"
+
+}
+
+```
+
+	* .tf  또는 .tf.json 형식으로 이름을 짓고 사용한다.
+
+	* tf 명령어는 cwd만 pasing 한다. (not nested 하게 실행되지 않는다.)
+
+	* 운영체제마다 개행이 다르다. LF / CR+LF
+
+* Directory, Modules
+
+	* root module / child module 로 구분할 수 있다.
+
+	* a*b/c 중 a가 b*c를 가져온다고 할때 a가 루트가 되고 b/c는 차일드가 된다.
+
+* Naming and comment
+
+	* 네이밍 규칙	: `알파뱃, 숫자(첫글자X), 언더스코어, 하이픈`
+
+	**주석 규칙		: `#text, //text, /**text*/`
+
+* Style Conventions
+
+	* 값이 너무 길땐 Args 를 논리적으로 묶고 공백 개행으로 Args를 구분한다.
+
+	* meta-args
+
+		* counter, foreach ⇒ Head 에 주석해서 설명
+
+		* lifecycle ⇒ tail 에 주석을 한다.
+
+	* 『tf fmt <target>』
+
+		* 컨벤션 포맷팅
+
+		* -diff : 변경 내용 출력
+
+	* BLCOK 의 종류
+
+		* tf, locals, Resource, Var, Module, Data, Output 
+
+
+
+### HCL, resource 와 data
+
+* 기본구조
+
+```terraform
+
+provider "aws" { resion = "north-east-2" }
+
+resource "aws_instance" "my_unbuntu"{
+
+  ami = "ami-id..."
+
+  instance_type = "t2.micro"
+
+
+
+  tags = {
+
+    Name = "FC-ubuntu:"
+
+  }
+
+}  // Create EC2 instance by ami
+
+```
+
+* 데이터 쿼리
+
+```terraform
+
+data "aws_ami" "ubntu" { //캐노니칼 직접 생산자 지정
+
+  most_recent = true
+
+  filter {
+
+    name ="name"
+
+    values = ["..... ubuntu-focal-20.04-amd64-server-*"]
+
+  }
+
+  owner = ["123133"] //canonical
+
+} 
+
+resource "aws_instance" "my_unbuntu"{ //가지고 온 정보 적용
+
+  ami = "data.aws_ami.ubuntu.ami_id"
+
+  instance_type = "t2.micro"
+
+}
+
+```
+
+### HCL Module
+
+* Github에 네트워크 등 서비스 분류별 리포지터리를 관리중
+
+* 각 레포지터리에도 사용방법이 소개중이지만, TF doc에도 동시에 업데이트 중
+
+* 로컬에서 임포트하든, 리포지터리를 쓰든 자유
+
+* 실습코드
+
+```terraform
+
+module "vpv" {
+
+  source  = "tedilabs/network/aws//modules/vpc"
+
+  version = "0.24.0"
+
+
+
+  name                  = "fastcampus"
+
+  cidr_block            = "10.0.0.0/16"
+
+}
+
+module "subnet_group__public" { name = "${module.vpc.name}-public" vpc_id = module.vpc.id 
+
+subnets = {
+
+    "${module.vpc.name}-public-001/az1" = {  ...  }
+
+    "${module.vpc.name}-public-002/az2" = {  ...  }
+
+}
+
+// 리터럴 처리를 할때만 "${}" 나머지는 그냥 자연스레 기술하면된다.
+
+module "route_table__public" { 
+
+  ipv4_routes = [{
+
+      cidr_block = "0.0.0.0/0"
+
+      gateway_id = module.vpc.internet_gateway_id
+
+    }]
+
+}
+
+// tedilabs-aws-network 리포지터리에 보면 실제로 어떻게 정의를 해놓았는지 볼 수 있다. 재사용 가능하게 인터페이스화 한것이 다르다. 나중에 배움
+
+```
+
+
+
+## **HCL VAR & INPUT & OUTPUT**
+
+* 변수를 통해 프로그래밍적으로 자원을 컨트롤 
+
+	* `variable "vpc_name" {} `
+
+* 변수 선언 기본값을 지정하지 않으면 apply에 입력받음.
+
+* 참조할땐 → `var.vpc_name`
+
+* Variable Definition Precedence (우선순위)
+
+	1. OS***Env. TF***VAR***[NAME] (e.g TF***VAR***vpc***name="test")
+
+	2. terraform.tfvars
+
+```.tfvars
+
+vpc_name="fastCampus"
+
+unset TF_VAR_vpc_name
+
+```
+
+	3. terraform.tfvars.json
+
+	4. '*.auto.tfvars' 
+
+	5. ~~var // -var~~file
+
+`tf apply ~~var~~file=test.tfvars`
+
+⇒  사용할 변수파일 지정
+
+`tf apply -var="vpc_name=fastcampus"`
+
+⇒ 직접 변수 입력
+
+* local value 
+
+	* 같은 코드가 중복으로 쓰일때 활용해라.
+
+```terraform
+
+locals {	//선언후
+
+  common_tags = {
+
+    Project = "net"
+
+    Owner = "me"
+
+  }
+
+} 
+
+resource {	// 체계적으로 관리
+
+ tags = local.common_tags
+
+}
+
+``` 
+
+
+
+* output
+
+	* description : 인프라의 문서화에 사용, 실질 작용 X
+
+```terraform
+
+output "vpc_name" { //참조
+
+  value = module.vpc.cidr_block
+
+}
+
+
+
+output "vpc_name" { //통째로 출력 가능
+
+  value = module.vpc
+
+}
+
+
+
+output "suibnet_groups" { //묶어서 출력
+
+  value = {
+
+    pub = module.subnet_pub
+
+    pub = module.subnet_pri
+
+  }
+
+}
+
+```
+
+
+
+## HCL - count, for_each
+
+* COUNT - resource, data, module 대상으로 사용가능
+
+```terraform
+
+resource "iam-user" "count" {
+
+  count = 10 //meta arg. 제일 먼저 쓰는게 컨벤션
+
+  name = "count-user-${count.index}
+
+}
+
+// output에서 활용할 수도 있다.
+
+output { // *은 전체유저를 칭함
+
+  value = aws_iam_user.count.*.arn
+
+}
+
+```
+
+
+
+* for_each
+
+```terraform
+
+for_each = toset ([ //형변환 함수 toset
+
+  "user-1", "user-2"
+
+]) 
+
+// 이걸 순회하고 있을때 'key' 'value 키워드를 for_each가 사용중인 인자를 호출가능
+
+output {
+
+  values = values(user.for_each_set).*.arn //count와 동일함.
+
+  values = keys(...*...) //키값만 불러옴
+
+}
+
+resource {
+
+  for_each = { // alice가 키, 오른쪽이 밸류 
+
+    alice = { level= "low", manager="g1"}
+
+  }
+
+}
+
+``` 
+
+* 주의사항
+
+	* `count` 는 리스트 형식(1~~2-3-4~~5)으로 데이터를 관리한다.
+
+		* 수시로 리스트가 변하니 관리하기 까다로움 
+
+	* `for_each`는 키 밸류 형식으로 관리함. (파이선의 SET을 생각해라, 중복키 안됨)
+
+* tf state list
+
+	* 상태값 저장해놓은거 조회
+
+
+
+### HCL - conditional expression
+
+```terraform
+
+locals { //기본적인 사용법
+
+  meg = var.is_john ? "hi john" : "hello"
+
+}
+
+resoruce "aws_vpc" "this" { 
+
+  cidr_block = "10.0.0.0/16" 
+
+}
+
+resource "aws_internet_gw" "this" { // 1일 때만 GW 생성
+
+  count = var.internet_gw_enalbed ? 1 : 0 
+
+  
+
+  vpc_id = aws_vpc.this.id
+
+}
+
+``` 
+
+
+
+### HCL - for expression
+
+```terraform
+
+//리스트의 경우
+
+[for i , v in var.list : "${i} is ${v}"]
+
+//맵의 경우
+
+{ for s in var.list s => upper(s) }
+
+// 익스프레스 할때 Key => Value(출력) 의 구조로 약속해놓았다.
+
+// s = ["a", "b", "c"], 출력: "a"="A","b"="B"
+
+
+
+// 필터링의 경우
+
+for s in var.list : upper(s) if s != ""]
+
+// var.list = ["a", "", "c"] 결과 "a" "c"
+
+
+
+//실제 사용
+
+variable "users" {
+
+  type = list(any)
+
+}
+
+resource "aws_iam_user" "this" {
+
+  for user in var.users {
+
+  user.name => user 			//user.name 은 키, user는 밸류
+
+  } 
+
+  user = each.key
+
+  groups = each.value.is_dev ? [aws_iam_group.dev.name, aws_iam_group.employee.name] : ,[aws_iam_group.employee.name]
+
+}
+
+```  
+
+
+
+### HCL - Backend (stage Storage)
+
+* Local State / Remote State
+
+* Backend(State Storage)의 종류는 다양. 로컬, 리모트(Terraform Cloud), S3(with/without DynamoDB) , 쿠버네티스, 콘솔
+
+	* Locking 제공 여부가 중요하다. 여러 작업자간 작업충돌을 방지해야함.
+
+	* 동시에 작업을 하더라도 한명에게만 실행권한을 가지도록 제어처리.
+
+	* DynamoDB로 하면 락지원
+
+* S3
+
+	* 백엔드 설정을 해놓고 init 하면 로컬 스테이트의 copy 여부를 묻는다.
+
+* 클라우드
+
+	* ~/.terraformrc
+
+	* tf login
+
+	* local execute 하도록 setting 변경 (클라우드)
+
+
+
+### HCL - 상태관리 『state』
+
+* list
+
+	* 워크스페이스에서 관리중인 리소스가 나온다. 클라우드 저장소를 쓰면 느림
+
+* mv
+
+	* 테라폼 코드를 리팩토링 할때 자주 씀.
+
+	* apply시 라벨이 바뀌면 파괴 후 다시 생성한다. 이건 장애 원인이기 때문에
+
+```shell
+
+tf state mv 'aws_iam_group.dev' 'aws_iam_gorup.this["dev"]'
+
+Succesfuly moved 1 object(s).
+
+```
+
+* rm
+
+	* 일단 만들었지만 테라폼으로 더 이상 관리를 원하지 않을때 사용, 예를 들어 권한관리를 다른 super_acl을 사용하고 싶을때 쓰는 명령어
+
+	* 코드를 바로 지우면 apply할때 해당 리소스를 destroy함
+
+`terrafirn state rm 'aws***iam***user_policy,dev["alice"]'`
+
+하면 state 에서 해당 유저가 빠지고 지운 코드를 apply 해도 destroy 가 이뤄지지 않음. 
+
+* pull
+
+	* work space 를 쪼개는 작업을 할때 필요함. 아웃풋을 저장!
+
+` tf pull > a.tfstate `
+
+* push
+
+	* 상태를 덮어쓰는 것이기 때문에 굉장히 주의해서 사용
+
+* show : 특정 리소의 상태를 조회
+
+* replace-provider : Provider가 큰 변경이 있을떄 사용
+
+
+
+### HCL - 특정 리소스 강제 변경 
+
+* taint ( mark fuction )
+
+`tf taint [PATH]`
+
+> Resource [PATH] has been marked as tainted
+
+> [PATH] is tainted, so must be replaced
+
+* 교체에 따라 이걸 의존하고 있는 자원들 예를 들어 이 경우는 라우팅테이블이겠지. 도 교체 되는걸 알아야함.
+
+* untaint
+
+	*  canceling taint 
+
+* replace
+
+`tf apply replace=[PATH]`
+
+	* taint가 좋다. 여러개를 할때는
+
+
+
+### HCL - 워크스페이스관리
+
+* 코드프로젝트 / tf 스페이스 "a" "b" "c"
+
+	* 스테이징 단계에 따라 사용하기 전략
+
+	* dev, stg, prd 를 복붙으로 관리하면 부담증가
+
+		* 코드와 데이터를 분리해라! ⇒ 즉 데이터는 vars로
+
+	* kr, jp, us 를 복붙으로 관리하면 부담증가
+
+* tf workspace -h
+
+	* list → 별표가 cw
+
+	* show → 현재 사용중인 워크스페이스 확인
+
+	* new → 생성
+
+	* delete
+
+	* select 사용 중인 워크스페이스 변경
+
+* 이 기능을 쓰기 시작하면 『terraform.tfstate.d』 에서 각 워크 스페이스에 따른 상태를 관리하기 시작함
+
+```shell
+
+tf select dev
+
+tf terraform apply -var-file=dev.tfvars
+
+// stg, prod 각각 tfvars를 구성하면 같은 코드로 다른 인프라를 구성할 수 있다.
+
+// 각각 다른 tf워크스페이스를 가지는것은 물론 각각 AWS에 자원들이 생성되는걸 볼 수 있다.
+
+```
+
+* 테라폼 클라우드를 쓸때는 상태값이 조금 다르게 동작한다. (주의! 문서 읽어보고 쓰면됨)
+
+
+
+### 테라폼 클라우드, 아틀란티스
+
+* 『Registry』 
+
+	* 모두가 저장할 수 있는 Public 저장소
+
+	* 내가 설정한 vcs를 레폼 모듈로 등록할 수 있다.
+
+	* 깃헙의 PR을 할때 깃헙 action 체크를 통해 플랜결과를 확인할 수 있다.
+
+* 『Workspaces』
+
+	* 조직 전용 저장소
+
+* 요금제
+
+	* 프리로도 5명까지, 협동툴, 무제한용량, 유료버전 트라얼 1달
+
+	* 팀
+
+		* 팀, 롤 매니지먼트
+
+	* 팀 앤 거버너
+
+		* 회사의 정책 적용
+
+		* workspace estimation
+
+	* 비지니스
+
+		* Agents, SSO
+
+* Execution Mode
+
+	* 어디에서 실행하느냐의 이슈
+
+	* local → 상태저장만 클라우드가 함
+
+	* remote → 테라아폼 클라우드 인프라에 tf runner 에게 작업을 시킴
+
+		* 만약 인트라넷 유저라면 리모트를 쓰기가 힘들다. 클라우드에 접근을 해야하니
+
+		* 장점
+
+			* apply 유무, 버전, 워킹 디렉토리
+
+			* Variable TAB에서 변수를 웹에서 등록해서 관리 private값은 숨기기 가능
+
+			* 환경변수 설정가능
+
+		* 스트리밍 방식으로 결과를 내려준다.
+
+* Run trigger
+
+	* 워크스페이스 간 실행순서 a > b > d > c 이런 시퀀스를 보장하고 싶을때 어플라이를 해줄 필요가 있다면 이걸 쓰면 쉽게 가능
+
+* 아틀란티스
+
+	* VCS 에서 PR할때 워크플로우에서 atlantis plan 코멘트로 플랜을 하고 atlantis apply 라고 코멘트에 써서 적용하고 코웍을 편하게
+
+
+
+### Terraform 모듈 작성법
+
+* 모듈의 위치는 내가 정의한것일수도 정의된 표준 모델 일수도 있다.
+
+* 기본 원칙은 Clear organization & DRY(don't repeat yourself)
+
+	* 리소스간 명확히 구분하고 캡슐화를 통해 분리해라
+
+	* 다시 정의하지 마라. 같은 리소스를 두번 이상 쓰지마라.
+
+	* 모듈의 단위의 근거
+
+		* 함께 생성할 인프라를 하나의 모듈로
+
+		* 권한 범위 내에서 정의
+
+		* 인프라의 생명 주기에 따라 분리
+
+* tree
+
+	* 구성 `readme.md mian.tf outputs.tf variables.tf versions.tf` 
+
+	* account alias, aws id가 기억하기 힘든 숫자라서 별도로 부여
+
+* 모듈의 핵심
+
+* 재사용 가능성을 높히려면 output이 중요하다.
+
+* source로 로컬 모듈을 들고와도 외부 링크를 써도 된다.
+
+* 모듈이 설정한 아웃풋만 쓸 수 있따.
+
+* 모듈을 래핑하는 모듈을 작성할 수 있다. 대신 이렇게 쓰면 점점 문제를 추적하기 힘들다.
+
+
+
+### Terraform 리모트 스테이트 사용
+
+* 하시코프에서 만든 '리모트 스테이트' 프로바이더
+
+* 복수의 워크스페이스가 생기고 Ws마다 의존성이 생기게 된다. 그걸 처리하기 위한 remote_state (상태파일을 참고)
+
+* 의존성을 설정할 main.tf 에서 설정한다.
+
+```terraform
+
+data "terraform_remote_state" "network" {
+
+  backend = "local"
+
+  
+
+  config = {
+
+    path = ${path.module}/../network/terraform.tfstate"
+
+  }
+
+}
+
+``` 
+
+
+
+* 참조를 위한 outputs 설정
+
+```terraform
+
+locals { 	//일단 로컬 이름로 레퍼런스 해주고
+
+  vpc_name      = data.terraform_remote_state.network.outputs.vpc_name
+
+  subnet_groups = data.terraform_remote_state.network.outputs.subnet_groups
+
+} 
+
+local.subnet_groups["public"].ids[0]
+
+// 실제로 값을 쓸땐 로컬로 쓰면 깔끔해진다.
+
+``` 
+
+
+
+### Terraform 워크스페이스 디렉토리 전략
+
+* 코드는 길어지고 협업은 해야하고 전략을 짜야한다. // 예제 파일은 apply는 안됨
+
+* 각 리소스들을 종류별로 .tf를 생성
+
+* 중요한건 variable.tf → config.yaml 참조
+
+* terraform.tf (백엔드 설정)
+
+```
+
+context = yamldecode(file(var.config_file).context  // yaml을 읽고 값을 들고 온다.
+
+config = yamldecode(templatefile(....)
+
+```
+
+* versions.tf config.yaml
+
+* remote-state.tf
+
+	* 다양한 워크스페이스를 쓸떄 중요해! foreach를 통해 yaml에서 정의한 리모트 정보들을 한번에 로딩한다.
+
+* 테라폼 버전을 필요에 따라 바꿀 필요가 있다. 이를 위한 'TF switch' , 'TF env'
+
+	* 설치를 하면 .version 을 읽고 알아서 해줌. 
+
+
+
+### Terraform 프로비저너와 EC2 userdata 속성
+
+소스:  `*hashicorp*aws`
+
+EC2 유저 데이터, 부팅시점에 사용자 생성 설치 등등 AMI에서 사용함.
+
+```bash
+
+user_data = <<EOT 		// multi-line stream, 히어 도큐먼트!
+
+#!/bin/bash
+
+sudo apt-get update
+
+sudo apt-get install -y nginx
+
+EOT
+
+```
+
+* 프로비저너 → 첫 리소스 생성 시점에 실행 
+
+* file : 로컬에서 리모트 파일복사
+
+* local_exec  로컬피시에서 명령어 수행
+
+* remote_exec 리모트 머신에서 명령어 수행
+
+	* ssh, win_rm
+
+```terraform
+
+ provisioner "remote-exec" {
+
+    inline = [
+
+      "sudo apt-get update",
+
+	"sudo apt-get install -y nginx",]
+
+    connection { ssh 정보}
+
+}
+
+``` 
+
+*  apply 시 provisioner를 사용했을땐 터미널에 아웃풋을 출력해준다 (AMI 에서 제공하는거 쓰면 안보임) 
+
+* 주의사항 
+
+	* 유저데이터 값은 처음 인스턴스를 생성할때에 사용한다.
+
+	* 따라서 값을 수정하면 apply 시 replace 되버린다.
+
+	* `self.public_ip` // 부모 리소스를 가르킴
+
+* 트리키한 팁
+
+	* null resource
+
+		* trigger 안에 filemd5 로 해시값을 생성하는데 할당한 값이 바뀌면 리플레이스 대상이 된다.
+
+		* 이제 트리거를 일으키고 apply하면
+
+		* null resource 가 다시 적용한다.
+
+		* 많이 쓰겠는데 이거?
+
+
+
+### AWS VPC _ OPEN VPN 구성
+
+1. 네트워크 tf 작성 - vpc, subnet
+
+2. EC2 tf 작성 - public →  openvpn, private → ec2
+
+	1. 사용자가 오픈VPN접속하고 ec2 를 사용하는 것이 목표
+
+	2. SG엔 ingress 1194를 추가해준다.
+
+```terraform
+
+locals {
+
+  // 첫번째 인자로 유저데이터 모듈
+
+  // 두번째 인자(컨텐스트)로는 파일에서 사용할 변수를 줬다.
+
+  openvpn_userdata = templatefile("${path.module}/files.openvpn-userdata.sh, 
+
+    {
+
+      vpc_cidr = local.vpc.cidr_block
+
+      public_ip = aws_eip.openvpn.public_ip
+
+    }
+
+  }
+
+``` 
+
+3. 이제 userdata.sh를 보면 뭘하는지 볼 수 있다. 
+
+// 강사는 openvpn with LDAP 인증 컨테이너를 많이 썼다. 
+
+// 1194 포트로 도커를 서비스 하고 "${public_ip}" 이렇게 변수를 사용했다. 
+
+*/ ${split("*",  vpc_cidr)[0] 이렇게 테라폼 내장 함수도 사용가능
+
+```terraform
+
+resource "aws_eip_association" "openvpn" {
+
+  instance_id =  [aws_instance.openvpn.id] 
+
+  allocation_id =  [aws.eip.openvpn.id] 
+
+} // 퍼블릭 아이피로 빌드하면 매번 아이피가 바뀌지만 aws.eip를 쓰면 매번 바뀌지 않고 계속 사용가능(현업에선 꼭 이걸로 하길 바람!)
+
+``` 
+
+
+
+4. 생성하고 public ec2 접속!
+
+`cat var*log/cloud~~int~~output.log /* 생성직후엔 도커를 설치하는 서버 모습 을 볼 수 있다.`
+
+5. sh 로 생성된 vpn config 파일을 실행하면 Tunnelblick 앱에서 연결을 해준다. 
+
+	1. 이제 openvpn 으로 프라이빗 망에 연결
+
+	2. 프라이빗 DNS 에서만 된다. `ip~~10-222-2~~6.ap.. internal`  이런 주소는 오직 내부망에서만 쿼리
+
+
+
+# Packer v1.8 톺아보기!
+
+* 패커는 머신 이미지를 코드로 생성하도록 도와줌. ≈ AWS AMI Builder 도 비슷한 역할을 한다. 다만 플랫폼 종속적
+
+* Warmup 시간이 중요한 팩터인데 AMI는 시간이 짧다.
+
+* 프로비전닝 기반으로 이 배포를 하면 Warmup 시간이 길어진다.
+
+* Templates
+
+	* HCL Template: 처음엔 JSON을 쓰다가 점점 HCL이 커져서 쓰게됨. (JSON Template)
+
+* 실제 사용 과정
+
+```shell
+
+vi main.pkr.hcl
+
+packer init .
+
+packer build .
+
+```
+
+
+
+* EC2 생성 > Provisioning > STOP > AMI snapshot
+
+	* 이 과정에서 임시 SG, SSH key페어도 생성한다. 이걸로 프로비저닝하는데 사용.
+
+* 끝나면 Terminate - EC2, Temporary SG
+
+* 패커는 상태관리를 하지 않는다. 삭제는 수동으로 한다.  
+
+* build, source는 테라폼에 없는 블럭
+
+
+
+### Packer Builder
+
+* 빌더를 정의한다는 것은 어떤 머신의 이미지를 만들건지 디파인하는것. AWS Azure 등등..
+
+* 테스트나 유틸리티 목적으로 사용하는 NULL 빌드
+
+	* `communicator = "none"` 
+
+	* 프로비저닝 할때 쓰는 통신방식 SSH, WINRM을 지정
+
+* 빌드할때 소스의 실행순서는 보장되지 않는다.
+
+	* build → name. null 이름에 pre-fix로 붙는다.
+
+* source 키워드는 extend 역할을 한다. 
+
+	* name 값을 주면 alias 보다 name 우선시 된다.
+
+	* overwrite는 지원하지 않는다.
+
+* provisioner 개별적인 스크립트 실행
+
+* post-processor 
+
+	* 빌드 후 후처리를 위한 모듈 → 이쪽은 실행순서를 보장한다.
+
+
+
+### 선택적 빌드 (only, except)
+
+```
+
+packer build -only="null.two"
+
+packer build -only="null.two", "null.one"
+
+packer build -except="null.two", "null.one"
+
+```
+
+**그롭 명령어가 먹는다. -only="**.one"
+
+
+
+### Packer's Provisioner
+
+* Shell, File, Window, Breakpoint (사용자가 확인하기전까지 멈춤)
+
+* Ansile, Chef, Puppet 등 CM도구도 지원
+
+* 프로비저너 리소스는 실행순서가 보증된다.
+
+	* tmp 폴더는 모든 유저가 접근가능
+
+
+
+### DataSource
+
+: 비교적 최근에 생긴 거라 지원하는 프로바이더가 적음
+
+* AWS
+
+	* Parameter Store
+
+	* AMI
+
+```packer
+
+data "amazon-ami" "ubuntu" {} // 이렇게 사전에 정의해놓고
+
+source "amazon-ebs" "" {
+
+ source_ami = data.amazon-ami
+
+} // 이렇게 해놓으면 ami 코드를 source 할때마다 적는걸 방지할 수 있다.
+
+```
+
+	* Secret Manager: 매니저에서 사용할 값을 정해놓고 프로바이더로 호출
+
+
+
+### Post~~processor (후처리기) (~~s 복수형도 별도로 존재한다)
+
+후처리기 플러그인
+
+1. CheckSum
+
+2. Compress
+
+3. Manifest Post-Processor (빌드를 한 사실에 대해 명세파일)
+
+4. Local Shell Post Processor (맘에 드는 프로세서가 없는 경우 직접 작성한 쉘을 실행)
+
+
+
+
+
+issue - AMI 과정을 만드는 과정이 긴데 디버깅을 하려면 힘들다. 그래서 지원하는 방법들
+
+1.  브레이크포인트
+
+```
+
+build { // 이렇게 하면 빌드 중 멈춘다. 터미널로 들어가서 커맨드를 내리면서 문제르 분석하면 된다.
+
+  provisioner "breakpint"{
+
+    disable = false
+
+    note = "디버깅"
+
+  }
+
+}
+
+```
+
+ 2. debug
+
+`packer build -debug .`
+
+	* 이렇게 실행하면 한단계식 실행한다. 
+
+	* 여기서 실행 중에 pem파일이 생성되는게 보이는데 이 키로 해당 인스턴스에 접속하면 된다.
+
+	* 보다가 죽었다! 하면 이제 쉘로 들어가서 syslog 든 뭐든 보면 된다.
+
+	* 중간에 실행하다가 CTL+C를 하면 프로비전을 취소해준다.
+
+AMI에서
+
+AMI를
+
+
+
+### Packer CLI 
+
+* `packer fmt` 	코딩컨벤션 포맷팅
+
+* `packer inspect` 	해당 템플릿이 어떤 구조로 되어있는지 청사진을 보여줌
+
+* `packer validate .` 	코드 문법 체크
+
+ 
+
+
+
+## Packer 마지막 실습 OpenVPN과 Grafana 구성
+
+* 필수는 아니지만 현업처럼 버전 관리를 위해 tags 구성
+
+```bash
+
+cloud-init status --wait // 사용자 명령이 끝날때까지 대기
+
+docker run
+
+	--restart unless-stopped // 이런식으로 쓰면 EC2가 재시작해도 항상 실행을 유지 AMI 를 만들어도 자동으로 실행됨.
+
+```
+
+
+
+```diff
++ 168.254.169.254
+```
+ → EC2 meta data Server. 여기에 쿼리하면 다 줌.
+
+
+`most_recent = true` → 그룹으로 끌고와서 가장 최근것을 사용
+
+* openvpn 을 연결하고 나면 프라이빗 대역에 대한 dns 쿼리도 가능하다. (인터넷의 루트도메인의 포맷과 다른 주소)
+
+* openvpn, Grafana 이미지를 만들고 tf로 네트워크 설정하고 인스턴스 올리고 실제로  vpn연결해서 서비스 사용해보고 그까지 했다!
+
+
+
+## Ansible ver  6.0.0a1 PRE-RELEASE
+
+1. 기본만 다루게 될것임 - 인벤토리, 애드훅, 플레이북, 모듈, 변수, 조건문 반복문, 임무, 실습
+
+2. 훨씬 다양한 고급기능이 있으므로 공부할 게 많음
+
+
+
+### 왜 서버 형상관리 인가?
+
+* 운영체제에 필요한 소프트웨어 설치하고 설정으로 관리한는것. Configuration as Code
+
+	* Code로 되면 GitOPS 이념 이행이 가능
+
+	* 비슷한 툴 puppet, saltSTACK, Chef
+
+	* Agentless 하게 동작 SSH로 통신
+
+* 유즈케이스
+
+	* 주요 기능으로 추천: Configuration Manage, Security Compliance 
+
+	* 보조 기능으로서 사용을 추천 CD, Application Deployment, Provisioning
+
+
+
+### 왜 앤서블인가?
+
+* 쉘로 하는것을 멱등성을 지원하기 위해선 많은 조건문이 필요해진다. 
+
+(각 명령어 실행전에 실행조건 확인하고 그에 따라 명령을 시행하는 한마디로 예외처리가 멱등성을 지원)
+
+* 앤서블로 하면 YAML 문법으로도 리눅스서버를 컨트롤 할 수 있다. 멱등성을 보장하기에 여러번 실행해도 된다. 
+
+* 여러 서버 대상으로 동시실행 할수 있다. 무엇보다 버전관리가 되는건 GitOPS 가능 
+
+
+
+###  INVENTORY
+
+* 타겟하는 서버 즉 호스트를 관리하는 파일. 그룹기능을 지원한다. 한 호스트가 여러 호스트에 속할 수도 있다. 서버의 속성, 네트워크 영역 또는 스테이징 단계로도 구분할 수도 있다.
+
+* Static Inventory, Dynamic Inventory 두가지가 존재. 클라우드 상에선 정보가 계속 변하기 때문에 Dynamic Inv가 필요하나 오늘은 정적 인벤만 사용
+
+* `name.inv` → 확장자는 컨벤션, IP와 도메인 모두 지원함
+
+```amazon.inv
+
+simple.inv
+
+[amazon]
+
+1.1.1.1
+
+2.2.2.2
+
+[ubuntu]
+
+ec2-3-24-...
+
+ec2-3-24-...
+
+// all이라는 default 그룹이 존재한다.
+
+```
+
+
+
+```alias.inv
+
+amazon1 anssible_host=1.1.1.1 // 이렇게 cn을 설정할 수 있다.
+
+```
+
+
+
+```vars.inv
+
+amazon1 anssible_host=1.1.1.1 ansible_user-ubuntu
+
+// SSH로 통신을 한다고 했는데 계정이 EC2-USER, ubuntu잖아 기본이 
+
+// 이 옵션을 안주면 맥의 사용자 아이디로 접속을 시도한다. 그래서 입력해야함.
+
+[linux:children]
+
+amazon
+
+ubuntu
+
+// 이렇게 하위 그룹을 설정하면 amazon과 ubuntu 를 가지게 된다.
+
+```
+
+
+
+
+
+### Ad-hoc Command
+
+* 플레이북 대신 바로 명령을 전달하는 방법
+
+`ansible host-pattern ~~m module [~~a 'module option'] [-i inventory] ` 	
+
+→ 이게 기본적인 사용법
+
+`ansible -i amazon.inv -m ping all ~~u ec2~~user`
+
+→ 쉘과 달리 순서가 중요하지가 않다. 이렇게 바로 접근을 위해선 ssh에이전트를 설치해놓거나  ssh-add ~~K [name.pem] 명령어를 통해 pem 교환을 해놔야한다. 또는 접속시 --private~~key [name.pem] 을 사용한다.
+
+* 여기서 사용한 `-m ping`은 ICMP Ping과 다르다. 대상호스트에 연결 후 파이선 사용가능여부를 확인하는 모듈이다.
+
+
+
+* Control node, Managed Node Concept
+
+	* 실제로 명령을 실행하는 맥북이 컨트롤 노드
+
+	* Managed Node는 명령이 실행되는 인스턴스를 칭함
+
+
+
+```bash
+
+ansible localhost -m setup >> ansible_facts // setup은 Facts를 수집하는 모듈이다. 굉장히 많은 정보가 수집된다. ansible_facts // 이 파일에 접근해서 참조가능`
+
+--become // 사용자 전환을 위한 옵션(DF. ROOT)
+
+```
+
+// 실습내용 apt 명령어를 전달해 git설치하고 지우고 했음 
+
+
+
+### Playbook (yaml)
+
+ `syntax.yaml`
+
+* 플레이가 모여있는 문서고 절차를 가지고 실행됨.
+
+	* Play: 작업 목록(tasks), 특정 호스트 목록에 대해 수행
+
+	* Task: 수행의 단위, 애드훅 하나하나가 작업이다.
+
+	* Module: 핑 모듈, 셋업 모듈, 호출하게 되는 하나의 함수를 뜻함
+
+	* Collection: 비슷한 모듈을 묶은 것
+
+```install-nginx.yaml 
+
+apt, service 모듈을 이용해 nginx를 설치 실행
+
+command, yum, service 이렇게 서비스 설치 후 실행 
+
+
+
+//사용방법
+
+$ asible-playbook -i inventory install-nginx.yaml
+
+```
+
+
+
+* 실행내용
+
+`changed`  → 변경사항이 있는걸 말한다.
+
+`ok`  →  이미 실행됐다. 괜찮다!
+
+* 리포지터리 활성화 하기 위해 썼던 command는 계속 실행되기 때문에 멱등성을 보장못한다. 별도로 처리하면 가능 →  :TODO 나중에 공부할 부분
+
+
+
+### Module
+
+: 사람들이 만들어놓은 많은 모듈이 존재한다.
+
+****Collection index*
+
+	* ansible.builtin - 효과적인 사용을 위한 기본. 이것만 봐도 절반은 하겠다!
+
+* `"name=fastcampus shell=bin*bash"` 	/* 스페이스를 구분자로 속성을 줄 수도 있다.
+
+****linefile 포맷*
+
+```yaml
+
+name:*  //resolve.conf에서 찾고 없으면 추가해라라는 뜻
+
+  path: /etc/resolve.conf
+
+  line: 'nameserver 8.8.8.8' 
+
+// 이렇게 키밸류 형식으로 속성을 줄수도
+
+```
+
+
+
+****Freeform* //  프리폼은 이렇게 기술함.
+
+`command : echo "hello world"`
+
+****Ansible_POSIX* 
+
+	* 리눅스의 rsync 를 앤서블에서 쓸 수 있게 해주는 모듈
+
+```yaml
+
+name:
+
+syncronize:
+
+  src: file/html/ 		// 로컬서버 설정
+
+  dest: var/www/html		// 목표서버 설정
+
+  checksum: true
+
+  archieve: true
+
+  recursive: true
+
+  delete: true
+
+```
+
+
+
+## Handler
+
+* 왜 핸들러가 필요한가? 핸들러는 이벤트 기반으로 동작하는 태스크이므로 작업간 종속성을 처리할때 활용할 수 있다.
+
+* 특정 태스크가 실행될때 이벤트 publish 하면 구독중인 태스크가 실행됨. 
+
+	* 실습에선 configure 파일을 수정하는 태스크가 실행될때 마지막에 재시작 Notify 퍼블리시 했다.
+
+* 주의 사항, 
+
+	* 이벤트를 여러번 일으켜도 동일 핸들러 는 한번만 실행된다.
+
+	* 모든 핸들러는 플레이 내의 모든 작업이 끝난 후 실행된다.
+
+	* 핸들러는 이벤트 호출 순서에 따라 실행되는게 아니라 핸들러 정의 순서에 따라 실행된다. 
+
+* 예제
+
+```yaml
+
+tasks:
+
+  - name: Install nginx
+
+   apt: (중략)
+
+  notify: 모듈로 이벤트를 만듬. 
+
+   - Start Nginx
+
+handler:
+
+  - name: Restart Nginx
+
+  service:
+
+    name: nginx
+
+    state: started
+
+```
+
+
+
+### Variable
+
+: 파이선 기반이기 때문에 파이선의 예약어 사용금지. `async labda` 또 네이밍룰도 마찬가지
+
+템플릿 언어로는 `Jinja2`를 사용한다. 총 22가지가 있다.  우선 순위는 DOC 확인
+
+```vars.inv
+
+user_name=posit0 user_comment="from inv:"
+
+```
+
+
+
+`ansible-playbook -i vars.inv playbook.yaml`	//  inv를 참조해 플레이북 실행
+
+
+
+플레이북에도 직접 변수 지정 가능.
+
+```playbook.yaml
+
+vars:
+
+  user_name: "posix0"
+
+```
+
+
+
+파일에서도 변수지정 가능 (vars_files 모듈)
+
+```vars_files
+
+user_name: "posix0" \n comment: "my comment"
+
+```
+
+ 
+
+`ansible-playbook -i playbook.yaml`  이렇게 실행
+
+
+
+커맨드라인으로 주는법
+
+`ansible-playbook -i playbook.yaml -e "user***comment=hello user***shell=*bin*sh"`
+
+→ 우선 순위 제일 높음
+
+
+
+이렇게 파일로 넘겨줄수도 있음.
+
+`ansible-playbook -i playbook.yaml -e "@vars.yaml"`  
+
+
+
+## Loop 반복문 사용법
+
+```with.yaml
+
+With <lookup> // lookup을 찾아서 속한 모듈을 3번을 실행함
+
+group: "Create groups"
+
+  name: "{{item}}"
+
+  status: "present"
+
+with_items:
+
+- backend 
+
+- frontend
+
+- devops	// {{item}}은 각각 with_items들을 가르킨다. group 모듈이 3번 호출됐다!
+
+```
+
+
+
+**loop** // 이게 권장되는 문법
+
+```loop.yaml
+
+group: "Create a user"
+
+  name: "{{item}}"
+
+  status: "present"
+
+loop:
+
+- me 
+
+- and
+
+- u	// item이 각각 이 아이템들을 가르킨다. group 모듈이 3번 호출됐다!
+
+
+
+vars:
+
+  users:
+
+    -me
+
+    -and 		// 이렇게 정의를 해놓고
+
+loop: "{{users}}:" 이렇게 호출
+
+```
+
+
+
+키밸류 형식으로 루프를 돌고 싶을땐
+
+
+
+```dict.yaml
+
+loop: "{{ tags | dict2item }}" 	// $$ exp | func 진자2의 함수 구현
+
+vars:
+
+  users:
+
+    - name : john
+
+    - shell: /bin/bash  //이렇게 key, value 정의를 해놓고
+
+user:		// 실행. 하여 딕셔너리 이터레이터
+
+  name: "{{item.name}}
+
+  shell: "{{item.shell}}
+
+  loop: "{{users}}"
+
+```
+
+****conclusion 이것 말고도 다양한 루프 사용방법이 있음* 이걸로 모잘라면 API 문서 참고
+
+
+
+### Conditional 
+
+: 조건문은 운영체제에 따라 다른 것을 하고 싶을때 주로 사용
+
+**when**
+
+```when.yaml
+
+loop: {{users}}
+
+when : item.enabled and (ansible_facts["distribution"] == "Amazon")
+
+  // 팩츠가 아마존일때만 실행된다.
+
+
+
+loop: [0,192,55,99]
+
+when: // 이렇게 수직으로 리스트를 선언하면 and 연산으로 처리
+
+- item >= 10
+
+- item <= 100
+
+// 이 경우 55, 99가 충족
+
+```
+
+
+
+`ansible_facts['distribution']=='Amazon'`	⇒  자주 쓰는 패턴(AMI is yum, 우분투 is apt)
+
+
+
+```yaml
+
+command: ""
+
+register: users
+
+
+
+debug:
+
+  msg: "There is no claud"
+
+when: users.stdout.find('claud') == -1
+
+// 저장한 변수를 이렇게 참조하여 없음(-1) 이면 msg 출력
+
+```
+
+
+
+## Facts (상세)
+
+* Facts를 수집하는게 기본이다. 수집안하게 하려면 `gather_facts:false`
+
+	* 대규모 시스템의 경우 이게 성능에 문제가 될 수가 있다. 
+
+	* 실험적 환경에서 앤서블사용을 준비할때도 꺼야한다. (테스트를 해야하니), 대부분 모듈은 파이선을 쓰고 컨테이너들은  파이선이 없는 경우가 많아서 false해놓고 command, shell 같이 파이선프리한 모듈로 파이선을 설치하는 과정이 선행. 
+
+		* AMI에는 파이선이 있지만, 그 외의 컨테이너들은 대부분 없다.
+
+`ansible localhost -m setup -a "fillter=anisible_distribution*" `
+
+→ 빌트인 모듈, 팩츠를 직접 수집해온다. 
+
+여기서 말하는 팩츠는 anisible 이 수집해온걸 말함
+
+
+
+### AWS 메타데이터 상세
+
+: EC2 메타데이터 팩트를 수집해보자 (setup 말고 다른 방법)
+
+```
+
+// collection.AWS 를 셋팅한다.
+
+ansible - i default.inv ubuntu - m amazon.aws.ec2_metadata_facts
+
+```
+
+* 이렇게 해서 ec2에서 주는 네트워크 값들을 가져와서 참조하여 작업구성
+
+
+
+* vpc 이름을 가져오기 위한 트릭. (raw 결가는 key가 너무 복잡하다)
+
+```yaml
+
+// (1) 방법
+
+-name: "set vpc CIDR"
+
+  set_fact : // 호스트 단위의 변수처럼 쓸 수 있다. dict2는 K-V Dict를 배열로 바꿈["key:v"]
+
+    vpc_cidr: {{ansible_facts | dict2items | selectattr('key', 'match', '^ec2_network_interfaces_macs_.*_vpc_ip4_cidr_block$') |  map (attribute='value'))[0] }}"
+
+// $는 표현식의 끝을 의미, map은 js의 map과 비슷. 조건문을 단 이터레이터, 파이프라인을 따라서 수집한 팩츠를 뽑아내는 중이다 
+
+
+
+// (2) 방법
+
+-name: "set vpc CIDR"
+
+  set_fact:
+
+    {{ vpc_cidr | ipaddr(2) | ipaddr("address") }} // ipaddr(2)는 해당 네트워크에서 두번째 인덱스의 호스트를 가지고 온다. 10.222.0.0/16 → 10.222.0.2/16 → 10.222.0.2 
+
+
+
+// ipaddr("netmask") 도 가능 (255.255.0.0)
+
+// ipaddr fillter는 주의할 사항이 있다. 파이선 라이브러리 netaddr이 필요함.
+
+이렇게 긁어온 값을 메타데이터 지정해놓으면 저 긴 표현식 대신 간결한 키로 참조가능.
+
+```
+
+
+
+## 실습: TF, Pack, Ansible로 Openvpn, Grafana 구성
+
+: 패커로 할때는 쉘 프로비저너로 했다. 패커의 Ansible Provision엔 (local, remote) 존재
+
+	* Ansible Provision는 원격에서 프로비전 실행
+
+	* Ansible local provisioner 는 해당 해당 서버에서 설치작업이 필요함
+
+
+
+* TF + Ansible 통합을 생각해보자
+
+	* TF 모듈엔 Ansible이 없어. Chef, habitat, puppet 과거에 지원하다가 지금은 deprecated됨..
+
+	* remote-exec Provision은 Generic PRV으로 구현하자
+
+	* 리모트 프로비전으로 앤서블 클라이언트를 설치하고 그 다음 local provisioner를 활용하는 구조로 구성
+
+
+
+1. 일단 TF로 네트워크 구성
+
+2. `ansible - initialize.yaml, playbook.yaml`  
+
+파일에 대한 권한은 rwx. (700)
+
+
+
+```yaml
+
+provisioner "ansible" 		//이걸로 앤서블 설치를 하고 
+
+provisioner "ansible-local"	//강사님은 이거 좋아함
+
+// remote에 앤서블 플레이북을 복사하고 그걸 보고 실행하므로 차후 문제트래킹할때 편함.
+
+```
+
+
+
+초기화 과정
+
+1. pip, python 설치
+
+2. 로컬에서 playbook.yaml 를 가져와 실행한다.
+
+3. task: 에서 그라파나, 도커 등등 설치
+
+pip에서 'docker' 패키지를 설치해야 컨테이너를 anisible 로 컨트롤 가능하다.
+
+4. yaml 내용
+
+```yaml
+
+canonical name
+
+  restart_policy: 	always → 재시작 하더라도 실행을 보장하지 않는다.
+
+				unless_stopped→ 항상 실행보장
+
+
+
+state: "{{ openvpn_create_client_config | default(false) | ternary('stated', 'present')
+
+// config값을 bool로 관리. ternary는 트루면 1번쨰 값, 반대면 2번째 값. present는 도커를 생성만 하고 실행하지 않는다.
+
+
+
+docker_container_exec: // 도커 컨테이너에 대해 명령을 내리는 모듈
+
+	container: openvpn
+
+	container: show-client-config
+
+    resister: result
+
+    untill: 100 // 될때까지 한다.
+
+    dealay: 10 // delay 10초로 100번 시도
+
+```
+
+
+
+```result.rc
+
+'"END PRIVATE KEY" in result.stdout'
+
+when: openvpn_create_client_config | default(false)
+
+```
+
+1. tf prv 할 때 AWS 제공한 userdata를 쓰면 AWS 에서 정보를 관리하니 볼 수가 없고 ansible 의 prv 모듈을 쓰면 직접 관리할 수 있다.
+
+2. TF 프로비전을 통해 서비스를 설치하고 playbook을 실행 하면서 TASK가 처리된다
+
+3. 호스트가 직접 플레이북을 갖고 있으면 다시 실행하기 좋다. (버전관리는.. 방법을 생각 해야겠지)
+
+
+
+
+
+# Part 5 도커와 쿠버네티스를 활용한 서비스 운영
+
+## CH01 개요 및 실습 준비
+
+### CH01_01 개요
+
+**컨테이너 기술의 발전**
+
+1. Season Traditional:  동일한 바이너리에 대해 한가지 버전의 라이브러리만 사용할 수 있다. →  앱1, 2, 3이 다른 의존성을 가지고 싶을때 트리키한 방법을 썼어야 헀다.  → 효율성과 확장성이 낮아졌다.
+
+2. Season Virtualized: 가상화를 통해 어플리케이션을 샌드박싱 → 하이퍼바이저가 게스트 OS 실행하여 독립된 실행환경을 보장. → 오버헤드 문제, 성능이슈 발생
+
+3. Season Container: 게스트 운영체제 없이  호스트 OS의 커널을 공유하여 샌드박싱 구현(chroot) → App Binary와 Library만 컨테이너에 들어감 성능개선 → 도커가 컨테이너를 돕는 엔진이라고 볼 수 있다.
+
+4. Season Kubernetes: 여러 도커를 관리할 수 있도록 돕는 시스템. 도커 클러스터링. 구글개발. 
+
+### CH01_03~07 환경구성 및 미니쿠베
+
+***docker, docker-compose, kubectl, kustomize,  minikube***
+
+🐭 rehash: Re-computes the internal hash table.
+
+Kubernetes v1.23
+
+
+
+## minikube
+
+: 학습하는 입장에서 여러가지 심플한 쿠버네티스 여러개를 구성할 필요가 있다. Driver라는 개념을 통해 원하는 가상환경을 구성가능.
+
+* 자 시작 명령어!
+
+`minikube start ~~-node 3 -~~driver=docker`
+
+* 사용방법 
+
+	* clusters, users, contexts: 클러스터와 유저의 결합을 담당
+
+```
+
+minikube start --driver docker //미니 쿠버를 이용해 Kub클러스터 생성
+
+cat ~/.kube/config
+
+~> "current-context: minikube" // 현재 사용중인 컨텍스트
+
+kubectl cluster-info  // 현재 어디에서 control-plane이 실행되고 있는지 DNS위치도 조회
+
+```
+
+* 기본적인 명령어
+
+`minikube [status*delete/pause/unpause/pause*stop]`
+
+* 많이 쓰는 명령어
+
+`minikube addons list`
+
+`minikube addons enable ingress`  // 애드온 활성화
+
+`minikube ssh`  // kubectl로 볼 수 있는 노드에 접속
+
+* 😱미니쿠베의 kubectl 버전과 kubectl 버전이 다를 수도 있다.
+
+
+
+### CH01_08 테라폼 코드를 이용하여 AWS 실습환경 구성
+
+1. Dk 및 DkCompose, kubectl, minikube, 등등 설치를 포함한 Prv을 포함하는 .tf 실행을 통해 실습환경 구축
+
+
+
+## 도커를 이용한 컨테이너 관리
+
+### 도커 이미지와 컨테이너
+
+**도커구성요소**
+
+1. Docker Client: 도커 명령어(docker build, pull, run) 를 실행하는 대상
+
+2. Docker HOST: 도커 엔진(데몬)이 띄어져 있는 서버를 
+
+	1. 데몬: 클라이언트와 통신하는 주체
+
+	2. 컨테이너: 이미지로 만들어진 프로세스. 격리된 자원사용. 어떤 작업을 하든 이미지에 영향 X
+
+	3. 이미지: 저장소로 부터 가져옴. 이미지와 컨테이너는 1:N 관계. 여러계층 구조로 존재(다른 챕터 참고)
+
+3. 이미지 저장소
+
+	1. 저장공간은 퍼블릭도 쓰고 프라이빗 서비스도 있다.
+
+* 이미지  이름 네이밍 규칙
+
+	* repo/prog:1.21 → 풀네임
+
+	* repo/prog → 가장 최근의 것
+
+	* prog:latest → 도커허브로 인식
+
+	* prog  → 도커허브에서 가장 최근의 것
+
+### 컨테이너 라이프 사이클
+
+* Created → Running → Paused
+
+* Stopped →  Deleted
+
+* 시작하는법. `docker run image` 했을때 이미지가 없으면 저장소에서 pull 해서 수행한다.
+
+```bash
+
+docker ps [-a]  //이미지 조회
+
+docker create nginx 
+
+docker start [name/id]  /
+
+```
+
+* docker 명령어 플래그
+
+```
+
+-i	호스트의 표준 입력을 컨테이너에 연결
+
+-t	터미널을 연결
+
+--rm	실행 후 자동 삭제
+
+-d	백그라운드 모드로 실행 (detached), 실행중에 exit 하거나 ctl+c 하면 원래는 종료됨.
+
+--name 이름지정 (안하면 랜덤이름)
+
+-p 80:80
+
+-v /opt/filepath \	호스트 컨테이너간 볼륨 바이딘
+
+docker run [이미지 이름] [my-command]	실행할 명령어를 제일 마지막에 붙여줄 수도 있다.
+
+```
+
+* bash는 스트리밍형태의 지속적인 입력을 요구한다. 때문에 bash만 있는 컨테이너는 `-i`로 켜면 좋다.
+
+* CTL + p, q 를 하면 컨테이너로부터 detach가능
+
+* 라이프 사이클 관련 명령어
+
+	* `docker inspect`  네트워크, 환경변수, 명령어 등 정보를 조회가능
+
+	* `docker pause`  `unpause`  일시중지
+
+	* `docker stop`  SIGTERM 전달(Graceful Shutdown)   `docker kill`  SIGKILL 전달
+
+	* `docker stop $(docker ps -a -q)`  전체 컨테이너 아이디 전달하여 stop
+
+	* `docker rm`  `docker rm ~~f `  `docker run -~~rm` 
+
+	**`docker container prune`**중지된 모든 컨테이너 삭제* //가지칠때 쓰는 단어
+
+* id는 꼭 다 입력 안해도 된다.
+
+
+
+### 엔트리포인트와 커맨드
+
+* 컨테이너가 실행할때 고정적으로 실행되는 스크립트 (prefix), 커맨드(suffix, 또는 prefix의 인자)
+
+```
+
+ENTRYPOINT ["docker-entrypoint.sh"
+
+CMD ["node"]
+
+```
+
+	* → docker-entrypoint.sh node → 이것과 같다.  또는 echo "node" 와 같이 '명령어' '인자' 의 관계도 가능하다.
+
+	* 실행할때마다 엔트리포인트와 커맨드를 바꿀 수 있으므로 중요하다.
+
+
+
+### 환경변수
+
+* 커맨드 환경변수 설정
+
+```bash
+
+docker run -it -e HY_HOST=fc.com ubuntu:focal bash
+
+$echo $MY_HOST
+
+```
+
+* ⭐️ 파일 환경변수 설정
+
+```sample.env
+
+HY_HOST=hello.com
+
+```
+
+
+
+`dokcer run ~~it --env~~file ./sample.env ubuntu:focal env`
+
+→ 컨테이너에 진입하자 마자 env를 조회한다.
+
+* 많은 컨테이너(eg. Grafana)들이 환경변수로 플러그인 설치 등을 컨트롤하고 있다. 이미지 문서를 읽어보면 활용가능
+
+
+
+### 명령어실행
+
+* `docker exec [container] [cmd]`  실행중인 컨테이너에 명령어
+
+* `docker exec -it [container] [bash]`  실행중인 컨테이너에 배쉬연결
+
+
+
+### 네트워크
+
+	![](/BearImages/2B2067DB-78A7-4EB6-A135-D5044D215842-18761-00000A58F182C7AE/Screen_Shot_2022-06-18_at_6.52.08_AM.png)
+
+* 도커 네트워크 구조
+
+	* docker0 과 eth0은  같은 네트워크로서 도커엔진이 브릿지 역할을 한다.
+
+	* 각 도커엔진은 각 컨테이너에 대해 veth를 할당한다.
+
+* 컨테이너 포트 노출
+
+	* `docker run -p 80:80` 이게 지정 퍼블리시
+
+	* `docker run -p 80`  호스트의 아무포트가 게스트 80과 연결
+
+	* `docker run -p [ip]:80:80`  지정 ip의 포트와 연결하여 실행, 이걸 localhost를 넣으면 퍼블릭IP, 나 프라이빗IP를 통해 접근을 하려해도 안된다.
+
+* Expose vs publish
+
+	* `docker run ~~d -~~expose 80 ~~-name my~~nginx nginx`  expose는 그냥 문서적인 용도 실제 패킷이 포워드 되진 않는다.
+
+* 네트워크
+
+	* `docker network ls`
+
+	* 네이티브 드라이버(Bridge, Host, None, Overlay), 리모트 드라이버(3rd party)
+
+	* Single Host Networking (bridge, host, none) / Multi Host Networking (클러스터 단계에서 실행할때 사용) 대표적으로 docker swarm
+
+	* `docker ~~it -~~net none container`  이렇게 실행한 다음 `inspect` 해보면 네트워크와 드라이버가 none 이 되어있는걸 볼 수 있다. 네트워크기능이 필요없거나 프라이빗한 네트워크를 쓰고 싶을때 사용한다.
+
+	* `docker ~~it -~~network=host grafana/grafana` 이렇게 실행하면 바로 호스트 네트워크 3000번에 바로 붙는다. `inspect` 해보면 별도의 IP가 없는 모습을 볼 수 있다.
+
+	* 직접 브릿지를 만들기
+
+		*  `docker network create --driver=bridge 2022campus`  
+
+		* `docker run ~~d -~~network=2022campus ~~-net~~alias=hello nginx`  이렇게 하면 내부에서 도메인을 찾을 때 hello 를 쓸 수 있다. 이제 grafana 컨테이너에 들어가  `wget hello`를 하면 index.html 을 받을 수 있다. 반대로 nginx 컨테이너에 들어가 curl grafana:3000을 해도 .html문서를 송신하는걸 볼 수 있다. 
+
+		* 호스트에서 `ifconfig` 를 해보면 veth, docker0 를 볼 수 있다.
+
+			*  `br-...` 이건 직접 만든 브릿지다.
+
+
+
+### 볼륨
+
+* 도커 레이어 아키텍쳐
+
+	* `docker build -t app .`  을 통해 base OS, apt Package, install pip, source Code, Update Entrypoint 이런 과정을 수행하고 이게 ***Image Layers*** 이고 Read only
+
+	* 도커는 이 각 단계를 레이어로 관리함으로서 작업수요는 줄인다. 
+
+	* `docker run app`  을 통해 실행하면 ***ContainerLayer*** 가 생겨난다. 이건 RW 
+
+* 호스트볼륨
+
+	* `docker -v *host/path:/guest*path`  이렇게 볼륨을 연결한다.
+
+	* 컨테이너에서의 작업이 호스트의 디스크에 기록할 수 있다.
+
+* 볼륨컨테이너
+
+	* Data를 쓰기위한 컨테이너를 작성하여 사용, 앱이 Data-only의 볼륨을 마운트
+
+	* `docker run ~~-name my~~volume -v *host/path:/guest*path focal`
+
+	* `docker run ~~-voulme-from my~~volume`
+
+	* 모든 셋팅된 컨테이너를 실행하면 다음 inspect 해보면 `source:... dest:...` 된걸 볼 수 있다. 
+
+* 도커 볼륨
+
+	* 도커가 제공하는 볼륨 관리 기능을 통해 데이터를 보존
+
+	* `var*lib/docker/volumes/${volume-name}*_data` 에 저장이 된다.
+
+	* 도커 볼륨 생성 `docker volume create --name db`  호스트 경로 대신 'db'를 쓰면 된다.
+
+	* 도커 볼륨 마운트 `docker run -v db:var*lib*mysql containerId`
+
+	* `docker volume inspect db`  이렇게 하면 현재 사용중인 볼륨을 볼 수 있고 ls 로 실제 위치에 존재하는 파일을 읽을 수도 있다.
+
+* 읽기 전용 볼륨 연결
+
+	* `-v db:*guest*path:ro`  이렇게 뒤에 ':ro' 를 붙이면 리드온리로 마운트된다.
+
+
+
+### 로그
+
+* STDOUT / STDERR
+
+	* 보통 앱에선 앱에서 제공하는 logging driver를 이용했다. 
+
+	* 도커에선 STDOUT / STDERR 를 직접 처리하는 식으로 해야한다. 다양한 드라이버를 제공한다. 사용목적에 맞게 사용. `json-file` 
+
+* 로그 확인하기
+
+	* `docker logs [con]`  로그를 1회 출력
+
+	* `docker logs --tail 10 [con]`  꼬리 10줄
+
+	* `docker logs -f [con]`  실시간
+
+	* `docker logs -f -t [con]`  타임 스탬프 표시
+
+* (json-file driver 사용시) 호스트 운영체제의 로그 경로 
+
+	* `cat *var/lib/docker/containers/${container_ID}*${container~~ID}~~json.log`  로그가 json 키로 되어 있는걸 볼 수 있다. keys → log:, stream:, time:
+
+* 로그 용량 제한
+
+	* `docker run ~~-log-driver=json-file --log~~opt max~~size=3m --log~~opt max-file=5` 
+
+	* 운영환경에선 필수로 해야하고 컨테이너 단위 뿐만 아니라 도커엔진에서 전체적으로 설정도 가능
+
+* 도커 로그 드라이버
+
+	* 이렇게 쌓은 로그들을 Centralized Log MNG 서비스 ( elastic, sematext, splunk, cloudWatch)에 쌓으면 된다.
+
+	* json~~file 은 파일기반, journald 는 리눅스 저널, syslog는 TCP~~UDP, fluentd는 TCP를 통해 Log Shipper에 전달할 수 있고 Log Shipper는 CLM에 HTTP로 전달한다.
+
+	* Splunk, Gelf, Logentries, CloudWatch, Google Cloud는 직접적으로 수집할 수도 있다.
+
+### 이미지빌드
+
+* 도커 이미지 구조
+
+	* os → nginx → web app 이런 순으로 레이어를 쌓고 컨테이너를 실행하면 최종 이미지를 복사하고 RW Layer가 덮어진다.
+
+	* 실행하고 나서 `inspect` 를 통해  RootFS-Layers에서 현 상태를 볼 수 있다. 
+
+* 도커파일없이 생성
+
+	* 컨테이너에 직접 들어가서 명령어를 수행한 다음 commit을 해서 이미지를 만들 수 있음.
+
+`docker commit -a 2022campus ~~m "add my***file" my***ubuntu my~~ubuntu:v1`
+
+`sha256:a961....` 이미지 생성 확인.
+
+	 * `inspect` my_ubuntu에 있었던 레이어가 봉니다. 기존 레이어를 따와서 재활용한다는걸 알 수 있다.
+
+* 도커파일로 생성
+
+	* [INSTRUCTION] [arguments] 구조로된 리스트
+
+	* `docker build -t my_app:v1 ./`  -t 태그 지정 (디폴트 파일, Dockerfile 이용)
+
+	* `docker build -t my_app:v1 -f example*MyDockerfile .*`  -f 도커 파일 지정 
+
+	* Sending build context to Docker daemon → 중요한 메시지
+
+	* 이후엔 명령어 수 만큼의 레이어가 생성됨을 알 수 있다. 이제 생성된 레이어들은 cache로 활용된다. 
+
+* 빌드 컨텍스트
+
+	* 명령 수행시 현재 디렉토리를 컨텍스트라고 한다. 복사같은 작업을 할때는 해당 디렉토리의 데이터들이 다 넘어간다. 그래서 용량이 커지는걸 알아야한다.  용량이 너무 큰게 있다면 ignore 활용
+
+* .dockerignore
+
+	**`**/temp*`
+
+	* `!README.md` 같은 방법을 통해 빌드 컨텍스트에서 무시할 파일들을 지시할 수 있다. 
+
+
+
+### Dockerfile
+
+* 파일 문법은 reference 문서를 참고
+
+	* `FROM ENV WORKDIR ADD COPY` 
+
+	* 이때 ${VAR} 이렇게 호출되는 환경변수는 전부 컨테이너의 환경변수!
+
+	* 빌드할때 값을 정의할 수도 있다. `ARG buildNo=1`
+
+	* `docker build ~~-build~~arg user=what_user ` 이렇게 정의하면 사용할 수 있는데  `ARG user` 라고 정의해주기 전에 참조하면 에러. 컨테이너 변수와 빌드 변수가 겹치면 ENV 지시어가 우선된다.
+
+```
+
+FROM node:16  #베이스 이미지 설정
+
+LABEL maintainer="FC Park <park@fc.com>" #이미지의 메타데이터
+
+RUN npm install
+
+COPY . .
+
+EXPOSE 8080 // 8080포트를 사용한다고 문서화 (publish 하는것과 다름) 
+
+CMD ["node", "server.js"] // 명령어, 최종적으로 이미지의 성격을 결정. 배열 또는 하나의 문자열도 가능 
+
+```
+
+* 엔트리 포인트를 사용하면 커맨드 명령에 앞서 뭔가 추가 할 수 있다.
+
+* ADD 는 사용지양, COPY로 대체가능. URL을 사용할 수 있는게 장점이지만 명령에 대한 성공여부를 체크하기 까다로워짐.
+
+### 이미지 압축파일로 저장 및 불러오기
+
+* 저장할때는 `docker save -o [posix.tar] IMAGE`  -o는 tar 파일로 남겨준다.
+
+* 불러올때는 `docker load -i [.tar] ` -i 는 압축으로 부터 불러온다. tar로 관리하는건 인터넷이 안되는 환경이거나 ECR을 안거치고 파일을 다른 사람에게 줘야할때 유용하다.
+
+1. 
+
+###  도커허브저장소 이용
+
+* 개인키로 로그인을 한다음 프라이빗 레포지터리 생성 후
+
+*  `docker tag nginx:latest park/my-nginx:v1.0.0`  태그 이미지 준비
+
+* `docker push park/my-nginx0:v1.0.0`  하면 업로드 진행
+
+* 실제로 프라이빗한게 지켜지는지 알기 위해 `docker pull park/my-nginx:v1.0.0` 시도 해본다.
+
+
+
+### ECR 이용
+
+* 동일하게 레포지터리 생성하면 된다. Scan on push 기능이 있다. (비용발생)
+
+* 동일하게 `docker tag` `docker images`  `docker push`를 사용, 다만 AWS 인증과정이 다르다.
+
+* 권한이 없으면 "no basic auth credentials"
+
+
+
+### 이미지 경량화 전략
+
+* 경량화를 하면 푸시, 풀, 실행하는 속도도 빨라진다. 보유할 수 있는 컨테이너의 숫자도 늘어난다. 
+
+* 꼭 필요한 패키지 및 파일만 추가
+
+	* 일반 서버 쓰듯이 다 설치하다보면 무거워진다. 컨테이너는 하나의 프로세스를 실행하기 위해 만들어진것을 잊지말자 
+
+* 컨테이너 레이어 수 줄이기
+
+	* 레이어의 수는 지시어의 수. RUN의 숫자를 줄여야한다. (하나의 RUN으로 통합하면 좋다)
+
+```docker
+
+RUN \
+
+ apk add --no-cache... && \ // 이렇게 하면 한번에 여러 명령어를 수행할 수 있다.
+
+ apk del --no-cache git &&  // Cache를 만들지 않는 옵션을 꼭 사용한다.
+
+```
+
+* 경량 베이스 이미지 선택
+
+	* node 서버가 905M인데 슬림을 고르면 174M, 기본 리눅스는 800M 알파인은 110M 
+
+	* 제일 쉬운 방법. debian slim, linux alpine, linux stretch → 고랭에서 바이너리를 스트레치에 엮어서 자주 사용함.
+
+* 멀티 스테이지 빌드 사용. 빌드에 필요한것은 빌드때만 쓰고, 릴리즈때는 뺴버리면 된다.
+
+	* `FROM node:16-alpine AS base`
+
+	* base, build, release 이런 단계를 거쳐야 한다고 볼때. FROM을 기준으로 쪼개서 관리하면 BASE -> 빌드, BASE → Release 이렇게 도커 파일의 흐름을 규정할 수 있다. 
+
+	* `FROM base AS release`  처음엔 이렇게 시작해서
+
+	* `FROM light-base AS release`  릴리즈 단계
+
+	* `COPY --from=build *app/node***modules .*node***modules` 이전 단계에서 수행한 내용 (`npm install`의 결과물을 복사. 의존성이 커질 수록 이 효과가 커진다. 레이어를 효과적으로 관리하기 위해선 초반에 고정적이고 후반에 가변적인 명령어를 다뤄야 한다.
+
+
+
+### 도커데몬 디버깅
+
+* `docker system info` 호스트 관점에서의 정보를 전달
+
+* `docker system events`  새로 발생하는 이벤트를 받는 스트리밍 파이프 상태
+
+이 상태에서 컨테이너를 실행시키면 컨테이너가 실행되는 과정을 지켜볼 수 있다.'
+
+* (우분투의 경우) `jouanlctl -u docker` 를 통해 도커 데몬의 로그를 볼 수 있다.
+
+* `docker system df` 를 통해 디스크 사용을 확인할 수 있다. `RECLAIMABLE`  컬럼 → 회수가능한
+
+* `docker system prune`  중지된 컨테이너, 네트워크, 댕글링 이미지, 댕글링 빌드 캐시 다 날림
+
+* `docker stats`  를 통해 컨테이너별 리소스 사용량 확인 가능.  
+
+
+
+### 명시적으로 컨테이너 관리하기
+
+* 도커 컴포즈 소개
+
+	* YAML 파일을 통해 명시적 관리하고 컨테이너를 묶어서 관리할 수 있게 된다.
+
+	* S1 → S3 를 호출하고 싶다. 브릿지 네트워크를 통해 net alias를 사용하는 대신 바로 호출할 수 있다. (디스커버리) 가 컴포즈에선 자동화 되어있다. 쉽게 컨테이너를 수평 확장할 수 있다.
+
+* 프로젝트 / 서비스 / 컨테이너
+
+	* 프로젝트: 워크스페이스 단위. 서비스 컨테이너의 묶음. 프로젝트 단위로 도커 네트워크가 생성됨. Project.yaml하나가 하나의 프로젝트
+
+	* 서비스 :  scale 속성을 통해 수평적 확장 가능. eg. Web, db, 
+
+	* 컨테이너: 서비스를 통해 컨테이너 관리
+
+* docker-compose.yml
+
+	* 최상위 옵션 `version, services, networks, volumes`
+
+		* service: db, web 과 같은 앱의 성격
+
+		* network: 프로젝트 내에서 사용할 리소스 정의 (없어도 디폴트 네트워크가 '프로젝트이름_bridge' 모드로 생성된다). 프로젝트 이름은 폴더 이름을 따른다. 
+
+		* volume: 프로젝트 내에서 사용할 리소스 정의
+
+ 	* 버전마다 yaml 의 호환성이 달라짐 ( docker composer file compatibility matrix 를 확인)
+
+	* Ver3부터 도커 스웜과 호환 (도커 컴포즈에서 사용되는 명령어인지, 스웜에서 사용되는 명령인지 확인해야함) 우리는 쿠버네티스를 쓸거다
+
+	* `docker stack deploy`  이것고 관련된 옵션들은 대부분 스웜	
+
+* docker-compose 명령어
+
+	* `docker~~compose up`  docker run 과 유사 '~~d' 백그라운드
+
+		* 실행될떄는 정의했던 컨테이너와 볼륨 네트워크들이 만들어지는걸 볼 수 있다.
+
+	* `docker-compose -p my_project ` 옵션으로 프로젝트명 지정.
+
+```yaml 
+
+volume:
+
+  db: {} // 별도로 옵션을 주지 않으면 기본 볼륨을 쓴다.
+
+network:
+
+  wordpress: {} // 이렇게 리소스가 정의된다. 기본은 bridge 필요하면 문서보고해! 
+
+```
+
+	* `docker-compose down`  -v 옵션을 주면 볼륨을 제거
+
+		* -v 옵션 없이 하면 컨테이너와 네트워크만 제거된다.
+
+	* `docker-compose ls -a`  전체 프로젝트 상태를 확인
+
+	* `build~~web~~1` 여기서 1은 서비스 내에서 첫번째 인덱스를 의미
+
+	* `docker~~compose up -~~scale web=3`  스케일 업할때는 이런 명령어를 주면 된다.
+
+		* 호스트의 아무 포트나 사용해서 컨테이너를 증가시켜 5000번으로 연결하게 된다. 
+
+```
+
+services:
+
+  web:
+
+    #container_name: "web" // 이렇게 이름을 지정해주면 스케일링할떄 충돌남
+
+    build: .
+
+    port:
+
+    - "5000" #"5000":"5000" 이렇게 하면 스케일링할떄 충돌남.
+
+```
+
+	* 숫자를 줄여서 다시 compose하면 컨테이너 숫자가 줄어듬
+
+* app: 이 가질 수 있는 옵션
+
+```
+
+db:
+
+	image:
+
+	volumes:
+
+  - db:/var/lib/mysql
+
+	restart: always
+
+  environment:
+
+  - MYSQL_ROOT_PASSWORD=wordpress # '-' 를 이용해 정의하면 배열
+
+...
+
+wordpress:
+
+  depends_on:
+
+  - db	# 디비에 의존하겠다는 뜻. 하지만 이게 컨테이너의 존재만 체크한다. 이걸 예쁘게 컨트롤 하려면 엔트리 포인트에서 서비스 유무를 체크해서 실행하게 하는게 좋다.
+
+  environment:
+
+    WORDPRESS_DB_HOST: db:3306 # --> 오브젝트 형식의 정의
+
+    WORDPRESS_DB_USER: user123 
+
+```
+
+* `docker-compose [ logs | events | images | ps | top ]`  등등 API DOC 참고 
+
+* 주요 사용 목적
+
+	* 로컬 개발 환경 구성 (Redis, MySQL, Kafka) 등을 사용할 수 있게
+
+	* 자동화된 테스트 환경 구성 (CICD 중 격리된 테스트 환경을 구성)
+
+	* ⭐️단일 호스트 내 컨테이너를 선언적 관리. (오케스트라에서 관리할 수도 있지만) 단일 호스트내에선 컴포즈로 하면 좋다.
+
+		* YAML 파일을 통해 선언적으로 관리 → 코드를 보면 호스트가 어떤 컨테이너를 쓰는지 알 수 있다. → 협업에 도움
+
+
+
+### 도커 컴포즈 이용하여 Grafana-MySQL 구성
+
+* 요구사항 → 3000번 바인딩, 설정파일을 호스트에서 주입, 데이터를 저장할 경우 호스트 볼륨에 저장, 플러그인 설정, 로그 드라이버 설정
+
+* 진행과정
+
+```yaml
+
+services:
+
+  grafana:
+
+    restart: unless-stopped #always는 죽으면 재시작한다. unless는 호스트가 재시작해도 재시작을 보장한다.
+
+    environment:
+
+      GF_INSTALL_PLUGINS: grafana-clock-panel
+
+    port: 
+
+    - 3000:3000
+
+    voluems:
+
+    - ./files/grafana.ini:/etc/grafana/grafana.ini:ro #로컬 파일을 연결
+
+    - grafana-data:/var/lib/grafana
+
+    logging:
+
+      driver: "json-file"
+
+      option: #중략
+
+volumes:
+
+  grafana-data: {}
+
+```
+
+* Grafana.ini 옵션
+
+```ini
+
+; 데이터베이스 설정은 주석 --> sqlite	를 쓰게 된다.
+
+```
+
+* 이제 grafana-mysql .yaml 을 확인
+
+```yaml
+
+db:
+
+  image: mysql:5.7
+
+volumes:
+
+- mysql-data:/var/lib/mysql # 이것 외에도 ini에서 데이터베이스 설정이 열린걸 볼 수 있다.
+
+```
+
+* grafana를 켜서 시스템 설정에서 변경된 내용을 확인
+
+
+---
+
+## CH3 쿠버네티스의 이요한 컨테이너 오케스트레이션
+
+### 쿠버네티스 소개
+
+* 구글 배포시스템 brog를 기반으로 재작성하여 공개 (2014년) 현재는 재단에 기부
+
+* 컨테이너의 배포, 관리, 확장, 네트워킹을 자동화하는 기술
+
+	* D.C가 한대의 머신을 관리하는 기술이라면 쿠버네티스는 ... 
+
+* ⭐️스케쥴⭐️, 스케일링, 로드밸런스, 롤백-롤아웃, 셀프힐링, 리소스 배분, 서비스 디스커버리, CM, 스토리지 오케스트레이션, 
+
+	* overlay network 를 통해 하나의 네트워크 처럼 동작하게 해준다. (Service discovery가 이것)
+
+* ***What is Container Orchestration?*** - 여러 머신으로 구성된 클러스터 상에서 컨테이너를 효율적으로 관리하기 위한 시스템 (운영체제는 하나의 머신에서 프로세스를 관리하기 위한 프로세스 오케스트레이션 시스템이잖아) → 덕분에 사용자가 OS에 대해 신경을 쓸일이 적어졌다. 해방됐다!라고 표현하기도 한다.
+
+* 기존에도 노마드, 메소스(DC/OS), 도커스웜, 랜처(간단한게 장점) 등 있었지만 선택받은 쿠버네티스
+
+* 왜 쿠버네티스인가?
+
+	1. Planet Scale 를 하기 위한 원칙
+
+	2. Never Outgrow - 다양한 요구사항을 만족할 수 있는 유연함, 로컬 규모부터 글로벌까지 유연하게 크기 조정, CRD(Custom resource Def)를 통해 기능 확장
+
+	3. 온프레미스, 퍼블릭 클라우드, 하이브리드 어디서나 동작. 리눅스라면 고의 다  동작. 환경제약이 없음.
+
+* 주의사항
+
+	1. 	복잡한 구성, 쿠버네티스의 자체가 여러 컴포넌트로 구성된 분산 시스템 → 이걸 대체하기 위한 AWS EKS, GKE 가 있다.
+
+	2. 방대한 학습량. 다양한 지식이 필요
+
+	3. 오버 엔지니어링 - 적합한가? 운영 관리에 필요한 인력과 비용이 충분한가? 멀티노드를 운영하는 구조이기에 비용이 높아진다.  
+
+
+
+### 쿠버네티스 버전과 배포판
+
+* 다양한 배포판을 가지고 있음. 
+
+	* Docker for Desktop. 쿠버네티스 기능을 활성화하고 나면 싱글노드에 클러스터 생성.
+
+	* minikube. driver를 이용해 어떤 클러스터를 구성할지 선택가능. 비슷한 역할을 하는 K3S, MicroK8s,
+
+	* 애저, 구글, 아마존에서 제공하는 Managed Cluster. AKS GKE EKS
+
+	* 레드햇은 쿠버를 래핍한 OPENSHIFT 플랫폼
+
+* 로컬 쿠버네티스 배포판
+
+	* 단일 노드에서 쉽게 쿠버네티스 구성 및 테스트 가능. 원래 멀티 노드를 위한거니까. 한계까 있는 minikube
+
+	* 클라우드 플랫폼에서만 사용가능한 기능
+
+		* ALB, NLB, EBS in AWS
+
+	* 복수의 노드에서 의미가 있는 리소스
+
+		* DaemonSet, Affinity, Taint, Toleration
+
+	* 위 기능을 쓰고 싶으면 프로덕션 레벨을 써야한다. 관리복잡도의 증가의 이슈. 
+
+		* 이를 위한 옵션, kops, kubespray, kubeadm 등을 이용해 쉽게 구축가능
+
+		* 운영부담을 최대한 줄이려면 EKS
+
+* 쿠버네티스 버전 선택
+
+	* 버전에 따라 사라지는 API resource. Deprecation Schedule
+
+		* Major 업데이트마다 Changeling, Breaking Change 꼼꼼히 검토
+
+* 실습에서는 minikube, EKS를 사용
+
+	* Driver - docker
+
+
+
+### 쿠버네티스 클러스터 구성요소
+
+* Control Plane (Master Node)
+
+	* 홀수개로 구성, kubectl 의 통신 대상
+
+	* 클러스터를 관리하는 역할, 상태관리, 명령어 처리
+
+	* etc: 저장소 역할, 분산 key-value 저장소
+
+	* cutler manager(여러가지 컨트롤러가 있다, 쿠버+클라우드)
+
+		* 클라우드 프로바이더에 종속적인 기능을 처리하기도 하고
+
+		* 쿠버네티스 본연의 기능을 위한 컨트롤 ( pod, deploy, service, secret) 각기의 컨트롤러들이 정보를 관리하고 있다가 etcd가  API 를 앞설때 갱신.
+
+	* scheduler(자원 사용을 관리하고 새로운 워크로드를 어디에 배포할지 관리) → apiserver(관리를 위한 API 제공) 
+
+* Node (Worker Node)
+
+	* kubelet - 컨테이너 런타임과 통신. 라이프사이클 관리. API 와 통신하여 노드 리소스 관리. kubelet → CRI → Container
+
+	* CRI (Container Runtime Interface)
+
+	* kube-proxy. 오버레이 네트워크 구성, 네트워크 프록시 및 내부 로드밸런서 
+
+	* pod
+
+* minikube를 쓰면 단일노드에 컨트롤 플레인과 ,워커노드가 한 호스트에 존재
+
+	* 이번 교육과정은 구축보단 사용자관점에서 사용방법을 배울것이다.
+
+
+
+### API 	리소스
+
+* Kubernetes가 관리할 수 있는 오브젝트의 종류
+
+	* Pod, Service, ConfigMap, Secret, Node, ServiceAccount, Role
+
+	* 거의 모든게 리소스 ≈  클래스 
+
+	* eg. 그라파나 리소스, 시크릿 리소스.
+
+* Object
+
+	* API 리소스를 객체화(인스턴스화) 한것. ≈ 인스턴스
+
+	* eg. grafana pod, nginx pod, mySecret,
+
+* `kubectl api-resource`  지원하는 API 리소스 목록 출력
+
+	* Name(복수), Shortnames(축약어), APIVERSION(각각 리소스마다 버전을 가진다), NAMESPACE, KIND(단수)
+
+* `kubectl explain pod`  리소스에 대한 설명 출력
+
+* 실습
+
+```bash
+
+minikube status
+
+kubectl get node
+
+```
+
+* `kubectl get po ~~all~~namespaces`  이렇게 pods 자원의 현황을 조회 
+
+* `kubectl explain pod`  해당 리소스의 스펙을 조회
+
+* 쿠버네티스는 오브젝트를 YAML 기반 매니페스트 파일로 관리
+
+	* API version → 오브젝트가 어떤 API 그룹에 속하나
+
+	* kind 어떤 API 리소스인가
+
+	* 식별을 위한 정보 metadata
+
+	* 오브젝트가 가지고자하는 데이터는 spec. → 이거 대신 data, rules, subjects 등 다른 속성을 가질때도 있다.
+
+* Labels, Annotations
+
+	* Labels → 사람이 필터링을 위해 설정하는 메타데이터
+
+	* Annotations → '애드온'이 오브젝트를 어떻게 처리할지 결정하기 위한 설정
+
+
+
+### kubectl 명령형과 선언형 방식
+
+* Imperative, 
+
+	* 액션을 지시, 빠르게 처리, 여러 명령어를 알아야함
+
+* Declarative (추천)
+
+	* 도달하고자하는 상태를 선언, 코드로 관리(GitOps), 많은 리소스에 대해 매니페스토 관리를 따라 빠르게 처리 가능, 명령어 숫자가 적음
+
+	* apply 명령을 지원하고 멱등성을 지원한다.
+
+* 명령형
+
+`kubectl run -i ~~t ubuntu -~~image unbuntu:focal bash` 이게 이미지로 우분투 파드 생성
+
+`kubectl expose deployment grafana ~~-type=NodePort -~~port=80 ~~-target~~port=3000`
+
+→ grafana dep 오브젝트에 대해 Nodeport 타입의 Service 오브젝트 생성. 노드포트에 3000번을 개방하라는 지시.
+
+`kubectl set image deployment/frontend www=image:v2`  
+
+→ frontend dep 의 www 컨테이너 이미지를 image:v2로 변경
+
+`kubectl rollout undo dep/frontend ~~-to~~revision=2`
+
+→ frontend dep 을 리비전 2로 롤백
+
+
+
+* 선언형
+
+`kubectl apply -f deployment.yaml`  정의된 매니페스토를 적용
+
+`Kubectl delete -f deployment.yaml`   오브젝트 제거
+
+`kubectl apply -k ./`  kustomization.yaml 을 위해 작성된 파일을 오브젝트 클러스터에 반영
+
+
+
+* 실습
+
+`kubectl create deployment grafana ~~-image=grafana/grafana -~~port=3000` → DEP을 생성하는데 3000번을 열라고 '포드'에게 지시하는것
+
+`kubectl expose deployment grafana ~~-type=NodePort -~~port=80 ~~-target~~port=3000`
+
+→ grafana DEP에게 '노드포트'에 3000번을 개방하라는 지시.
+
+이렇게 노출과 노출이 결합이 되면 minikube에서 서비스가 열렸다고 알려준다. 
+
+
+
+선언형으로는 `deployment.yml `, `service.yml`을 준비
+
+`kubectl delete -f deployment.yml` 서비스는 노드포트 타입을 들고 있다. DEP은 앱에 대한 명세.
+
+
+
+`unchanged` `configured`  `changed` 이미 적용된 상태라면 결과값에서 표시를 해준다.
+
+
+
+* TIP
+
+	* C R U D 작업은 선언형방식을 추천
+
+	* SSH, log, port 개방 등은 선언형으로 관리
+
+****트러블슈팅용 명령어*
+
+	* `logs, attach, exec, port-forward, proxy, top`
+
+
+
+### API 리소스 Pod
+
+* 파드란?
+
+	* 컨테이너를 다루는 기본 단위. 컨테이를 직접 컨트롤 하는건 없다. 무조건 파드로 한다. 동일 파드내 컨테이너는 여러 리눅스 네임스페이스를 공유, 네임 스페이스 내엔 동일 IP를 사용. (파드안에컨테이너가 몇이든 아이피는 같다)
+
+	* 사용자가 직접 관리하지는 않는다.
+
+실습
+
+```
+
+kubectl api-resources | grep pod
+
+kubectl explain pod
+
+kubectl describe pod
+
+kubectl apply -f pod.yaml
+
+kubectl get pod		# READY/전체테이너
+
+kubectl get pod -o wide # ip등을 포함한 정보
+
+
+
+```
+
+* 현재 쉘이 우분투에 있고 미니쿠베 클러스터에 있는건 아니기 때문에 172.17.0.3 으로 서비스되는 서비스에 바로 접근은 불가 
+
+	* `minikube ssh`  를 이용해 접근하면 된다.  이제 여기서 curl을 보내면 서비스를 받을 수 있다. 
+
+	* 두번째 방법 pod에 접근. `kubectl  run -i ~~t debug -~~image=posquit0/doraemon bash`  이제 클러스터의 쉘에 있으니 curl 가능
+
+	* `kubectl exec -i -t hello bash`  도커와 마찬가지로 hello 이미지에 명령을 전달할 수 있다. 쉘을 켜면 된다.
+
+****멀티 컨테이너 파드, 사이드카 패턴*
+
+	* 파드 구성의 특징
+
+		* 동일 파드내 컨테이너는 모두 같은 노드에서 실행 (네임스페이스를 공유). 때문에 kubectl 은 항상 목표 컨테이너 이름을 지정해야한다.
+
+	* 사이드카 패턴
+
+		* 메인컨테이너와 보조 컨테이너를 같이 실행하는 구조를 일컫는다.  사용예제는 다음과 같다.
+
+			* Filebeat 같은 로그 에이전트
+
+			* Envoy 같은 프록시 서버로 서비스메시 구성
+
+			* Valut Agent 같은 기밀 데이터 주입
+
+			* Nginx 설정 리로드 에이전트
+
+```
+
+kubectl apply -f multi.yaml
+
+kubectl exec -it hello -c debug sh #debug 컨테이너에 접근.
+
+kubectl eexc -it hello sh // 이렇게 하면 디폴트 컨테이너에 접근 (이번엔 nignx) 
+
+```
+
+### API 리소스 ReplicaSet (옛날이름 Replication Controller)
+
+* 파드의 수를 늘린다(Scale-out), 그런데 매번 def를 바꾸긴 귀찮으니, DEP에 붙어있는 REPLICA SET을 설정하고 REPLICA SET에 파드가 붙는다. 
+
+* 정해진 수의 파드가 항상 실행될 수 있도록 관리해주는 역할도 한다.
+
+* 사용자가 직접 컨트롤 하는 일은 없다. 유저는 DEP을 컨트롤한다.
+
+* 매니페스트
+
+```yaml
+
+apiVersion: apps/v1
+
+kind: ReplicaSet
+
+metadata:
+
+  name: hello
+
+spec:
+
+  replicas: 4
+
+  selector:  #많은 API 리소스가 이런식으로 레이블 셀렉터를 쓴다.
+
+    metaLabels:  #
+
+      role: web
+
+	temlplate : #레플리카셋이 만드는 pod템플릿
+
+	  metadata: #레플리카셋이 만들 파드의 메타 데이터를 지정해준다.
+
+      name: hello
+
+      labels:
+
+        app: hello      
+
+    sepc: 
+
+      container: # ...(중략)
+
+```
+
+다른 표현방법  
+
+```
+
+matchExpressions:
+
+  - {key: tier, In, values: [cache]}
+
+  - {key: environemnet , oerator: NotIn, values: [dev]} #In, NotIn논리연산을 할수도 있다.
+
+```
+
+* Control Plane은 ReplicaSet Controller가 들고 있는걸 관찰해서 스케일링을 관리
+
+ apply 후 상태확인
+
+```yaml
+
+kubectl get replicaset # rs
+
+kubectl describe replicates hello 
+
+kubectl api-resources | grep replicasets
+
+```
+
+* ReplicaSet은 라벨셀렉터로 파드를 체크할뿐. 동일한 이름의 파드가 레플리카셋에서 관리하는 파드인지까지는 검사하지 않는다 (레플리카가 아닌 유저가 실행된거라면?) 더미 파드로 같은 이름으로 실행하면 레플리카는 그걸 이미 실행되어있다고 가정하고 3개 띄울거 2개만 띄운다.
+
+	* `kubectl edit pod hello-n98st` → `lables: app: bye`  이렇게 하면 라벨이 변경되고 레플리카가 추가로 파드를 추가한다.
+
+
+
+### API 리소스 Deployment 
+
+* 파드를 새로운 버전의 이미지 파드로 교체해야 한다면, 버전이 갱신될때 배포 전략을 설정해야한다. Deployment 오브젝트를 생성하면 대응되는 ReplicaSet과 Pod가 자동 생성된다. 이걸 활용
+
+* Recreate 전략 + RollingUpdate 전략
+
+	* 재생성 전략은 모두 종료하고 새로운 파드를 생성
+
+	* 트래픽을 받고 있다면 롤링업데이트
+
+* 매니페스트
+
+```yaml
+
+#기존에 사용하던 것에서 kind만 Deployment 로 교바꿨다.
+
+spec:
+
+  type: RollingUpdate
+
+  rollingUpdate:
+
+    maxSurge: 1 #업데이트 과정에 spec.replicas 수 기준 최대 새로 추가되는 파드 수
+
+    maxUnavailable: 0 #업데이트 과정에 허용량 최대 이용 불가능 파드 수
+
+  minReadySeconds: 5 #새로운 파드가 띄어질때 기다리는 시간
+
+  minReadyHistoryLimit: #업데이트 할때마다 리비전으로 관리중인데 최대 보관갯수
+
+```
+
+`kubectl api-resources | grep deployment` 
+
+* 롤링 업데이트 전략
+
+→  새 파드 생성해서 삭제하거나 삭제하고 생성하거나 컨트롤 할 수 있다. 생성하고 파괴하는건 수용량 유지에 유리하고 파괴하고 생성하는건 노드의 갯수가 설정값을 초과하지 않는데 장
+
+`kubectl rollout history deploy`   이렇게 보면 리비전이 기록된걸 볼 수 있다.
+
+`kubectl set image deployment rolling nginx=nginxdemos/hello:latest --record` 선언형으로 업데이트 진행
+
+`kubectl rollout undo deployment rolling ~~-to~~revision=1`  롤링으로 롤백을 수행
+
+`kubectl rollout status deployment rolling`  롤백 상황을 조회 가능
+
+
+
+### API 리소스 - Service
+
+* 역할
+
+	* Deployment를 통해 파드를 수평확장하기 위한 개념 L4 기반 Loadbalance 
+
+	* 여러 파드에 대해 클러스터 내에 사용 가능한 고유 도메인 부여(Service discovery)
+
+	* 파드의 IP는 항상 가변 할 수 있음.
+
+![](/BearImages/A282D917-284B-4FD5-9BC4-A495E2644B16-7058-0000020254C4B15D/1D250843-51BB-4F3F-A0C5-1CEF3BFDC392.png)
+
+* 서비스의 종류 `Nodeport NodePort LoadBalancer ExternalName`
+
+	* ClusterIP 클러스터 내부의 요청만 처리. 외부트래픽 X
+
+	* NodePort : ClusterIP 의 랩핑한 타입, 외부로부터 트래픽이 오면 node가 받아서 SVC로 전달
+
+	* LoadBalancer : NodePort  래핑한 타입, 밖에 존재하는 로드밸런서를 컨트롤해서 SVC로 전달
+
+	* ExternalName : 앞의 3개가 트래픽을 받기 위한 거라면, 이건 외부로 가는 트래픽을 해석하는 변환하기 위한 용도. 
+
+* ClusterIP 
+
+	**서비스 네트워크 IP/PORT 정보 → 
+```diff
++ spec.clusterIP:spec.ports[**].port
+```
+
+
+	* ⭐️ 파드에 부여하는 CIDR 대역과 서비스에 부여되는 ClusterIP CIDR 가 독립적으로 존재한다.  클러스터는 서비스를 가지고 서비스는 ClusterIP 를 가진다. 이곳으로 오는 요청은 LoadBalance 내부 DNS를 통해 서비스 이름으로 통신도 가능
+
+```yaml
+
+apiVersion: v1
+
+kind: Service
+
+metadata:
+
+  name: hello
+
+  labels:
+
+    app: hello
+
+spec:
+
+  type: ClusterIP #타입 이거 안넣으면 기본값으로 들어감
+
+  ports:
+
+  - name: http
+
+    protocol: TCP
+
+    port: 8080 #CIP:port 이렇게 사용된다. --> podIP(targetPort)로 포워드
+
+    targetPort: 80 #컨테이너의 포트를 적는다.
+
+  selector:
+
+    app: hello #이 서비스는 hello라는 DEP를 가르킨다. 
+
+``` 
+
+
+
+`minikube ssh` 접속해서 curl 해보면 서비스하는 파드의 이름들이 변하는걸 볼 수 있다.
+
+`kubectl run -i ~~t test -~~image=posquit0/doraemon bash` 이렇게 만들 다음 curl을 해보면 클러스터 내에서 통신이 가능하지
+
+`kubectl cluster-info dump | grep ~~m 1 service-cluster-ip~~range`
+
+→ 클러스터 아이피를 볼 수 있고 수도으로 설정도 가능하다.
+
+* NodePort를 외부에 노출하기
+
+	**서비스 네트워크 IP/PORT 정보 
+```diff
++ <NodeIP:spec.port[**].nodePort
+```
+
+
+	* 쿠너네티스의 모든 동일 포트를 개방하여 서비스에 접근가능케함
+
+```yaml
+
+apiVersion: v1
+
+kind: Service
+
+metadata:
+
+  name: hello
+
+  labels:
+
+    app: hello
+
+spec:
+
+  type: NodePort
+
+  ports:
+
+  - name: http
+
+    protocol: TCP
+
+    port: 8080
+
+    targetPort: 80
+
+    #nodePort: 31000 #지정하지 않으면 port 랜덤하게 설정
+
+  selector:
+
+    app: hello
+
+``` 
+
+	* 이제 적용하면 ClusterIP는 유지되고 타입이 바뀌면서 PORT에 NodePort 가 보인다. 
+
+	* `kubectl describe service hello`로 NodePort 조회
+
+	* 이제 ssh 안하고도 바로 curl 로 접근 할 수 있다.
+
+* LoadBalancer (보통 클라우드 프로바이더의 로드밸런서와 연동하여 쓴다)
+
+	**서비스 네트워크 IP/Port 정보 
+```diff
++ spec.loadBalancerlp:spec.ports[**].port
+```
+
+
+	* 클라우드 프로바이더에서 제공하는 로드밸런서를 동적으로 생성하는 방식. minikube 에선 패스. (할수는 있지만) MetalLB 같은 기술을 쓰면 On Poremise에서도 로드밸런스 타입 사용가능.
+
+```yaml
+
+spec:
+
+  type: LoadBalancer
+
+  ...(중략)
+
+  selector:
+
+    app: hello
+
+``` 
+
+미니쿠베이기 때문에 `kubectl apply` 해도 `pending`상태가 유지된다.
+
+* ExternalName 로 외부로 요청 전달
+
+	* 보통 클러스터 외부의 레거시 시스템을 쿠버네티스로 마이그레이션할때 쓴다. DNS의 cn 레코드와 동일한 역할 수행 ( 리다이렉트 해준다)
+
+```yaml
+
+apiVersion: v1
+
+kind: Service
+
+metadata:
+
+  name: httpbin
+
+spec:
+
+  type: ExternalName 
+
+  externalName: httpbin.org
+
+```
+
+apply 하고 `kubectl get service`를 하면 `hot-bin ExternalName` 이란 서비스를 볼 수 있다. 그리고 `httpbin.org`를 가르키고 있다. 이제 테스트 파드에 들어가서
+
+`$curl httpbin.org` 를 하면 외부에 대한 요청을 성공한다. 
+
+	* [EKS실습환경] 에서 로드밸런스 기능 확인
+
+명세
+
+```yaml
+
+apiVersion: v1
+
+kind: Service
+
+metadata:
+
+  name: hello
+
+  labels:
+
+    app: hello
+
+spec:
+
+  type: LoadBalancer
+
+  ports:
+
+  - name: http
+
+    protocol: TCP
+
+    port: 8080
+
+    targetPort: 80
+
+  selector:
+
+    app: hello
+
+```
+
+`kubectl get service`하면 로드밸런서 확인가능 . `NLB 타입도 쓸 수 있다. 
+
+```LB-nlb type yaml
+
+annotations:
+
+    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
+
+```
+
+```LB.yaml 
+
+kubectl app -f deployment.yml 
+
+kubectl get svc
+
+kubectl get pod // 이렇게 하면 타입들이 변한걸 확인 가능
+
+```
+
+
+
+### API 리소스 - ConfigMap
+
+* 어플리케이션의 설정값을 컨테이너에 주입! 어플리케이션과 볼륨, 환경변수를 분리하면 이상적
+
+```yaml
+
+      env:
+
+      - name: MYSQL_ROOT_PASSSWORD #실행하고 들어가면 $PASSWORD 해보면 보인다.
+
+```
+
+직접적으로 지정하는 방법
+
+```yaml
+
+apiVersion: v1
+
+kind: ConfigMap
+
+metadata:
+
+  name: mysql-config
+
+data: # 대개 spec을 가지나 data 키를 가진다.
+
+  MYSQL_ROOT_PASSWORD: fastcampus 
+
+  MYSQL_DATABASE: devops
+
+  ... (중략)
+
+```
+
+**envFrom 방법**
+
+```
+
+        envFrom:
+
+        - configMapRef: #mysql-config맵 모든걸 가져온다.
+
+            name: mysql-config
+
+```
+
+**configMapKeyRef 방법**
+
+```
+
+        env:
+
+        - name: MYSQL_ROOT_PASSWORD
+
+          valueFrom:
+
+            configMapKeyRef: #키를 지정해서 가져온다.
+
+              name: mysql-config
+
+              key: MYSQL_ROOT_PASSWORD
+
+```
+
+apply 하고 나면  `kubectl describe cm` 을 통해 현재 관리되고 있는 ConfigMap 의 정보를 조회가능. `kubectl describe cm mysql`을 통해 현재 가지고 있는 환경변수 값을 조회 가능
+
+**볼륨으로 쓰는법**
+
+```
+
+    Containers:
+
+        volumeMounts: # tmp/config에 mysql-config를 덮었다. 이렇게 하면 파일이 올라간다. 그걸 직접 집어들어서 쓰는것.
+
+        - mountPath: /tmp/config
+
+          name: mysql-config
+
+      volumes:
+
+      - name: mysql-config
+
+        configMap: #볼륨 드라이버 옵션이 들어올 자리인데 컨피그맵을 보게 했다.
+
+          name: mysql-config
+
+
+
+```
+
+@팁 yaml 파일이 굉장히 길수도 있다. 그게 부담이 된다면 imperative를 이용해 쉽게 쓸 수 있는 트릭, 
+
+`kubectl create configmap my-config`
+
+`kubectl create configmap my~~config --from~~file config.yaml` 이건  `#key=value` 구조로 들어간다.
+
+`kubectl create configmap my~~config --from~~file config=config.yaml` // 이렇게 쓰면 'config'키가 파일을 바라보게 된다.
+
+`kubectl create configmap my~~config --from~~file config=config.yaml ~~dry~~run -o yaml `  드라이 런은 이렇게 하면 가짜로 실행하라는 의미. 클러스터에 반영이 안되고 어떤 결과를 내는지를 본다. -o (ou  tput) yaml 포맷. 의미 따라서 declarative한 사용에 필요한 값을 출력 받을 수 있다. 
+
+`kubectl create configmap my~~config config=config.yaml -dry~~run ~~o yaml --from~~file deployment.yaml`이렇게 쓰면 'data:' 의 키값으로 deployment.yaml 이 들어간다.
+
+`kubectl create configmap my~~config config=config.yaml -dry~~run ~~o yaml --from~~file test=deployment.yaml`  → test 이렇게까지 써주면 파일명 대신 test란 이름으로 config키가 설정된다. 
+
+`~~-from~~literal key=value` 옵션을 주면 data: 밑에 바로 등록이 된다.
+
+
+
+### API 리소스 - Secret
+
+* 패스워드, ssh key, API key 등을 주입하기 위해 사용. 안전하게 저장되는건 아니다. Base64으로 그냥 플레인하게 저장되어있다. Binary도 지원한다. etcd 에 접근가능하면 아무나 읽을 수 있다. KMS로 관리해야 진짜로 안전. RBAC(role based access control) 리소스을 통해 시크릿을 콘테이너와 분리할 수 있다. 
+
+* 여러 종류의 시크릿의 사용방법
+
+	* Opaque (generic) 일반. kubectl get 를 통해 바로 사용가능
+
+	* dockerconfigjson - 도커 이미지 저장소 인증 정보
+
+	* tls → 파드나 서비스 등에서 암호화를 위해 필수!
+
+	* service~~account~~token - ServiceAccount 인증 정보 (RBAC할때 필요함)
+
+* kubectl 로 생성
+
+`kubectl create secret generic my-secret` →  generic은 타입이다. 
+
+`kubectl create secret generic ~~-from~~file secret.yaml`  yaml 에 정의해놓고 쓰는법 이것 도 역시 드라이런을 활용할 수 있다.
+
+* 실습
+
+```
+
+envFrom:
+
+- configMapRef:
+
+    name : mysql-config #기존 사용
+
+- secretRef:
+
+    name : mysql-secret #키를 두번 설정하면 아랫께 오버라이드
+
+```
+
+apply하고
+
+```
+
+   valueFrom:
+
+      secretRef: // 이렇게 또 키로 참조
+
+```
+
+그냥 뭐 ConfigMap 쓰는걸아 비슷하네
+
+
+
+type: docker-registry 도 비슷하게 쓰면 되는데 imperative하게 선언하는 방법
+
+```bash#!/usr/bin/env sh
+
+kubectl create secret docker-registry docker-registry \
+
+  --docker-username=fastcampus \
+
+  --docker-password=fastcampus \
+
+  --dry-run -o yaml
+
+```
+
+
+
+```
+
+    spec:
+
+      imagePullSecrets:
+
+      - name: docker-registry // 이렇게 설정하면 여기서 들고 오게 된다.
+
+```
+
+@팁 퍼블릭 이미지는 레이트 리밋이 걸려있으므로 시크릿으로 만들어서 사용하면 속도개선
+
+
+
+type:tls 만들어서 저장하기
+
+```bash
+
+openssl req -new -newkey rsa:4096 -days 365 -nodes -x509 -subj "/CN=fastcampus.com" -keyout cert.key -out cert.crt
+
+
+
+kubectl create secret tls my-tls \
+
+  --cert cert.crt \
+
+  --key cert.key \
+
+  --dry-run -o yaml
+
+```
+
+
+
+Secret을 코드로 관리하게 되면 의미가 없어진다. 따라서 두가지 방법
+
+1. external secrets
+
+	* 시크릿관리 백엔드와 연동하여 프로바이더에게 기밀값을 가져오는 방식
+
+1. Sealed secrets
+
+	* kubeseal CLI 를 통해 암호화를 하고 컨트롤러가 복호화한다. 
+
+	* 파일로 관리해도 평문이 노출되지 않는다.
+
+	
+
+### Namespace ResourceQuota LimitRange
+
+* 네임스페이스 - 일반 언어 네임스페이스와 다르지 않다. 논리적 구분 + 논리적인 그룹에 대하여 CPU, MEM 등 리소스 제한을 둘 수도 있다. 환경에 따라 구분  (팀, 환경, 서비스 단위)
+
+	* 네임스페이스 범위 API 리소스 조회  `kubectl api~~resources -~~namespaced=true `
+
+		* 종속적인 리소스들 event, pods, 
+
+	* 클러스터 범위 API 리소스 조회  `kubectl api~~resources -~~namespaced=false`
+
+		* namespaces, nodes, 
+
+* 클러스터 기본 네임스페이스
+
+	* 기본은 default, `kube-system` 쿠버 시스템에 의해 생성되는 API 오브젝트를 관리하기 위한 스페이스
+
+	* `kube-public` 클러스터 모든 사용자로부터 접근 가능하고 읽을 수 있는 오브젝트
+
+	* `kube~~node~~lease` 쿠버 내부 시스템이 사용하는 영역
+
+* 다른 네임 스페이스의 서비스에 접근하는법
+
+	* 	FQDN(Fully Qualified Domain Name), Domain Search 옵션
+
+`curl ${service}.${namespace}.svc.cluster.local`→ FQDN 레벨의 서치, 이게 resolve.conf에 설정되곤 하는데 
+
+이런 도메인 서치 옵션들이 하는건 curl my-service 하게되면 알아서 FQDN부터 해서 순차적으로 넓은 범위로 쿼리를 한다.
+
+* 실습환경 구축 및 테스트
+
+```
+
+kubectl create namespace a
+
+kubectl create namespace b
+
+kubectl apply -f . -n a // 이렇게 하면 같은 내용으로 두 개의 네임스페이스가 생성됐다.
+
+kubectl apply -f . -n b #-n은 네임스페이스를 지정하는 옵션
+
+```
+
+ →  `kubectl get all -n a` → minikube ssh → curl http://hello.a.8080
+
+→ curl http://hello.b.svc:8000 해도 잘 됨. 
+
+* 자원제한 (@TODO: 나중에 많이 필요할듯)
+
+	* ResourceQuota , LimitRange
+
+		* 사용량의 합을 제한 ( 할당 자원의 <CPU, MEM, VOL>총합 재헌, 생성하는 리소스<POD, Service,  Deployment> 의 개수 제한)
+
+	* 	LimitRange는 자원할당량의 기본, 최소, 최대를 설정한다.
+
+	type:Container 타입을 자주 많이 쓴다.
+
+* 컨테이너에 리밋을 걸면 파드에도 상위 리소스의 값을 상속해서 알아서 제한이 걸린다. 
+
+
+
+### Job과 CronJob
+
+* 지속적으로 실행되는 서비스가 아니라 특정 작업을 수행하고 종료해야 하는 경우에는?
+
+* 특정 동작을 수행하고 종료하는 작업을 정의하기 위한 리소스, 데이터 백업, 점검, 알림전송에 사용
+
+```
+
+apiVersion: batch/v1 
+
+kind: Job
+
+spec: 
+
+  template: #DEP도 파드를 가질때 템플릿을 사용헀다.
+
+    sepc:
+
+      restartPolicy: Never #잡을 만들때는 반복시도 하지마
+
+      containers:
+
+      - name: hello ...(중략)
+
+```
+
+JOB은 파드처럼 알아서 레이블과 레이블 셀렉터를 만들어준다. 다만 특별히 조정하고 싶을땐 직접 셀렉터를 설정해주면 된다.
+
+* 패러렐리즘 (동시실행횟수)
+
+```
+
+kind: job
+
+spec: 
+
+  completions: 10 #타겟횟수
+
+  parallelism: 2 #동시진행
+
+``` 
+
+`kubectl logs job/hello` 이렇게 조회 `kubectl get job`
+
+* 데드라인
+
+```
+
+sepc:
+
+  activeDeadlineSeconds: 3 #최대 수행시간
+
+```
+
+실패하면 Completed 가 아닌 Terminated가 된다. 
+
+
+
+* kind: CronJob → 파드의 템플릿 구조를 그대로 사용.
+
+```
+
+  schedule: "/1 * * * *"
+
+  successHistoyLimit
+
+  jobTemplate:
+
+    spec:
+
+      template:
+
+        spec:
+
+          restartPolicy: Never
+
+          container:
+
+          - name: hello
+
+          image: ubuntu:focal
+
+          command: ["sh", "-c","echo Hello $(date)!"]
+
+```
+
+	* 이 구조는 `DEP -> ReplicaSet ~~> pod <~~ job <- Cronjob` 로 파드를 감싼다고 보면 된다.
+
+
+
+### API 리소스 - DaemonSet
+
+* 각 노드마다 꼭 실행되야 하는 워크로드(로그 수집, 메트릭 수집, 네트워크 구성)이 있다면?
+
+* 클러스터의 모든 노드에 동일한 파드를 하나씩 생성한다.  
+
+	* filebeat, fluentbit 로그수집
+
+	* node-exporter, metricbeat, telegraf 메트릭수집
+
+	* kube-proxy, calico 네트워크 구
+
+* Label Selective 하게 동작가능하고 모드도 지정할 수 있다.
+
+```yaml 
+
+kind: DaemonSet
+
+(중략)
+
+spec:
+
+  selector:
+
+    matchLabels:
+
+      app.kubernetes.io/name: filebeat
+
+(중략)
+
+      containers:
+
+      - name: filebeat
+
+        image: docker.elastic.co/beats/filebeat:7.15.0
+
+(중략)
+
+        - mountPath: /var/lib/docker/containers #모든 컨테이너에 접근할 수 있게 되었다.
+
+          readOnly: true
+
+(중략)
+
+        hostPath:
+
+          path: /var/lib/filebeat-data #데이터를 쌓기 위해 
+
+          type: DirectoryOrCreate 
+
+```
+
+보통은 파일로 저장하는데 ConfigMap 보면 그냥 콘솔로 아웃풋을 출력하게 해놨다. 실제로는 그렇게 운영하지마!
+
+
+
+### API 리소스 - Ingress
+
+* 소개 - 외부로부터의 요청에 대해 TLS 및 라우팅 관리가 필요한데. 인그레스는 L7에서 처리할 수 있게 해준다. 인그레스가 HOST, 앱과 PATH를 읽어서 서비스로 전달하고 서비스에선 LoadBalancer 를 한다. 
+
+* ingress 리소스는 있는데, 컨트롤러는 없어서 별도로 설치를 해야한다.
+
+	* 인그레스 컨트롤러 역할을 할 수 있는 앱이 많기 때문이다. eg. NGINXINX, Kong ingress, AWS LBC, GoogleLBC
+
+* 	인그레스 클래스는 - 하나의 클러스터에서 여러 인그레스 컨트롤러를 쓸 수 있게 해주는 리소
+
+	* 인그레스컨트롤러 + Configuration 
+
+* `minikube addons enable ingress` → kubectl get ns → kubectl get ingressclass 
+
+* path.yamlml 을 적용하고 나면 kubectl get inginxress 에서 처리하고 있는 패스가 보인다. 
+
+
+
+```yamlspec:
+
+  ingressClassName: nginx
+
+  rules:
+
+  - http:
+
+      paths:
+
+      - path: /hello
+
+        pathType: Prefix
+
+        backend:
+
+          service:
+
+            name: hello
+
+            port:
+
+              name: http
+
+```
+
+→ 가장 기본이 되는 패스 기준 인그레스 처리
+
+
+
+```yaml
+
+spec:
+
+  ingressClassName: nginx
+
+  rules:
+
+  - host: hello.fastcampus // 이렇게 호스트 헤더에 따라 라우팅도 한다. 실제로 할때는 curl로 헤더값을 넣는게 아니라 클러스터 상에 도메인 설정읋 해서 해야한다.(이게 뭔소리야)
+
+    http:
+
+      paths:
+
+      - path: /
+
+        pathType: Prefix
+
+        backend:
+
+          service:
+
+            name: hello
+
+            port:
+
+              name: http
+
+```
+
+→  인그레스의 핵심이 되는 설정
+
+
+
+```
+
+spec:
+
+  ingressClassName: nginx
+
+  defaultBackend: #나머지 요청을 처리하도록 등록
+
+    service:
+
+      name: httpd
+
+      port:
+
+        number: 80
+
+```
+
+→  요약을 하면... 인그레스 쓰고 싶은거 골라서 정의하고 어떻게 쓸지 yaml 로 정의해주면 된다 이거지
+
+
+
+### 파드의 배치 전략 - Node Selector
+
+* 파드를 만드는데 어떤 Node에 배치할지는 전략모델에 따른다. 
+
+	* minikube 로 멀티노드 클러스터를 구성해서 파드를 만들어볼것입니다!
+
+* `NodeName` 을 이용해서 배치하면 강직성이 높아져 추천하지 않는다. 정확히 지정한 이름의 쿠베에 들어간다.
+
+* `NodeSelector`를 이용해 Label Selector 기반 배치
+
+	* 노드를 구성할때 Kubelet 옵션을 통해 기본 레이블 설정 가능
+
+	* `kubectl label node minikube~~m2 team=red`  이렇게 레이블 설정 뺄때는 `team~~`
+
+	* 실제로 셀렉트 할때는
+
+```dep.yaml
+
+nodeSelector:
+
+  team: red #미니쿠베 2-3번에 `team-red`을 주었다.
+
+```
+
+이런 구조에서 `kubectl apply -f deployment.yaml`을 하면 귀신같이 red에만 달라붙는다. 
+
+
+
+### 파드의 배치 전략 - Node Affinity
+
+* affinity (선호도)
+
+* nodeAffinity 확장된 Label Selector
+
+	* Hard(required)조건, Soft(referred)조건이 존재한다. ignoredDuringExecution(이미 실행 중이라면 이 규칙을 무시한다). 실행중인 워크로드 , 즉 deployment 카인드로 별도로 배치를 했다면 무시한다는거다.  Scheduling 중에 적용되는 전략이다. 
+
+```dep_required.yaml
+
+kind:deployment: (...중략)
+
+  affinity:
+
+        nodeAffinity:
+
+          requiredDuringSchedulingIgnoredDuringExecution:
+
+            nodeSelectorTerms:
+
+            - matchExpressions:
+
+              - key: team
+
+                operator: In
+
+                values:
+
+                - blue
+
+                - red
+
+```
+
+	* 소프트룰에선 weight 는 40~100으로 설정하여 가중치를 조정 
+
+
+
+* podAffinity ( 띄어져 있는 pod 위치에 가점)
+
+	* 여기도 하드, 소프트 조건이 존재. 토폴로지 키 (Topology Key)가 중요하다. 
+
+	* 노드, 존, 리전 세가지 키가 존재하는데 미니쿠베에서는 설정불가능. 
+
+	* 존 → age, 리전 → aws리전, 노드 → 호스트네임
+
+```yaml
+
+     affinity:
+
+        podAffinity: 
+
+          preferredDuringSchedulingIgnoredDuringExecution:
+
+          - weight: 100
+
+            podAffinityTerm:
+
+              labelSelector:
+
+                matchExpressions:
+
+                - key: app
+
+                  operator: In
+
+                  values:
+
+                  - mysql
+
+              topologyKey: kubernetes.io/hostname
+
+              # topologyKey: topology.kubernetes.io/zone
+
+              # topologyKey: topology.kubernetes.io/region
+
+```
+
+* podAntiAffinity (안띄어져 있는 pod 위치에 가점)
+
+	* 반드시 중복해야하는것(hard), `requiredDuringSchedulingIgnoredDuringExecution`
+
+	* 선호하는 조건 soft `preferredDuringSchedulingIgnoredDuringExecution` 으로 쓴다.
+
+	* [규칙이 하나 밖에 없으면 의미가 없다.]
+
+### 파드의 배치 전략 - Taint와 Toleration
+
+* Taint(얼룩), 임의의 파드가 할당되는 것을 방지
+
+* Toleration(용인) 정의한 노드에 대해 면역을 가지고 배치를 할 수 있다.  톨러레이션을 주면 무시하고 들어간다.
+
+```yaml
+
+    spec:
+
+      tolerations:
+
+      - key: role
+
+        operator: Exists // 구분자 exist 면 그냥 다 적용해버린다.
+
+```
+
+* taint를 관리하는 방법에는 kubectl, kbl 
+
+
+
+`kubectl taint node minikube-m02 role=system:NoSchedule`  해당 노드에 노스케쥴 테인트 추가
+
+`kubectl taint node minikube~~m02 role=system:NoSchedule~~`  해당 노드에 노스케쥴 테인트 제거
+
+`kubectl taint node minikube~~m02 role~~`  해당 노드 모든 테인트 제거 
+
+
+
+* Effect 효과
+
+`NoSchedule`  파드를 스케쥴링하지 않 기본적인 테인트의 목
+
+`NoExecute`  파드의 실행을 허용하지 않음
+
+`PreferNoSchedule`  파드 스케쥴링을 선호하지 않음
+
+
+
+
+---
+
+# Chapter04. Kustomize를 이용한 쿠버네티스 매니페스토 관리 (이하 kust)
+
+**Helm에 대해 정리**
+
+차트 - 헬름의 패키지.  (패키지에는 애플리케이션, 도구, 서비스를 구동하는데 필요한 리소스가 포함. like YUM RPM (Redhat Package Manager) 디펜던시를 설치해주고 실제 목적했던 프로그램도 설치
+
+저장소 - 차트를 모아놓고 공유하는 장소.
+
+릴리즈 - 클러스터에서 구동되는 차트의 인스턴스. 차트는 여러번 실행될 수 있다. 
+
+`helm install[릴리즈][차트]` 의 형태로 설치할 차트를 명령할 수 있다. 
+
+`helm show values` 이걸로 차트의 구성정보를 확인하고 차트를 커스터 마이징하게 된다.
+
+릴리즈를 업데이트, 삭제, 롤백을 할 수 있다.
+
+
+
+## 01. KUST 소개
+
+* Kubernetes 매니페스트를 효율적으로 관리하기 위한 오픈소스 도구
+
+YAML을 보존한채 변경본(patch)을 만들어 사용할 수 있는 것을 목표로함. 다른 툴 Helm 은 Chart를 쓰는걸 도와주는데 둘 중에 하나를 쓴다. Kustomize가 쉽다. Helm 은 템플릿을 만들어서 변수를 넣어 완성하는 방식. 
+
+* 원본이 유지됨에 따라 base가 되는것도 언제든 apply가능한 상태
+
+* kustomization.yaml 
+
+: Kustomize가 사용하는 매니페스트, Base 매니페(기본설정만 구성됨)-오버레이 매니페(변형을 위해 사용됨)로 나뉜다. 누군가의 Base가 될 수 있다. 도커의 layer랑 비슷하네. 오버레이 값은 베이스가 되는걸 덮어쓰는 방식으로 동작한다. 
+
+* 주요 명령어
+
+ `kustomize create`  kustomize build . (yaml을 해석하여 쿠버네티스 매니페스트 출력) 
+
+`kustomize build [url]`URL을 통해 원격에 위치한 customisation.yaml 을 해석하여 쿠버네티스 매니페스트 출력
+
+`kustomize build . | kubctl [apply|delete] -f -`
+
+kustomize 는 매니페스토를 표춘출력만 한다. 그래서 이렇게 kubctl에 흘려줘야함.
+
+* kubectl에 통합되어서 바로 사용가능
+
+```bash
+
+kubectl kustomize .
+
+kubectl apply -k .
+
+kubectl delete -k .
+
+```
+
+
+
+## 02. 메타데이터
+
+* 실습
+
+```kustomization.yaml
+
+apiVersion: kustomize.config.k8s.io/v1beta1
+
+kind: Kustomization
+
+
+
+resources:
+
+- pod.yaml // `resource` 키워드로 yaml을 묶을 수 있다. 
+
+- rbac.yaml
+
+
+
+namespace: fastcampus // 변형 코
+
+```
+
+여기에다  뭘 적으면 이제 pod, rbac yaml 에 네임스페이스가 등록된다.
+
+* namePrefIx, nameSufix 를 이용해 리소스의 이름에 뭘 달아줄 수 있다.
+
+```
+
+CommonLables:
+
+  ownner: claud
+
+  department: devops
+
+```
+
+이렇게 레이블을 달아주는데도 유용
+
+
+
+## 03. Replica and Images
+
+* 이제 annotation, namespace 등을 모두 공용으로 지정해줘서 더 짧은 코드로 더 풍부한 정보를 줄 수 있지?
+
+```yaml
+
+resources:
+
+- grafana/ // 디렉토리를 리소스로 지정할땐 각 디렉토리에 kustomization.yaml 이 있어야 한다. 각 리소스를 실행한 결과를 리소스로 사용하게 된다. 
+
+- hello/
+
+```
+
+```yaml
+
+replicas:
+
+- name: grafana // 이렇게 하면 각 앱의 정의는 앱.yaml에서, replica만 kust로 관리하게 된다.
+
+  count: 2
+
+- name: hello
+
+  count: 1
+
+``` 
+
+
+
+* `images:`  이미지 레지스트리의 위치 변경, 이미지의 버전변경에 사용가능하다. 이미지와 버전을 kust에서 관리할 수 있단 뜻. 각 앱의 정의는 이미지에 대해 신경쓰지 않고
+
+```yaml
+
+images:
+
+- name: grafana/grafana
+
+  newTag: "8.2.2"
+
+- name: nginxdemos/hello
+
+  newName: nginx
+
+  newTag: "latest"
+
+```
+
+
+
+## 04. ConfigMap과 Secret, Generator
+
+```yaml
+
+configMapGenerator:  #ConfigMap을 직접 관리하면 힘드니 만들어진 기능
+
+- name: mysql-config
+
+  literals:
+
+  - MYSQL_DATABASE=devops
+
+  envs:
+
+  - mysql.env
+
+- name: test-files
+
+  files:
+
+  - files/test1.txt  // 이렇게 정의하면 밸류만 지정하면 경로가 키가 된다. 
+
+  - test2.txt=files/test2.txt // 좌측이 키, 우측이 밸류가 된다.
+
+
+
+secretGenerator:
+
+- name: mysql-secret
+
+  literals:
+
+  - MYSQL_ROOT_PASSWORD=fastcampus
+
+
+
+# These labels are added to all configmaps and secrets. 제너레이터와 관련된거 모두에 추가된다. (위쪽 제너레이터)
+
+generatorOptions:
+
+  labels:
+
+    env: dev
+
+  annotations:
+
+    managed_by: kustomize
+
+  # disableNameSuffixHash is true disables the default behavior of adding a
+
+  # suffix to the names of generated resources that is a hash of
+
+  # the resource contents.
+
+  # disableNameSuffixHash: true
+
+```
+
+
+
+* from literals 환경변수를 키밸류로 하나하나 정의
+
+* from env 파일을 읽어서 변수로 정의(파일 안에서  키밸류로 정의)
+
+* from files:   
+
+* kust로 생성된 빌드 내용들엔 해시값을 쓰라는 정의가 없는데 빌드하면 붙어서 나온다.  여기서 나오는 해시들은 제너레이터가 출력값에 따라 해시값을 다르게 가지게 된다. 내용 변경없이 실행하면 계속 같은 해시값이다.
+
+	* 해시를 추가하는 이유는 디플로이먼트 객체가 configmap을 참조할때 configmap있는 계정과 패스워드가 바뀌게 된다면 디플로이는 알 수 없어서 가만히 있는다. 하지만 해시를 해성성하고 있다면 변경을 감지하고 디플로이가 파드를 업데이트 할 수 있다.
+
+	* 이런 동작은 항상 장점이 되지는 않는다. 일부러 해시붙이는 기능을 disable 할 수 있다.
+
+* `kubectl exec -it deploy/mysql bash` 명령어로 파드에 붙고  `cd temp; cat test; 하면 환경변수나 볼륨을 확인할 수 있다.
+
+
+
+## 05. Patches
+
+* base, dev, prod 각 폴더로 patchesStrategicMerge 를 통해 실습
+
+```kust.yaml at dev
+
+resources:
+
+- ../base // 베이스를 참조한다.
+
+
+
+namePrefix: dev-
+
+
+
+patchesStrategicMerge:
+
+- resources.yaml
+
+- service.yaml
+
+``` 
+
+
+
+```resource.yaml at dev
+
+apiVersion: apps/v1
+
+kind: Deployment
+
+metadata:
+
+  name: hello // 여기까지 앱버전, 카인드, 메타데이터는 세가지값을 명시하면 머지를 수행할때 어떤 머지의 대상인지 판별하는 기준이 된다. 그 다음부터 쓰는 데이터들은 패치의 대상
+
+spec: // 이미지 이름이라던가 기본적으로 써야할게 다 빠져있다. 이정보는 merge를 통해 가져온다.
+
+  template:
+
+    spec:
+
+      containers:
+
+      - name: nginx
+
+        resources:
+
+          requests:
+
+            cpu: 100m
+
+            memory: 64Mi
+
+```
+
+base에서 설정하는 속성, patch에서 설정하는 방법을 구분하여 머징한다. → patchesStrategicMerge
+
+이렇게 설정해놓고 `kubectl apply  -k dev` 로 클러스터에 적용
+
+
+
+* 패치 메소드 2 
+
+```base/service.yml
+
+apiVersion: v1
+
+kind: Service
+
+metadata:
+
+  name: hello
+
+  labels:
+
+    app: hello
+
+spec:
+
+  type: ClusterIP
+
+  ports:
+
+  - name: http
+
+    protocol: TCP
+
+    port: 8080
+
+    targetPort: 80
+
+  selector:
+
+    app: hello
+
+```
+
+
+
+```/prod/kustomization.yaml
+
+resources:
+
+- ../base
+
+
+
+namePrefix: prod-
+
+
+
+patchesStrategicMerge:
+
+- resources.yaml
+
+
+
+```
+
+
+
+```resource.yaml at prod
+
+spec:
+
+  template:
+
+    spec:
+
+      containers:
+
+      - name: nginx
+
+        resources:
+
+          requests:
+
+            cpu: 300m
+
+            memory: 128Mi
+
+
+
+```
+
+
+
+* 위와같은 작업을 json으로도 할 수 있다.
+
+	*  JSON 방식으로 할때는 `target`을 지정해줘야 한다. 
+
+```dev/kustomization.yaml at
+
+apiVersion: kustomize.config.k8s.io/v1beta1 // 적용대상은 이 앱!
+
+kind: Kustomization
+
+
+
+resources:
+
+- ../base
+
+
+
+namePrefix: dev-
+
+
+
+patchesJson6902:
+
+- target:
+
+    version: v1
+
+    kind: Deployment
+
+    name: hello
+
+  path: resources.yaml // (1) 리소스를 참조해서 적용하게 하게 한다고
+
+- target:
+
+    version: v1
+
+    kind: Service
+
+    name: hello
+
+  path: service.yaml
+
+```
+
+op 엔 add replace 등등 많으니 문서 참고
+
+
+
+```dev/resource.yaml
+
+- op: add
+
+  path: /spec/template/spec/containers/0/resources // (2) 이 항목에 values를 넣어라.
+
+  value:
+
+    requests:
+
+      cpu: 100m
+
+      memory: 64Mi
+
+```
+
+
+
+``` base/deployment.yaml
+
+    spec:
+
+      containers:
+
+      - name: nginx
+
+        image: nginxdemos/hello:plain-text
+
+        ports:
+
+        - name: http  // (3) 이 레벨에서 values의 값이 입력된다.
+
+          containerPort: 80
+
+          protocol: TCP
+
+
+
+```
+
+
+
+### 이번 이챕터요약
+
+→ kubectl 가 Kubernetes 를 통제하기 위한 명령어였다면 kustomization은 kubectl을 좀 더 유연하고 코드 생상성을 높히기 위해 사용하는 것이다.
+
+
+
+
+---
+
+# CAHP5 쿠버네티스 관리 도구
+
+## kubectx를 이용한 쉬운 컨텍스트 전환
+
+* `kubectl config get-contexts` 를 통해 보면 EKS를 통해 만들어진 컨텍스트, minikube 를 통해 만들어진 네임. 여러가지가 있을 수 있다.
+
+	**cluster + user + namespace 3개의 합이**컨텍스트*
+
+* `cat ~*.kube*config` 에서 컨텍스트를 볼 수 있다. 
+
+	* kubectl 로도 컨텍스트를 바꿀 수도 있는데, kubectx가 더 간단하다.
+
+* `kubectx fastcampus`  컨텍스트 변경
+
+* `kubens`명령얼 통해 네임스페이스 목록을 출력
+
+	* kubectl get pod  같은걸 할때 default 를 지정해놓은걸로 자동으로 타겟이 지정된다. 디폴트를 안썼으면 아무것도 안나옴. `kubectl get pod ~~n kube~~system` 처럼 다 쓰지 않고도 명령어 수행가능
+
+	* `kubeens` 로 네임스페이스를 바꾸면 간단하게 사용 가능 굳
+
+
+
+## kail을 이용한 쿠버네티스 서비스 접촉
+
+* kail은 로그를 보는데 사용한다. 
+
+* kail의 Selectors 옵션 잡이름, 노드이름, 서비스 이름 을 기준으로 셀렉터하여 로그를 볼 수 있다.
+
+* Combining Selector
+
+	* 예를 들어 `mail ~~-rs workers -~~rs db` 이렇게 두번 쓰면 OR로 동작한다.
+
+	*  `mail ~~-svc front -~~deploy back`  둘다 다른 옵션을 쓰면 AND 로 동작한다.
+
+* other flags
+
+	* `--since 12h` 특정 시점에서 로그를 보여주기 때문에 자주쓴다. 옵션 안주면 실시간 로그를 ㅁ
+
+* 그냥 kail만 하면 디폴트 네임 스페이스로의 로그를 수집
+
+* 예를 들어 kubectl get svc 를 통해 서비스를 보고 그중에 hello를 보고 싶어.. 그런데 지금은 로그가 없네
+
+그러면 `kail ~~-svc hello -~~since 12h` 쓰면된다.
+
+* `-n` 은 네임스페이스 지정
+
+
+
+## kubefwd를 이용하여 로컬에서 쿠버네티스 서비스 접속
+
+* 개발자가 로컬에서 쿠버네티스 환경을 구축할때 사용하면 좋다.
+
+* 쿠버네티스 안에서의 로컬 DNS는 개발자와 로컬 환경과 구분되어 있어서 접근이 안된다. 그걸 하려면 서비스에 인그레스 설정을 따로해야겠지. 애초에 열라고 만든것도 아니잖아
+
+* kubefwd를 이용하면 공공 DNS에 요청하기 전에 먼저 응답받을 수 있다.
+
+* `sudo kubefwd svc ~~all~~namespaces`를 수행하면 모든 네임스페이스로 부터 서비스를 가져다가 포트포워딩을 벌크로 진행한다.  ( 포트포워드는 관리자 권한을 요구한다) 이제 로그가 막 찍히는데
+
+* `kubernetesectl get svc ~~all~~namespaces`로 서비스 목록을 받아보고 비교해보면 포트포워드된걸 확인할 수 있다.
+
+* `curl nginx:80` 이러면 통신이 되지? 접속안해도 바로 된다! 굿
+
+* `sudo -E kubefwd svc -n fastcampus` 이렇게 서비를 특정하여 포워드를 할 수도 있다. 
+
+* mac 이나 윈도우에서 포워딩이 되면 서비스를 브라우저에서도 확인할 수 있으니 훨씬 좋다.. (아하)
+
+
+
+## k9s : CLI 클러스터 관리 툴
+
+* 문서에 있는 옵션들 꼭 읽어보길
+
+* GUI환경에서 쿠버네티스에 속하는 리소스들을 볼수 있다.
+
+* metris-server 애드온 설치하면 됨 리소스 사용량 조회가능
+
+* 파드에 대한 조작 명령어들도 지원
+
+* `popeye`를 통해서 현재 상태를 체크할 수 있다. (왜 점수가 그렇게 나왔는지도 나옴)
+
+
+
+## Lens 이용하여 GUI 앱으로 쿠버네티스 클러스터 관리
+
+* brew install lens 
+
+* connect
+
+* config - Lens Metrics (클릭하나로 관측 시스템을 구성할 수 있는게 장점)
+
+	* 전문적으로 또는 개별적인 서비스가 필요하다면 직접 구성하는걸 추천한다.
+
+* 쉘에 바로 접속을 하거나 리소스 사용량, 히스토리 조회 가능
+
+* 실시간으로 Replica도 늘릴 수 있고 
+
+* 여기서 변경을 하면 yaml에 반영이 되나?
+
+* Network-service에서 포워드를 끄고 켜고 할 수 도 있다. 
+
+* Event도 유용
+
+* 개발자들한테는 lens를 추천. 쉽게 접근할 수 있으니까.
+
+
+
+# Part 6 CI/CD 구현
+
+## Chapter 1 CICD
+
+* CICD's ideal
+
+	* 잘 관리된 코드베이스
+
+	* 빠른 머지 빠른 제공
+
+	* 베이스라인에 매일 작업들이 커밋되고 배포되어야
+
+	* 모든 커밋은 테스트를 거쳐야 한다.
+
+	* PRD환경을 클론한 스테이징 환경
+
+* CICD → Continuous delivery
+
+	* 계속 자동으로 배포가 된는 구조의 문제점을 극복하기 위해 더 확장된 개념. 비즈니스적 관점을 추가한것.
+
+	* 예를 들어 임베디드 제품이라면? 디펜던시가 있는 프로젝트라면? 특정 시점에 배포를 해야한다면? 이런 니즈를 처리하는게 Delivery
+
+## Chapter 2 AWS IaaS CI/CD
+
+* 	젠킨스 장점
+
+	* 커뮤니티가 활성화 되어 있고, 플러그인이 다양하게 준비된다. 클러스터가 되고 확장성이 높다. JVM 기반 구동
+
+* 	젠킨스 실습
+
+```bash
+
+// 도커로 정의 후 실행
+
+```
+
+플러그인 검색, SMTP 설정, 깃허브 설정, 크레덴셜 등록(AWS API 콜을 위한), 
+
+* 파이프라인 잡을 만들고 여기에서 스크립트로 잡을 구성했다.
+
+## 젠킨스 파이프라인
+
+* 2.0 이후부터 추천한다. 프리스타일 잡들이 단일 잡에 특화되어있으므로 파이프라인은 복합적 작업을 위한 기능
+
+* 두가지 타입으로 작성가능. 
+
+	* 스크립트 타입 파이프라인 (groovy, JAVA API 호출)
+
+
+
+## Chapter 3 AWS SaaS CI/CD
+
+## Chapter 4 외부 SaaS를 이용한 CI/CD
+
+## Chapter 5 kubernetes CI/CD
+
+
+
+# Part 7 모니터링 서비스 및 운영 구현
+
+
+
+# Part 8 AWS 기반 보안
+
+
+
+# bonus Part AWS EKS
+
+
+
+#devops/Mainline
\ No newline at end of file
diff --git "a/Bear/\360\237\214\247 (2) Devops Mainline.md" "b/Bear/\360\237\214\247 (2) Devops Mainline.md"
new file mode 100644
index 0000000..6e4d076
--- /dev/null
+++ "b/Bear/\360\237\214\247 (2) Devops Mainline.md"	
@@ -0,0 +1,3458 @@
+# 🌧 (2) Devops Mainline
+
+#Devops #Mainline
+
+
+---
+
+# Part 6 CI/CD 구현
+
+## Chapter 1 CICD
+
+* CICD ideal point
+
+	* 잘 관리된 코드베이스
+
+	* 빠른 머지 빠른 제공
+
+	* 베이스라인에 매일 작업들이 커밋되고 배포되어야
+
+	* 모든 커밋은 테스트를 거쳐야 한다.
+
+	* PRD환경을 클론한 스테이징 환경
+
+* CICD 의 확장 `Continuous delivery`
+
+	* 계속 자동으로 배포가 된는 구조의 문제점을 극복하기 위해 더 확장된 개념. 비즈니스적 관점을 추가한것.
+
+	* 예를 들어 임베디드 제품이라면? 디펜던시가 있는 프로젝트라면? 특정 시점에 배포를 해야한다면? 이런 니즈를 처리하는게 Delivery
+
+
+---
+
+## Chapter 2 AWS IaaS CI/CD
+
+## CH02-01 소개
+
+* 젠킨스 장점
+
+	* 커뮤니티가 활성화 되어 있고, 플러그인이 다양하게 준비된다. 클러스터가 되고 확장성이 높다. JVM 기반 구동
+
+* 도커로 실행
+
+* 플러그인 검색, SMTP 설정, 깃허브 설정, 크레덴셜 등록(AWS API 콜을 위한), 
+
+* 파이프라인 잡을 만들고 여기에서 스크립트로 잡을 구성했다.
+
+
+---
+
+## CH02_02 젠킨스 파이프라인
+
+* 버전은 2.0 이후부터 추천한다. 구버전에서 지원하는 프리스타일 잡은 단일 실행에 특화되어있다. 파이프라인은 복합적 작업을 위한 기능
+
+* 두가지 타입으로 작성가능. 
+
+	1. 스크립트 타입 파이프라인 (groovy, JAVA API 호출)
+
+	2. 선언형 파이프라인 (Jenkins DSL, isolate complex logic into Jenkins plugin) 
+
+* 선언형 파이프 라인의 구성에 들어가는 개념
+
+	* Agent: pipeline or stage가 실행될 노드 지정, type(none, any, label, node, docker, dockerfile, Kubernetes)
+
+	* Stages: 작업의 명세서인 stage의 묶음
+
+	* Steps: Stage안의 단계
+
+	* Directives: step의 묵음
+
+	* Post: 후처리. (스테이지 안에 선언하면 다 끝나고 실행된다) type(always, cleanup ...) 
+
+	* env: credentials() 를 통해 호출 가능
+
+	* parameter: 스코프가 다 블럭마다 존재
+
+	* when (실행 조건)
+
+
+
+## CH02_03 실습 #1 by Manual  install
+
+* 실습과정
+
+1. Provision the following →  VPC, NAT, SUBNET, Bastion, Jenkins, RouteTable, SG, IGW
+
+2. `tf apply ~~-auto~~ap prove`
+
+3. EC2 접속후 `git remote -v`결과로 클론, 허드슨이 제공하는 공식 스크립트로 젠킨스 설치
+
+4. `journalctl -u jenkins.service -f` `netstat -nlp | grep 8080` `curl - v http://localhost:8080` 이렇게 구동 확인
+
+5.  실습의 목표는 젠킨스가 ECR의 이미지를 가져와 도커를 다뤄야 하므로 도커 데몬스가 필요하다. 
+
+```DOCKER daemon install
+
+sudo uyum install -y docker;
+
+systemctl enable docker;
+
+systemctl start docker;
+
+ll /var/run/ | grep docker // 이렇게 보면 docker를 3개 볼 수 있는데 sock이 중요하다. 
+
+```
+
+6. 권한 부여 `usermod ~~aG docker ec2~~user`  socket에 접근 할 수 있도록 하기 위한 조치. 소켓은 root, docker 그룹에 속한다. 가지고 있으므로 ec2-user 에게 권한을 준다. 명령어를 내린 다음 재로그인해야 적용. 
+
+7. `cat *etc*passwd | grep jenkins` 젠킨스 유저가 도커를 컨트롤 할 수 있게 `sudo usermod -aG docker jenkins` 이제 젠킨스도 도커를 컨트롤 할 수 있다.
+
+
+
+## CH02_04~07 실습 #2 by Docker
+
+* DIND 구조와 DOOD 구조
+
+Docker in Docker: 딘드 내에서 소스 코드를 빌드한다면 딘드가 여러개있을때 독립적인 환경을 구성할 수 있는게 장점. 대신 딘드가 리눅스의  **Cgroups**에 접근해야하므로 권한을 많이 가지게 되고 딘드가 침해당하면 호스트가 침해당하게 된다.
+
+* DOOD(Docker out of Docker)
+
+	* 도커데몬 대신 도커 클라이언트로 두드를 실행한다. 유닉스 소켓(docker.sock)을 통해 요청을 하여 마더 도커 데몬과 통신을 한다. 보안 취약을 극복할 수 있지만 두드 컨테이너는 네임페이스를 마더와 공유하기 때문에 여러 두드가 생기게되면 사이드이펙트가 발생.  격리를 포기한다는 뜻.
+
+	* DOOD의 도커 클라이언트가 도커 Push등의 명령을 받게 되면 호스트의 데몬에 소켓을 통해 요청을 한다. 
+
+	**호스트 소켓은 어떻게 두드가 참고 할 수 있을까? (서로 독립된 OS인데) -> 마운트를 하면 된다. 두드는 소켓에 대한 권한을 가지면 된다. 호스트는**docker:999*그룹을 jenkins 실행 계정에 실행한다.
+
+	* 이때 액세스 권한에 주의한다. sock을 others에 다 풀어줘도 해결이 될 수 있지만 보안 문제가 발생한다.
+
+* 실습 시나리오: When github receive push Req -> Pipeline -> Delivery
+
+1. 파일 구성
+
+```dockerfile
+
+FROM jenkins/jenkins/lts
+
+ARG DICKCER_GID=1000
+
+#AWS_CLI설치
+
+RUN /user/sbin/groupadd -g ${DOKCER_GID:-1000} -f dokcer && \ user/sbin/usermod -aG docker jenkins
+
+USER jenkins
+
+```
+
+```docker-compose.yaml
+
+volumes:
+
+  - "/var/run/docker.sock:/var/run/docket.sock"  // 중요한 마운트 부분
+
+```
+
+2. 웹서비스에서 초기설정 →  젠킨스 URL → 로드밸런스나 다른 서비스에서 젠킨스를 참조할때 사용
+
+3. **Pipeline script from SCM(Source Control Management)** 라는 옵션이 있다. 깃에서 스크립트를 가져오게 와서 사용함. 이러면 매번 웹 인풋박스를 통해 잡을 매니페스트 하지 않고 체계적으로 관리할 수 있게 된다. GItOPS
+
+4. 깃허브에서 발행한 레포, hook 권한을 준 키를 입력한다.  
+
+5. WEB hook 설정을 한다. 젠킨스 주소, json, 이벤트를 설정 이제 웹훅을 통해 트리거되는 모습을 볼 수 있다. 
+
+
+---
+
+##  CH02_07 실습 #3 CI 자동화
+
+* 젠킨스 환경변수 사용 `env.WORKSPACE`
+
+* `when { expression { return params.DOCKER_IMAGE }` 이런식으로 사용한다.
+
+****빌드는 캐시에 영향을 많이 받는다.*
+
+### 자동화 과정
+
+1. 빌드(`docker build -t test:1`
+
+2. 테스트(`docker run --rm test:1 root*.local/bin*pytest -v`)
+
+3. 이미지 푸시
+
+```
+
+sh """
+
+docker push ${DOCKER_IMAGE}
+
+# 이런식으로 steps 안에서 쉘 스크립트 멀티라인을 정의할 수 있다.
+
+"""
+
+```
+
+
+
+4. Deployment 
+
+* 빌드 캐시는 디스크를 빨리 채우게 되고 운영에 지장을 줄 수 있다. 도커 GCE가 정기적으로 관리하도록 해야한다. 
+
+	****prune* 이란 컨셉에 의한 캐시 정리는 문제의 원인이 되기도 한다. 가끔 하는 작업이거나 동시에 병렬 또는 시퀀스를 가질때 문제가 된다. 왜냐하면 A가 이미지를 prune으로 날리면 A에 대해 의존성을 가질때 B가 실패하게 된다. (Race condition) 배치잡을 통해 할것.
+
+	* 컨테이너만 Prune의 대상이 아니다. 이미지, 볼륨, 네트워크, 시스템 오브젝트 모두 대상
+
+
+---
+
+##  CH02_07 실습 #3 CD 자동화
+
+1. 파이프라인에서 설정을 하면 credential 을 이용, sshagent로 명령을 전달한다. 
+
+빌드는 빌드서버에서
+
+배포는 배포서버로 연결해서 수행 
+
+```
+
+aws ecr get-login...
+
+export IMAGE=${ECR_DOCKER_IMAGE}
+
+export TAG=${ECR_DOCKER_IMAGE}
+
+docker-compose -f compose.yaml down;
+
+docker-compose -f compose.yaml up -d';
+
+```
+
+2. **Input** 타입을 통해 유저에게 물어보고 입력 여부에 따라 프로세스를 분기하면 delivery를 컨트롤 할 수 있다. (이거 좋네!?) 빌드는 하되 배포하지 않는걸 통해 리소스 효율과 딜리버리를 달성할 수 있다. 
+
+3.  파이프라인을 이용할 수 있는 젠킨스 최신 버전은 스테이별로 진행상황을 볼 수 있다. 로그도 따로 등록된다.
+
+* Tips
+
+	* 젠킨스가 이전 버전의 컨피그로 실행되는 문제가 간혹 발생한다. 
+
+	* 여러대를 배포해야한다면? 6대를 해야 한다면?
+
+		* AWS 오토스케일링 그룹을 통해 서비스를 한다면 알아서 해주겠지
+
+		* Packer를 통해 배포를 한다면? 이런 관리니즈를 충족할 수 있다. 
+
+	* 위의 실습은 젠킨스의 기능을 순수하게 활용하기 위한 예제 다른 서비스를 보통 쓴다. 패커나 쿠버네티스
+
+
+---
+
+## 슬랙연동
+
+### 설치 및 연동 과정
+
+1. slack app directory → Jen Config → Jen 애드온에서 notification 추가 → 시스템 설정 slack에 워크스페이스, 토큰, 채널 입력  
+
+
+---
+
+## 젠킨스 Master, Slave concept
+
+* 마스터는 매니저만 하고 슬레이브에게 빌드를 분담하는 컨셉
+
+* 구현방법
+
+1. 쉘 등록
+
+```.ssh/config in bastion.
+
+Host target
+
+  Hostname 10.0.3.61
+
+  User ec2-user
+
+  IdentityFile ~/.ssh/dev.pem
+
+```
+
+2. 슬레이브 쪽엔 authrized_key 즉 공개키를 등록시켜준다. 
+
+<Tips: in iTERM , CMD + SHIFT + i 로 복수의 터미널에 동시입력이 가능하다. >
+
+3. git, docker 등을 설치하고 JDK 등을 설치한다. 에이전트로 부터 받은 명령이 JVM 기반으로 실행된다.
+
+4. 이제 `webconsole - system - Nodes` 에서 슬레이브를 등록한다.  `trusted key`  옵션을 선택한다. 
+
+5. 이제 파이프라인에서 어디에서 할지 `label`을 붙여준다. 
+
+6. 스테이지를 분산하게 되면 생기는 에러를 주의해서 파이프라인 작성(스테이지간 의존성)
+
+	* EC2를 잠시 띄었다가 다시 내리는 방식으로 처리할 수도 있다. 플러그인을 믿어.
+
+
+
+
+---
+
+
+
+# Chapter 3 AWS SaaS CI/CD
+
+## AWS Code Series CICD 개요
+
+젠킨스에서 마스터 슬레이브 구조를 통해 역할을 분담한것과 비슷한 구조를  AWS CB, CD에서 구현하는 내용! SaaS를 쓴다는건 바로 이것이다.
+
+### 장점!
+
+1. CODE Build, fully managed build service 큐를 신경쓰지 않고 사용가능
+
+```buildspec.yml
+
+pharses:
+
+  install:
+
+    run-as:
+
+  pre_build:
+
+  build:
+
+artifacts:
+
+cache: // 이런 구조로 빌드 과정을 정의
+
+```
+
+* 권한설정: 마스터 젠킨스를 EC2에 두는 구조. EC2의 룰은 ECR, S3, CloudWatch, VPC 에 대한 권한을 가져야 한다. 
+
+```jenkinsfile in EC2 Master
+
+steps {
+
+  awsCodeBuild(
+
+    credentialsType: 'keys's,
+
+    buildSpecFile: 'deploy/buildspec.yml'
+
+  )
+
+} // 이렇게 코드빌드를 호출하는 함수를 사용한다. 코드빌드 플러그인이 이일을 한다. 
+
+```
+
+tips - 잡이 실행되면 코드빌드와 클라우드 와치에서 동작을 확인할 수 있다.
+
+
+
+### Deployment by CodeDeploy (fully managed build service)
+
+### 콘셉트
+
+	* 컴퓨팅 서비스 ( EC2, Lambda, on-Premise) 에 배포 자동화 지원
+
+	* In-Place, Rolling, AB Deployment, Canary Deployment
+
+	* Rollback, Notification, Delivery 지원
+
+### 구성
+
+	* App, Deployment Group, Deployment, Deployment Configuration
+
+### 시나리오
+
+1. CB가 만든 파일을 CD가 참조해서 한다.
+
+2. 배포할 파일을 S3 오브젝트에 명세한다. 
+
+3. CD 프로젝트는 S3권한이 필요해진다.
+
+4. 타겟 서버(배포 서버)에는 CD Agent가 필요하다.
+
+5. CD가 직접 배포하는게 아니고 작업 내용은  `appspec.yml`에 명세한다.  
+
+6. Agent가 직접 S3오브젝트를 읽고 매니페스트를 처리한다. 때문에  CD가 아닌 타겟서버의 EC2에 S3 Read 권한을 줘야한다. Agent는 호스트의 권한을 따른다. (Conssume)
+
+```appspec.yml
+
+permission:
+
+ - object: /home/ec2-user
+
+  pattern: "**" // 하위 디렉토리 모두
+
+hooks:
+
+  applicationStart:
+
+  applicationStop:
+
+```
+
+
+
+### 시나리오 해석
+
+1. EC2에 바로 넣는게 아닌 S3에 올리는 구조가 기존 배포구조와 다른 점 
+
+2. 아티팩트  `artifacts { ... }` 에서 빌드 결과물을 컨트롤하고 있다. 
+
+3. `deployment***gorup.tf`의 `resource deployment***config` 에서 `minimum***healthy***hosts`를 정의할 수 있다.  디폴트는 한번에 하나씩 하는 전략. (1개니까 여기선 주석처리했고 복수 노드를 대상으로 배포 할땐 사용한다.)
+
+4. 개인적으로 관심있게 본 부분
+
+```main.tf
+
+user_data  = data.template_file.userdata.rendered
+
+# user_data를 프로비전하도록 하고
+
+```
+
+```data.tf
+
+data "template_file" "userdata" {
+
+  template = file("templates/userdata.sh")
+
+} # 여기에선 스크립트 실행
+
+```
+
+```userdata.sh
+
+cd /home/ec2-user
+
+wget https://aws-codedeploy-ap-northeast-2.s3.amazonaws.com/latest/install
+
+chmod +x ./install
+
+sudo ./install auto
+
+sudo service codedeploy-agent status
+
+rm -rf ./install
+
+# 배포 환경을 셋팅
+
+cat >/etc/init.d/codedeploy-start.sh <<EOL
+
+#!/bin/bash
+
+sudo service codedeploy-agent restart
+
+EOL
+
+chmod +x /etc/init.d/codedeploy-start.sh
+
+# 디플로이 스크립트를 짜고 실행한다.
+
+``` 
+
+
+
+### 배포과정 설명
+
+1. `build spec.yml` 의 `discard-paths` 옵션을 쓰면 디렉토리 경로를 무시하고 HOME에 파일을 바로 생성한다. 
+
+2. 타겟서버에 `user_data` 데이터를 줬다. 그리고 스크립트에 코드디플로이 설치 및 서비스 시작 스크립트가 들어갔다. 에이전트가 S3에 접근할 수 있도록 권한도 Define한다.
+
+3. Jenkins 파이프라인 구성
+
+```YAML 
+
+# Override로 정의하는 이유. 빌드넘버가 생길때마다 산출물이 읽기힘든 해시로 생겨나는데 디버그를 힘들게 한다. 젠킨스의 빌드 넘버를 쓰도록 오버라이드를 하자.
+
+  artifactPathOverride: "${currentBuildNumber}"
+
+```
+
+4. 스탭 내 스크립트를 이용한 배포 
+
+```groovy
+
+sh```
+
+  aws deploy create-deployment \
+
+  --application-name ${CODEDEPLOY_NAME) \
+
+  ...
+
+```
+
+5. 코드디플로이가 배포를 주도하기 때문에 while을 통해 리절트 값을 체크한다. 
+
+
+
+### 서버 여러대라면 배포 설정의 결과는 어떻게 판단하는가?
+
+deployment config 의 타입에 따라 성공판단 기준도 바뀐다. AllAtOnce, HalfAtTime 일부의 실패도 성공으로 받아들이는 타입은 조심해서 사용해야겠지.
+
+
+---
+
+## AWS CodePipeline
+
+* 젠킨스를 대체하는 SaaS
+
+* 지원하는 스테이지 Stage
+
+	****Source* 지원 서비스 - 깃헙, 코드커밋, ECR, S3 (다른 소스를 쓰고 싶으면 S3에 후크를 걸면 된다.
+
+	****Build* - 코드빌드, 젠킨스, 팀시티, 클라우드비
+
+	****Test* - 코드빌드, 디바이스팜, S3 
+
+	****Deployment*  - 클라우드 포메이션, S3, ECS
+
+	****Approval* -  휴먼 디시전, Invoke(람다, 스탭펑션 호출)
+
+* 스테이지별로 아웃풋을 정의하고 다음 스테이지에서 또 호출해서 쓴다.
+
+	* 설정한 뒤 `웹 - Setting - 깃헙` 커넥션을 정의해줘야 한다.
+
+	* 테라폼에서 지원안되는 리소스도 있다. 직접 만들자~! 
+
+	* Noti (SNS) 설정
+
+		1. 파이프라인 → noti rule을 생성 
+
+		2. AWS chatbot 설정
+
+		3. slack -> configure slack channel
+
+
+---
+
+## Chapter 4 외부 SaaS를 이용한 CI/CD
+
+* Github Actions, CircleCI
+
+	* 왜 이런걸 외부 SaaS라고 부르는가? AWS 기준으로 보니 외부 SaaS가 되었다. 
+
+	* 이벤트를 통해 워크플로우를 자동화 할 수 있는 도구
+
+		* push event, Pull request, master branch 병합, 주기적 태스크 실행 →  모두 이벤트
+
+* Github Actions 컴포넌트 구성
+
+	****Workflows* (전체를 아우르는 상위 개념)
+
+	****Events* (push, pr, release, schedule)
+
+	****Jobs* (스탭의 묶음, 러너가 실행하는것, 의존성있는 실행도 지원)
+
+	****Steps* ( shell 실행을 말한다. 스탠드얼론)
+
+	****Runners* (실행자, 애저의 서버를 활용할 수도 있고, on-premise도 지원
+
+* 정의하는 방법
+
+```.github/workflows/learn.yml 
+
+name: blah
+
+on: [push]
+
+jobs:
+
+  check-version:
+
+  runs-on: ubuntu-latest:
+
+  steps:
+
+    - uses: actions/checkout@v2
+
+    - run: npm install -g bats
+
+```
+
+	* 무시할 패스와 이벤트를 일으킬 패스를 구분할 수 있다.
+
+	* 셋팅 후 이벤트가 일어나면 Actions 탭에서 워크플로우를 조회할 수 있다. 젠킨스 없이도 바로 할수 있는게 재밌는 포인트.
+
+
+---
+
+### 액션과 AWS CLI를 연동해보기
+
+* 깃허브는 외부 서비스고 타겟서버는 운영서버니까 직접 관여하는건 보안문제가 됨. 배포에선 스크립트가 복잡해지니 CodeDeploy를 활용하는 설계.
+
+```
+
+jobs:
+
+  ci:
+
+  cd:
+
+```
+
+이런 정의에 사용되는 리소스들은 액션 마켓플레이스에서 구할 수 있다. 
+
+`echo ::set-output name=.... ${{ steps.login... }}` 이런식으로 고유한 변수 정의 문법이 있다. 
+
+`zip -j`패스를 지우고 바로 현재 위치에 다 압축을 구성한다.
+
+```cicd.yml
+
+needs: [ci] // ci 작업이 끝나면 실행하겠다.
+
+```
+
+
+---
+
+## CH04_03 Custom Action
+
+### slack  연동
+
+* incoming WebHook 등록 → 이제 HTTP 문서로 메시지를 채널에 쓸 수 있게 되었다. 이제 웹훅의 시크릿을 적용하고자 하는 레포지터리에의 시크릿에  등록하고 메시지를 쓰게 한다. 워크플로우 중에 호출하여 메시지를 슬랙에 쓴다. 
+
+```slack.yml
+
+jobs:
+
+ slack:
+
+   steps:
+
+   uses: dev-chilbuji/devops_custom_action@master
+
+```
+
+### 커스텀 액션의 용도
+
+**복수의 REPO에서 각자 슬랙과 통신해야한다고 했을때 각 프로젝트마다 로직과 토큰을 관리해야 한다면 관리비용이 커진다. `커스텀 액션`을 정의해놓으면 참조를 통해**reuseable*을 보장할 수 있다.  
+
+* 기존에는 저장소마다 토큰을 발급하고 로직을 작성해 이벤트를 일으켰다면 커스텀은 액션은`incomming 토큰`을 발급해서 여기를 모든 저장소가 호출하여 이벤트를 처리하게 만든것이다.
+
+* `action.yml` → `dockerfile 호출` →
+
+```dockerfile
+
+FROM ... RUN ... ADD ... ENTRYPOINT ["/entrypoint.sh"]
+
+``` 
+
+→ 
+
+```entrypoint.bash
+
+CMD = '$1'
+
+case "${CMD}" in
+
+  slack)
+
+    _slack // 커맨드를 받아서 슬랙 액션을 호출한다.
+
+    ;;
+
+  *) 
+
+    exit 1
+
+esac
+
+```
+
+→ 
+
+```slack.yml 다른 레포지터리에 있는 깃허브 액션 정의
+
+jobs:
+
+  slack:
+
+    runs-on: ubuntu-latest
+
+    steps:
+
+    - name: Send slack message # 메시지 발송
+
+      uses: dev-chulbuji/devops_custom_actions@master
+
+      with:
+
+        args: slack
+
+      env:
+
+        SLACK_TOKEN: ${{ secrets.SLACK_TOKEN }}
+
+        SLACK_MESSAGE: Push event!!
+
+```
+
+
+
+## CH04_04 CircleCI 소개
+
+* Since 2011 개발
+
+![](/BearImages/8FB83FDC-6CF1-4F11-A573-46B26809C1BF-641-000001BE4ABCEA9E/7A14CD8F-454F-4583-B6C8-FB3D31FB7856.png)
+
+* 컴포넌트
+
+	* Project, Pipelines, Steps, Workflows, Executors
+
+	* Jobs 의 묶음 →  워크플로우
+
+	* Orbs : 재사용성이 높은 코드스니펫 (마켓이 있다)
+
+
+---
+
+## CH04_05  CircleCI 실습
+
+* 로직을 매니페스트하는 파일
+
+`.circleci/config.yml`
+
+* 실습
+
+	1. 깃헙과 연동 - 프로젝트 선택 - config 정의 (repo와 1:1 매칭)
+
+	2. 연동 후엔 Circle CI 웹 콘솔을 통해 REPO 통계와 실행결과 조회
+
+	3. `config.yml`에서 build - test - deploy 단계를 워크플로우로 정의
+
+	4. jobs내의 executor에 대해선 `setup***remote***docker`를 구성해줘야 한다. 
+
+```
+
+	steps:
+
+	   - checkout // 자주 쓰는 명령어는 이렇게 압축해놨다.
+
+```
+
+### Context 
+
+시크릿을 저장해놓는 공간. Orbs에서 요구하는 키값을 미리 저장해놓으면 알아서 읽는다. 그래서 코드를 줄줄이 적지 않아도 된다. (GitHub 는 하나하나 정의해줘야함) 
+
+
+---
+
+# Chapter 5 kubernetes CI/CD
+
+## CH02 argocd
+
+Concept
+
+* GitOPS 기반 워크로드 실행 솔루션. 구체적으론 CD를 담당한다.
+
+	* 설치시 쿠버네티스 내에서 자신의 워크스페이스에서 동작하며, 롤을 만들고 롤에 기반한 토큰을 발행하여 외부에서 api call을 한다.
+
+* Argo를 구동하기 위한 워크로드(앱의 구성요소)
+
+	* API SERVER
+
+	* Repository server
+
+	* Application controller 
+
+	* dex-server
+
+	* argocd-redis
+
+
+---
+
+## CH03 declarative-setup
+
+* 기본 컨셉: 깃허브에 푸시를 하면 argo는 그걸 default 네임스페이스에 반영한다. 
+
+* 디폴트  비밀번호는 configuration - secret 에서 확인가능
+
+### 메뉴와 개념
+
+	****repository* - 연동규칙 by http, SSH
+
+	****Clucster*를 추가하면 현재 아르고가 실행중인 클러스터 말고도 외부 클러스터에 워크로드를 실행할 수 있다.
+
+	****Project* == 네임스페이스와 동일한 로지컬 스코프
+
+	****Role*을 만들어서 path에 따른 권한을 할당, Account 기반 권한관리도 가능하다
+
+### 프로젝트
+
+***프로젝트는 어플리케이션으로 구성되고 하나의 어플리케이션은 여러 워크로드로 구성된다.***
+
+* 어플리케이션 생성
+
+	* 이름, 싱크 정책 지정, 소스(레포지토리, PATH), Destination (`kubernetes.dafault.svc`)
+
+	* 프로젝트에서 사용할 path와 클러스터 설정
+
+* 여러가지 방식으로 리스트를 조회할 수 있다. 어플리케이션들은 싱크 값을 강조하여 보여준다. 각 어플리케이션을 정의하는 yaml의 싱크 상태 ( 정의된 상태, 실제 상태 ) 를 가시적으로 볼 수 있다.
+
+* 기존에 클러스터를 명령어로 관리할때는 하나씩 명령어를 이용해 정의한 yaml 상태값을 apply하던것에 비해 git으로 상태값을 관리할 수 있게 된다.
+
+```appProject.yml
+
+spec:
+
+  project: dev
+
+  source:
+
+    repoURL: https://github.com/dev-chulbuji/devops_k8s.git
+
+    targetRevision: HEAD
+
+    path: sample-yaml
+
+  destination: // 배포할 장소
+
+    server: https://kubernetes.default.svc
+
+    namespace: default
+
+  syncPolicy: // 오토를 안켜면 수동으로만 관리
+
+    syncOptions:
+
+    - Validate=false
+
+    - CreateNamespace=true
+
+    - PrunePropagationPolicy=foreground
+
+```
+
+
+
+### 쿠버네티스 패키지 관리는 helm !‼
+
+```
+
+  source:
+
+    repoURL: https://github.com/dev-chulbuji/devops_k8s.git
+
+    targetRevision: HEAD
+
+    path: sample-helm-1
+
+    helm:
+
+      valueFiles:
+
+        - values.yaml
+
+```
+
+```values.yaml
+
+sentinel:
+
+  port: 26379
+
+// 대충 이런 값들을 저장하기 위해 쓴다.
+
+```
+
+* 사용 시나리오
+
+레포가 바뀐다 -> Out of Sink -> 젠킨스가 감시하고 있다가 트리거 → 트리거에 필요한 토큰과 API 정보를 주면 된다.
+
+```
+
+/{project-name}/sync
+
+// 헤드에 token
+
+```
+
+
+---
+
+### CH04 app of apps 패턴
+
+* 앱을 만드는 앱. 부속품들을 배포하게 된다. 앱을 덩어리로 만드는 느낌이네
+
+```values.yml
+
+apps:
+
+  - name: prometheus-operator
+
+    project: dev
+
+    namespace: prom
+
+    source:
+
+      path: kube-prometheus-stack
+
+      customValues: true
+
+      values:
+
+        - values-local.yaml
+
+  - name: prometheus
+
+    project: dev
+
+    namespace: prom
+
+    source:
+
+      path: prometheus
+
+      customValues: true
+
+      values:
+
+        - values-local.yaml
+
+```
+
+* 모든 앱에 적용될 종속적인 정보를 한곳(app of apps)에서만 설정하면 나머지는 설정한 값을 따라가 준다.  
+
+  
+
+
+---
+
+
+
+### CH05 local-user
+
+* dex 서버를 이용해 외부 인증을 처리
+
+* 가장 베이직하게 yml 에서 매니페스트
+
+```
+
+metadata: (중략)
+
+data:
+
+  account.alce: apiKey, login //이렇게 정의
+
+```
+
+	* 패스워드는 ARGO CLI 를 통해 진행한다.
+
+* 명령어
+
+```bash
+
+argocd login cd.argoproj.io —username admin —-grpc-web
+
+argocd account list
+
+argocd account update-password --acount alice 
+
+```
+
+* ArgoCD RBAC (Roll base access control)
+
+	* local user setup 또는 SSO기반으로 진행할 수 있으며 빌트인 권한이 존재한다.  
+
+```values-local.yaml
+
+server:
+
+	rbacConfig:
+
+    policy.default: role:readonly
+
+```
+
+	* `p, <role*user/group>, <resource>, <action>, <approject>*<object>, allow` 문법에 따라 권한등록
+
+
+---
+
+### CH06 SSO
+
+* 설정: Organization → new → Settings → Developer Setting → new OAuth (name, URL, Authorisation Callback URL) → Got ClicentID , clientSecret (쿠버네티스 시크릿을 이용해 관리하면 좋다)
+
+```
+
+server:
+
+  config:
+
+    dex.config: |
+
+      connectors:
+
+        - type: github
+
+          id: github
+
+          name: GitHub
+
+          config:
+
+            clientID: xxx
+
+            clientSecret: xxx
+
+            orgs:
+
+            - name: xxx
+
+```
+
+* SSO 로그인 UI 활성화 ->  ORG ->  TEAM 생성. -> rbacConfig 설정 추가 -> 깃헙의 조직구성에 따른 RBAC 관리가 가능
+
+* 깃랩, LDAP 다양한 서비스 지원
+
+
+---
+
+### CH07 Kubernetes CICD with Actions
+
+* App repo update -> image update -> config repo 의 values.yaml 업데이트 -> ArgoCD 가 싱크를 맞추고 POD가 업데이트 된다. 
+
+* 설계 하나의 Config repo에 여러개의 App repo를 담는구조. 이걸 위해서 파드는 ECR에 접근할 수 있는 권한이 필요하다. 
+
+*  Actions 동작과정
+
+	1. App repo, `.*github/workflows*cdcd-k8s.yml`
+
+```yaml
+
+  cd:
+
+    needs: [ci]
+
+    runs-on: ubuntu-latest
+
+    steps:
+
+      - name: Checkout Target Repository
+
+        uses: actions/checkout@v2
+
+        with:
+
+          repository: dev-chulbuji/devops_k8s
+
+          path: deploy-k8s
+
+// 일련의 스탭을 담은 액션
+
+```
+
+	2. Config repo. `demo/values.yaml`
+
+```yaml
+
+replicas: 1
+
+image:
+
+  repository: 552661052297.dkr.ecr.ap-northeast-2.amazonaws.com/demo
+
+  tag: 1.2.6
+
+  imagePullSecrets:
+
+    - name: ecr-cred
+
+service:
+
+  type: NodePort
+
+```
+
+여기 TAG 버전을 바꿔주는게 앱 Repo 액션에 담겨있다.  그리고 컨피그 배포에 푸시 배포!
+
+
+
+```App repo .yaml
+
+      - name: Push helm repo
+
+        env:
+
+          token: ${{ secrets.GH_TOKEN }}
+
+          IMAGE_TAG: ${{needs.ci.outputs.IMAGE_TAG}}
+
+        run: |
+
+          cd deploy-k8s
+
+          git config --global user.email "dev-chulbuji@gmail.com"
+
+          git config --global user.name "dev-chulbuji"
+
+
+
+          git add demo/values.yaml demo/values-eks.yaml;
+
+          git commit --message "Update demo image tag to $IMAGE_TAG";
+
+          git config -l | grep 'http\..*\.extraheader' | cut -d= -f1 | xargs -L1 git config --unset-all
+
+          git push --prune https://token:$token@github.com/dev-chulbuji/devops_k8s.git
+
+```
+
+* 이와는 반대로 Argo가 config repo를 풀링 하는 구조(3분주기)도 할 수 있지만 반대로 웹후크로 푸시하는게 낫다.
+
+* ngrok
+
+	* 외부에서 로컬호스트 서비스에 접근할 수 있도록 해주는 서비스, 현재 쿠버가 로컬에서 서비스 중이므로 외부서비스가 클러스터에 접근 할 수 없기 때문에 필요한 서비스
+
+	* `http:*/12312323.ngrok.io` → `http:/*localhost:30080` 이렇게 해준다. 
+
+		* 이제 GitHub Setting에 생성된 URL을 등록한다. 
+
+
+---
+
+### CH08 CircleCI
+
+* 이전의 시나리오와 다른 부분은 Actions가 하던일을 .circleci가 하는점
+
+1. CI
+
+```
+
+  steps: // ... (중략) 테스트 스탭
+
+   -persist_to_workspace:
+
+      root: .
+
+      paths: VERSION // 이렇게 테스트하는 영역을 퍼시트로 선언하면
+
+cd:
+
+  steps:
+
+   - attach_worksapce:
+
+     at: . // 다음 스탭에서 활용할 수 있다.
+
+```
+
+2. CD
+
+```config.yml
+
+          git clone https://github.com/dev-chulbuji/devops_k8s.git && cd devops_k8s;
+
+
+
+          yq eval -i '.image.tag = env(VERSION)' 'demo/values.yaml';
+
+          yq eval -i '.image.tag = env(VERSION)' 'demo/values-eks.yaml';
+
+// 클로닝 한 다음 버전값을 업데이트 했다.
+
+... 중략
+
+workflows:
+
+  cicd:
+
+    jobs:
+
+      - aws-ecr/build-and-push-image: 
+
+···
+
+      - test:
+
+          context: AWS
+
+          requires:
+
+            - build-and-push-image
+
+      - deploy:
+
+          context: GIT // 이건 깃허브에서 제공하는 변수 네임 스페이스
+
+          requires:
+
+            - test
+
+```
+
+	* 깃헙액션이 레포지토리 단위의 배포환경 설정에 특화되어 있다면, Circle CI는 중앙관리형 배포환경 관리가 가능해진다.  성능도 액션보다 빠르다.
+
+3. **전체 워크플로우**
+
+App Repo의 변화를 Circle이 알아차리고 컨픽 Repo를 업데이트. 그리고 컨픽 Repo에 걸려있는 Web hook이 Ngrok를 거쳐 현재 개발중인 로컬의 Argo를 콜. 파드가 배포된다.
+
+
+---
+
+### CH09 AWS EKS
+
+****목표* Argo 를 통해 AWS EKS에 배포, v1.21, prod용, DMZ(public)vpc를 썼지만 실제환경에선 Private권장, 워커로드가 t3.small이라 한다면 워크로드에 대해 붙일 수 있는 파드의 갯수는 11개로 제한된다. Attach limit이 다르다.  [amazon~~eks-ami*eni-max-pods.txt at master · awslabs*amazon-eks~~ami · GitHub](https:*/github.com/awslabs/amazon~~eks-ami/blob/master/files*eni-max~~pods.txt) 이게 Packer 의 EKS config 리소스 배포 
+
+1. EKS 리소스 생성, 컨텍스트를 Lens에 등록, LoadBalancer CTRLER 를 쓰기 위해 VPC 소스에 다음 코드를 추가한다.
+
+```
+
+// main.tf
+
+  public_subnet_tags  = local.public_subnet_tags
+
+  private_subnet_tags = local.private_subnet_tags
+
+// *.auto.tfvars
+
+	private_subnet_tags = { "kubernetes.io/role/internal-elb": 1 }
+
+	public_subnet_tags  = { "kubernetes.io/role/elb": 1 } // 1또는 빈값을 넣어야하는데 이건 eks 리소스 독을 보면 알 수 있다. 이 태그가 있음으로서 LB CTLR이 일을 할 수 있게 된다. 
+
+```
+
+2. EKS를 쓸거니 이번엔 ingress 서비스를 이용해서 외부와 클러스터를 연결해야 한다. 배포가 되면 NGROK이 해주던 일을  이젠 로드밸런스가 하게 됨. 
+
+![](/BearImages/14302489-A0A8-4198-977F-48B3152457C6-76434-000004DD7F908808/008B1B50-8AF1-4B8E-B36C-59233FFC50C7.png)
+
+3. 아르고를 먼저 배포하고, App of Apps를 배포한다.
+
+4. config repo에서 web hook 를 이제 nrok 대신 argo의 서비스 URL을 걸어준다.
+
+5. 크게 달라진건 없다. EKS환경에 따라 인그레스 및 로드밸런스가 해야할일이 생겼을뿐.
+
+
+
+* yq 명령어. jq 와 비슷한 커맨드. 파일의 내용을 바꿔준다. (json → yaml)
+
+`yq e ‘.test = “no”’ ingnore.yml`  e .test란 키르 찾아서 no로 바꾼다는 의미
+
+
+
+
+---
+
+
+
+# Part 7 모니터링 서비스 및 운영 구현
+
+## CH01 - 모니터링 개요
+
+* 개발을 돕는 것이 지금까지 배운것이라면 모니터링은 운영을 돕는다. 데이터를 축적하고 액션 플랜을 다시 개발쪽에 제공해줄 수 있다. 
+
+* Telemetric 원격측정
+
+	* 모니터링, 로깅, 트레이싱( MSA에서 중요하다.) 하나의 사용 시나리오를 보여주는걸 트레이싱이라고 한다.
+
+* 실습시나리오: external, public, private 3단 구조.
+
+	* Application LoadBalancer  , CloudWatch, RDS, EC2, Slack, Prometheus, ElasticSearch, 장애에 대한 조치방안 설정
+
+
+---
+
+
+
+## CH02 - AWS 인프라 모니터링
+
+### _01 CloudWatch 개요
+
+* 모니터링 및 메트릭에 따른 앱 인터그레이션을 자동화
+
+* 도메인 용어
+
+	* namespace. 데이터가 들어갈 공간
+
+	* ‘사용률’로 대변되는 값
+
+	* dimension (동질적인 리소스의 메트릭을 합하는 개념) 예를들어 특정 AMI EC2에 대한 시피유 사용률을 감지
+
+	* Statistics 평균 최소 최대 등 통계값
+
+	* Resolutions (데이터 측정의 단위, 요금과 관계가 있음) Standard(1m), High RES(1s) 로 나뉨 High RES는 과금이 된다.
+
+	* Alarm을 이용하면 스케일링, 문제가 있는 인스턴스를 스탑하는 작업(ec2 action), system mag actions(특정 시스템에 대해 명령어를 내린다거나) , SNS 토픽 발행
+
+		-> 특정 프로세스가 행이 걸리면 가서 크러시 내고 덤프를 저장하는 거 해보자 재밌겠다
+
+
+---
+
+
+
+### _02 Monitoring #1 기초
+
+* basic monitoring은 5분, detail monitoring은 1분, 
+
+* 메트릭: CPU, MEM, Network, MetaDataNoToken, CPU Credit, EBS Metric, Status check metric
+
+	* 특별한 토큰을 가지고 서비스를 호출할 수 있는데 그 양을 메트릭으로 삼을 수 있다. 
+
+	* 버스터 타입(T) 타입은 인스턴스 타임마다 사용량이 기준치를 초과하지 않으면 밸런스를 올려주고 사용량이 많아지면 성능이 늘어난다. 그래서 이 크레딧에 대한 모니터링도 필요하다.
+
+* dedicate (bear metal)
+
+* Status check metrics (normal..?)
+
+* EC2 usage Quota ( 한 리전에서 허락된 최대 리소스 사용량) 그것도 감시가능하다.
+
+* 디테일드 모니터링 옵션을 켜면 과금이 된다. (TF에서도 관련 키가 있어~)
+
+* Metrics 을 쿼리할 수도 있고 다양한 포맷으로 조회할 수 있다. (그래프 등)
+
+* Period, Vertical annotation
+
+* JSON 형식으로 API 쿼리를 해서 결과를 받을 수도 있다
+
+* 굳이 하나 하나 안만들어도 기본적인 대시보드를 셋팅해놓았다. 
+
+
+---
+
+
+
+### _02 Monitoring #1 커스텀 매트릭
+
+* 위에서 설명한건 다 제공하지만 프로덕션에서 특이한 것들을 모니터링해야한다면 커스터마이징한 메트릭을 만들어내야한다. 이건 CW agent 프로세스를 통해 put metric 으로 생성한다. 이걸 위해 EC2에게 IAM 권한도 필요
+
+1. DMZ EC2를 관찰할 예정. 기본 메트릭 말고도 다른거를 보내는 내용 실습. 
+
+2. 별도의 롤을 EC2 에 attach ( CloudWatchAgentServerPolicy )
+
+3. 설치는 `userdata.sh	` amazon~~cloudwatch~~agent 를 yum 으로 설치
+
+4. `sudo *opt/aws/amazon~~cloudwatch-agent/bin*… config~~wizard` (telegraph 기반)
+
+위자드 형태로 config를 생성해준다. on-premise를 지원한다 -> 복합적인 구성도 가능하다.
+
+`*opt/aws/amazon~~cloudwatch~~agent/bin*config.json`에 생성된 값 확인가능
+
+5. API DOC → 수집가능한 메트릭의 리스트  
+
+```bash
+
+wget \
+
+  https://raw.githubusercontent.com/dev-chulbuji/devops_infra/master/apne2/dev/ec2/bastion/templates/cloudwatch-agent-config.json \
+
+  -O /opt/aws/amazon-cloudwatch-agent/bin/config.json
+
+
+
+# run agent
+
+sudo amazon-cloudwatch-agent-ctl \
+
+  -a fetch-config \
+
+  -m ec2 \
+
+  -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json \
+
+  -s
+
+```
+
+이렇게 하면 에이전트가 동작하기 시작한다.
+
+* 커스텀 대시보드를 만들기
+
+* CloudWatch agent configuration
+
+1. agent: assume이라고 한다. EC2을 권한으로 에이전트가 동작하는걸
+
+2. logs : nginginx를 쓴다고 할떄 로그를 클라우드 워치에서 로그를 보고 싶다면 path를 잡아서 바로 볼 수 있다. 시스템레벨 + 프로세스레벨 로그 둘다 가능!
+
+3. metrics
+
+* userdata 리소스를 이용해서 에이전트와 config를 넣으면 편하게 수집가능
+
+	* 동일하게 셋팅을 했으니 Log groups > *aws/ec2/var/log*messages 그룹에 들어가면 인스턴스아이디별로 수집이 되는걸 볼 수 있다. 
+
+	* 잘 트래킹하고 싶으면 시간을 잘 동기화 시킬것  `timedatectl set-timezone Asia/Seoul`
+
+
+---
+
+
+
+### _05 ALB logging
+
+* 프로비저닝과 동시에 메트릭이 수집된다. HTTP status Code count 이런것도 수집이 되므로 연동해서 전략을 짤 수 있다. 
+
+* ALoadBalancer attribute를 수정하면 accesslog를 s3에 저장하도록 셋팅 할 수 있다. 버킷 폴리시를 줘야한다. (여기선 자동생성)
+
+* AWS의 서비스는 하나의 서비스가 마이크로 서비스로 짜여져 있다. 염두하면 이해하기 편하다.
+
+### S3에 쌓이는 로그 정보를 처리하기
+
+1. Athena가 직접 해석해서 서비스. 그냥 RDB처럼 보이는데 저장공간은 S3를 쓴다. 5TB에 아주 쬐금 과금 됨. 
+
+	1. 쿼리 결과를 저장할 S3를 지정한다.
+
+	2. DB, Table을 생성해준다. 공식 DOC에서 제공하는 생성 스크립트에 location, region 만 바꿔도 됨
+
+	3. 이제 SQL이랑 동일하게 쿼리를 하면 결과를 볼 수 있다.
+
+2. AWS Lambda가 주기적으로 패턴을 잡아서 호출
+
+	1. 모든 걸 클라우드에서 하고 싶다! 그럴때 사용하는 전략
+
+	2. S3이벤트를 받아서 파싱 후 클라우드 워치로 전송하는 코드.  보내는 포맷은 json, alb 선택가능.
+
+
+---
+
+### _03 CloudWatch Alarm #1 ~ #3
+
+* collect(metrics, log) -> evaluation (static 판단 / abnormal 판단 지원) -> alarm -> action (sms, ec2, sailing, system manager)
+
+* 알람의 옵션들
+
+	* datapoint는 period 이내에 몇번의 유효판단을 요구할지
+
+	* Alarm Status : OK ALARM INSUFFICIENT DATA
+
+* 누락 데이터 처리전략 
+
+	* notBreaching(treat as good)
+
+	* breaching ( breaching the threshold)
+
+	* ignore(알람 상태를 유지), missing (미싱이라고 지정)
+
+* subscription filter 를 통해 이벤트 소스(에러) 에 따른 액션을 취할 수 있다. lambda, kinesis, opensearch를 호출하는 구조. 다만 이런건 datapoint 기능이 없다.
+
+	* 이걸 하기 위해선 로그의 발생을 metric화하면 된다. 
+
+
+---
+
+
+
+### 실습시나리오
+
+* watch -> SNS -> Lambda | chatbot -> slack
+
+1. SNS 설정 (cloud watch 에서 관측할 topic을 생성)
+
+2. 챗봇에서 슬랙에 대한 new channel을 허용.
+
+3. Alarm을 만들어놓고 insufficient data 상태에서 시작, stress로 데이터 값 내고 ->   알람방생
+
+
+
+* 로그기반 알람 실습
+
+1. 시나리오, 읽은 로그를 통해 람다를 실행
+
+2. 클라우드워치에 람다를 실행할 권한을 준다.
+
+3. log groups -> subscription filter -> oom 이렇게 패턴을 건다. 패턴 검증도 가능
+
+4. Log groups (로그스트림)에 잘 쌓였는지 보고 람다도 실행된다. 
+
+
+
+* Log Insight
+
+1. 쿼리를 날리듯이 짜놓으면 메트릭화할 수 있다.
+
+2. Create metric filter. 1) Define pattern - 키워드를 패턴을 잡거나 accesslog처럼 형식이 있거나 하겠지. 그걸 원하는 대로 잡을 수 있다. filter pattern `${$.target***processing***time = 0.001 }`  ‘Metric Value ->  잡은 패턴값 그대로 쓸 수도 1로 쓸 수도 있다. (필드값을 따오고 싶으면 $로 참조)
+
+3. 이제 로그 그룹스에 Metric filter 탭을 확인할 수 있다 
+
+4. 이제 알람을 생성 -> 추가설정 만들값을 고른다.`$.target***processing***time` 선택
+
+****Sumaary -> 로그를 메트릭 수치화 해서 대시보드에서 보거나 알람기능과 연동할 수 있다.!*
+
+
+---
+
+## CH03 - metric 모니터링 시스템 구축
+
+### Introduce Prometheus
+
+* 모니터링의 두 개의 컨셉
+
+	1. Push, coping metric backend system, require agent
+
+	2. Poll, require service discovery, easy to update setting
+
+* 소개
+
+	* PromQL, multi-dimentional
+
+	* pull method, Collect, Store time-series
+
+	* pushgateway ( 풀링이 적합하지 않은 리소스 eg. crontab)은 여기에 정보를 쌓고 server가 게이트웨이에서 풀링
+
+* 컴포넌트
+
+![](/BearImages/870777DA-620F-4B29-860A-8030D980093E-76434-000008ACBFB98A02/D9B0856C-6634-4EAE-B6F9-2B4698F029D5.png)
+
+* Metric type
+
+	* Counter (cumulative metric only up)
+
+	* Gauge (up & down)
+
+	* Histogram (sables observations), 0.3초보다 낮은 애들만 모으고 싶다. 이렇게 선언하여 버켓에 데이터를 저장할 수 있다. 서버측의 서버측 계산이 많다.
+
+	* Summary: 특정 기간 동안의 클라이언트 사이드에서 계산을 해서 서버로 던진다.
+
+* 메트릭의 구성
+
+	**name, label key = label value, metric value**(scalar)*
+
+****샘플* 
+
+	* 프로메테우스에서 데이터를 일컫는, 검색을 하면 특정 시간대를 보여준다. 동일 시간대의 샘플 묶음을 인스턴스 벡터라 한다. 
+
+	**prometheus***http***requests_total [1m] 이렇게 검색을 할 수 있는데 이건**레인지 벡터*라한다.
+
+		* 하나의 샘플 안에 스칼라는 여러개의 스칼라를 가진다.
+
+* 레인저 벡터
+
+	* 시간 대역 대의 여러개의 값을 라 한다.
+
+* PromQL
+
+	* instance Vector selector 의 동작 코드가 200인 애들만 보고 싶다면? `prometheus***http***requests_total{code=“2—“)` regex나 논리표현도 지원한다. `code!=“200”`
+
+	* `offset 1m` 1분전 데이터를 가져오고 싶다. UNIX epoch도 쓸 수 있다. 
+
+	****operation*  → 인스턴스 벡터를 대상으로만 사용할 수 있다. 
+
+		* sum, min, max, avg, stddev, count, count_values(값 별로 몇개 인지), bottomk(가장 작은), tops, quantile(분위수)
+
+	* GROUP BY - SQL 과 비슷하다. 묶어야 데이터가 의미있어지지
+
+		* BY (끼리끼리), Without (라벨을 무시)
+
+	* JOIN
+
+		* one to one 
+
+`method***code:http***errors:rate5m{code="500"} / ignoring(code) method:http_requests:rate5m` 코드를 무시하고 두개를 검색하고 같은 검색이 된것끼리 나누기 연산을 했다.
+
+	* one to Many
+
+		* 카디널리티가 높다. (모수)가 많다. (숫자가 많다) Group left면 모수가 많은 쪽이 왼쪽에 가야 한다.
+
+`method***code:http***errors:rate5m / ignoring(code) group***left method:http***requests:rate5m`
+
+***MyOp: 이렇게 결과를 쉽게 조작해서 의도된 좋은 데이터를 모니터링의 기준으로 삼을 수 있는게 환상적이네***
+
+
+
+* Prometheus Configuration 
+
+	* 두가지 설정법
+
+		* command-line flag
+
+		* configuration file
+
+	* 어떤 쿼리를 했는지 저장할 수 있는 로그를 지정할 수도 있다.
+
+		* `global, rule***files, scrape***configs, alerting, remote***write, remote***read, storage`
+
+	* 자주 쓰거나 부하가 큰 것들은 캐시를 지정해놓을 수 있다.
+
+```dj.alerts.yaml
+
+    rules:
+
+      - alert: alerts:cpu_usage:prometheus:80
+
+        expr: rate(process_cpu_seconds_total{job=~"prometheus"}[1m]) * 100 > 0
+
+```
+
+* prom tool check rules [name] 으로 yaml 의 문법 정합성을 체크할 수 있다. 
+
+	* 얼럿을 미리 PromQL로 yaml에 정의해서 레코드가 쌓이는걸 볼 수 있다.
+
+* 프로메테우스는 단일 서버에 DSDB에 데이터를 쌓는데 이렇게 되니 성능문제가 생기기 쉽고 스케일아웃도 쉽지 않다. 떄문에 확장을 지원하기 위해 `remote_write, read` 샤딩 형태를 API로 구현한다.
+
+* Scrap_configs
+
+	* 가장 많이 설정하는 내용
+
+```prometheus.yml
+
+scrape_configs:
+
+  - job_name: prometheus
+
+    scrape_interval: 15s
+
+    metrics_path: /metrics
+
+    static_configs:
+
+      - targets: [ 'localhost:9090' ] #override Global
+
+```
+
+	* 타겟(호스트)에 대한 컨픽(이건 스케일아웃되면 답이 없지), 파일을 읽어 서비스 디스커버리를 자동으로 변경하도록 설정 
+
+```
+
+ - job_name: ‘dj-custom-file-sd’ #별도의 타겟을 지정하게 되고 설정한 내용을 웹에서 볼 수 있다.
+
+   file_sd_configs:
+
+     - files:
+
+         - /etc/prometheus/sd/dj_custom.json
+
+       refresh_interval: 10s
+
+```
+
+
+
+* 아래와 같은 서비스 디스커버리를 등록해놓았고 
+
+```
+
+ - job_name: ‘dj-custom’
+
+   scrape_interval: 10s
+
+   scrape_timeout: 10s
+
+   metrics_path: /metrics
+
+   scheme: http
+
+   http_sd_configs: //동적으로 타겟서비스를 찾아내는 리소스
+
+     - follow_redirects: false
+
+       refresh_interval: 1s
+
+       url: http://sdapp:8080/targets
+
+```
+
+`curl -XPOST ~~v http:*/localhost:9090/~~*reload` 이렇게 해놓으면 파일 dj-custom이란 디스커버리를 등록하여 체크한다. 이상태에서 서비스 호스트를 더 많이 추가하면 타겟이 추가되어도  자동으로 추가된다. 
+
+	* 	이런 sd들이 거의 모든 AWS 서비스에 다 존재한다. 
+
+	* 태그를 이용해 모니터링 여부를 컨트롤하는 팁.
+
+* Relabeling
+
+	* Add Label by host’s meta data
+
+* 룰 (얼럿, 사정저의 값으로 알람생성, 룰 - 캐시정보 생성)
+
+### Install Prometheus
+
+* 미리 config 용 yml을 작성하고 도커를 올릴때 volumes로 업로드한다. 커스텀 네트워크를 사용하여 도커와 도커를 연결
+
+* 그라파나를 써서 datasources를 프로메테우스를 지정하면 프로메테우스의 부족한 데이터 조회 기능을 보완할 수 있다. 프메가 데이터 소스를 제공하고 그라파나는 시각화 
+
+1. 데이터 소스는 엘라스틱서치, 프로메테우스 다양하게 지원
+
+2. node-exporter 메트릭을 외부에 노출 시켜주는주는 앱 (≈  CW agent)
+
+### Install Kubernetes
+
+```values-eks.yaml 
+
+server:
+
+  replicas: 1
+
+  service:
+
+    type: NodePort
+
+    namedTargetPort: false
+
+  ingress:
+
+    enabled: true
+
+    annotations:
+
+      kubernetes.io/ingress.class: alb
+
+      alb.ingress.kubernetes.io/scheme: internet-facing // 사내에선 internal로 설정한다. 
+
+      alb.ingress.kubernetes.io/tags: Environment=prod,Name=argocd-alb
+
+  extraArgs:
+
+    - —insecure
+
+  config:
+
+    accounts.admin: apiKey, login
+
+    repositories: |
+
+      - url: https://github.com/dev-chulbuji/devops_k8s.git
+
+      - url: https://github.com/dev-chulbuji/devops_sample_app_python.git
+
+
+
+```
+
+쿠버네티스에 접근하기 위한 인그레스 LoadBalancer 및 인그레스 설정 추가만된다.
+
+
+---
+
+
+
+### Prometheus Metric
+
+* 프로메테우스가 이해할 수 있는 메트릭으로 뽑아내는걸 라이브러리를 사용해 만들 수 있다. exporter를 사용하면 만들지 않고 알아서 제공하게 할 수도 있다. 
+
+* 네트워크에러가 나면 `docker network create monitoring`dㅇ
+
+* 단독실행되던 도커 옆에 node***exporter를 붙여서 컴포즈하고 scrape***configs에 잡을 등록해주면 끝. 
+
+* 이제 그라파나에서 대시보드 마켓에서 번호등록
+
+* nginx~~prometheus~~exporter
+
+	* 8080:80, export도 같이 컴포즈에 넣어준다. 9113:9113으로 노출, `nginginx.scrape~~uri http:*/nginx/metrics -web.telemetry~~path=*metrics`
+
+```nginx.conf
+
+  location /metrics {
+
+    stub_status on;
+
+    access_log off;
+
+    allow all;
+
+  }
+
+```
+
+	* 이렇게 정볼르 노출시킬 패스를 만들어주고 이걸 Exporte가 참조한다. 
+
+* Blackbox-exporter 
+
+	* 어플리케이션(워크로드)의 성격에 따라 커스텀 모니터링을 할 수 없다. 그러니 일단 잘 떠있는지 등 기본적인 것들은 공통이니 모니터링 하기 위해서 쓴다. 
+
+	* `host.docker.internal` 도커에서 내부에서 로컬호스트를 가르킬 수 있도록 쓰는 도메인
+
+	* `_***address***_`는 target 리소스에 등록한 호스트들을 가르킨다.
+
+	* 이렇게 컴포즈 해놓고 나면 익스포터는 앱의 활동을 감시하는걸 curl을 해보면 알 수 있다. 
+
+* prometheus~~flask~~exporter (라이브러리 형태로 exporter)
+
+	* `import PrometheusMetrics` APM 같은 기분을 내준다. function level 에서 헤비한 작업을 한다고 했을때 그걸 측정하게 해주는 라이브러리. 코드로 등록하고, compose대시보드를 등록하고 
+
+
+---
+
+
+
+### Kubernetes 리소스를 상태를 수집하기 위해 node~~exporter-Kube~~
+
+* 프로메테우스에 대해 다음의 쿼리를 날리면`label***values(kube***namespace***created,exported***namespace)`  네임스페이스를 탭으로 표시해서 대시보드를 나눌 수 있다. 
+
+* `sum(kube***pod***labels(exported_namespace=“$namespace:”})`이렇게 하면 적용중인 네임스페이스의 파드라벨의 합을 보여준다.
+
+**`kube***service***createdexported_namespace=“$namespace:”, pod=~"$service.**})` -> Kubernetes 를 제외하고 상단 셀렉터에서 고른 서비스를 쿼리. 멀티밸류는 꺼줘야 원하는 값이 나온다.
+
+	**`container***cpu***usage***seconds***total{namespace=$namespace”, image=“”, pod=~”$service.**”}[1m`  전체 CPU  자원 점유량을 표현, `contiainer***memory***res`를 사용하면  메모리 사용량을 체크할 수 있다. 
+
+* 사이드 메뉴 사용법 주절주절 딱보면 다 알 수 있다.
+
+	* value mapping (특정값이 도달하면 발동) 
+
+
+---
+
+
+
+### Prometheus Alarm
+
+* 	Alertmanager 기반으로 여러 통신매체에게 전달하는식으로 Alert를 처리. 프로메테우스가 아니라도 매니저에게 통신요청 가능
+
+	* Features: duplicating, grouping, sending, silencing, inhibition, HA
+
+* Install
+
+```alertmanager.config.yml
+
+global // 서비스 및 권한정보 
+
+route //받은 메시지를 처리하는 방법에 대해 정의, 재발생주기, continue(case fallthrough 같은 키워드)
+
+receiver: // 누가 받을지 어떤 채널에 보낼지, 어떤 내용과 제ㅔ목
+
+inhibit_rules // 상위 등급의 알람이 왔을때 하위 알람을 무시하겠다.
+
+templates: p[] // title, text 등 자주 쓰는 컨텐츠를 템플릿으로 관리하는 방법 지원
+
+```
+
+* smtp***auth***password 등은 계정에서 앱 패스워드를 발급할 수 있는데 보통 그걸 입력하면된다. 슬랙도 마찬가지다.
+
+```prometheus.yml
+
+alerting:
+
+  alertmanager:
+
+  - scheme : http
+
+  api_version: v2 
+
+```
+
+* HA 컨셉
+
+![](/BearImages/82C74298-AB5C-41BA-B011-FF35EE5D13FA-76434-00000A38C4B69400/63644837-58F7-41E2-B344-CA6D8AED3649.png)
+
+	* Alertmanager는 웹에서 확인가능하고 히스토리를 다 조회할 수 있다. 굉장히 유연하게 알러트를 발생시키고 관리할 수 있네 좋다야.. 
+
+### 	Alerting Making, Alert manager 를 거치지 않고 직접 발생시키기
+
+* 슬랙 채널의 정보를 입력
+
+* Edit panel -> Rule, condition -> 컨텐츠 설정
+
+
+---
+
+
+
+## CH04 - logging 시스템
+
+## CH04_01 ELK Stack 소개
+
+* 각 서비스의 이름을 합친거. 여기에 Beat 시리즈가 합쳐져 스택이 됐다.
+
+* Workload logging
+
+	* 옛날의 방법,  `Application + Log` 는 기본적인 동작 App’s stdout 하는 걸 파일로 기록하고 이를 호스트에 접속해 직접 본다.
+
+	* 각각의 호스트를 접속해야한다는 전제조건이 생기는데, 클라우드 네이티브 환경에선 application 과 호스트가 디커플링된다. (종속성이 사라진다) 어떤 앱이 어떤 호스트에서 뜨는지 연결할 수가 없다.
+
+	**이 문제를 해결하기 위해 파일비트 데몬이 로그를 읽어서**Elasticsearch**로 보낸다. 여기서 더 필요하면**Kibana*가 일을 하면 된다.
+
+	**파일비트의 설정을 바꿔야하는 시나리오에서 하나씩 접속할 수는 없으니 설정의 관리와 로그의 파싱은**logstash*가 추상화 추상화 레이어로서 동작한다. HA를 구현하거나 queue 서비스를 합쳐서 메시지 정합성을 구현한다.
+
+	* 로그들을 파이프라인으로 관리는게 이번 챕터의 목표
+
+
+---
+
+
+
+## CH04_02 ELK Component Elasticsearch
+
+* 정형, 비정형 데이터 검색 및 분석 툴, Apache Lucene(java 기반 고성능 검색 library), 2010년에 출시, HA와 API를 제공한다 -> 여러 서비스와 integration
+
+* 비교한다면 RDB? Inverted file index (vs row), 풀텍스트 데이터 검색에 용이(vs 데이터 수정, 삭제에 용이)
+
+	* IFI? 문자가 들어오면 전부 다 쪼개서 테이블로 관리한다. `1  best 2,3` 
+
+* Document
+
+	****데이터 단위(serialized json), collection of Field, Field=(key-value)*
+
+	****Index, collection of Document*
+
+	* primary shard, replica shard 를 통해 HA구현
+
+	* Mapping: support dynamic mapping. JSON으로 넣는다 하더라도 알아서 타입을 지정해서 관리해준다.
+
+* HA가 중요하잖아.
+
+	* 9200 - to Client / 9300 -  to Node
+
+	* Master Node -> index metadata + shard location + cluster status
+
+		* `elasticsearch.yml` 에 `node.master: true` 설정을 하여 마스터 후보군을 설정한다.
+
+		* 후보군간엔 마스터만 관리하는 데이터를 공유한다. master가 너무 많으면 불필요한 통신이 많아진다.
+
+	* Data Node -> store index data, `node.data: true`
+
+* Split Brain Concept
+
+	* Master 는 홀수개로 지정, (짝수면 문제가 생겼을때 각각 마스터 정보를 가지게 된다) v7부터 split brain문제를 해결하는 알고리즘이 들어갔고 그냥 홀수개로만 하면 된다. 
+
+* Stack Component
+
+	* 도큐먼트의 묶음이 Index(indices), 저장을 indexing ~~> es01(PRI-0,PRI~~3, REP~~1, REP~~4), es02(PRI~~1,PRI-4,REP-0,REP2), es03(PRI-2,REP~~3) 이렇게 데이터를 쪼개서 데이터를 보존한다. P가 죽으면 남은 서버의 R이 P로 승격하고 파괴된 REP 샤드는 남은 노드 중에 한개에 생성된다.
+
+
+---
+
+
+
+## CH04_03 ELK Component Elasticsearch 설치
+
+* 	도커를 이용해 Elasticsearch 설치 (master 1, Data 2)
+
+```docker-compose.yml 
+
+ES_SETTING_BOOTSTRAP_MEMORY__LOCK:”true”
+
+node.roles: master
+
+cluster.initial_master_node: esm01
+
+discovery.seed_hosts: esm01, esd01, esd02
+
+(...)
+
+```
+
+* `:9200/_nodes` 이렇게 API 호출을 하면 현재 클러스터의 구성정보를 조회할 수 있다. 
+
+* 키바나를 켜면 KIBANA 쿼리 문법을 통해 정보를 받을 수 있다.
+
+	* `GET _nodes`
+
+	* `GET ***cluster*health` -> PRI 샤드가 배분안됐을때 RED, REP 샤드가 Assign안 되어있을때 옐로우, GET `***cluster*setting?inlcude_defaults=true` 동시성 리밸런스 등 설정 내용을 확인가능 (이게 튜닝포인트)
+
+```
+
+PUT devops/_doc/1
+
+{
+
+  "title": "",
+
+  "chapter": ""
+
+} // 이런 형식으로 인덱스를 넣을 수 있다.
+
+```
+
+	* `GET devops*_doc*1`으로  정보를 조회할 수 있다.
+
+	**`GET devops/_maaping`을 하면 다이나믹 타입을 결과를 알 수 있다.**ES는 다이나믹 매핑을 할때 가장 보수적인 매핑을 한다.* (즉 성능이 떨어진다, 튜닝할 부분이 있다) 이미 설정된 매핑은 바꿀 수가 없다. 
+
+	* 한번 매핑이 되고 나면 다른 타입을 넣으려고 할때 에러가 발생하기 시작한다.
+
+	* `DELETE develops*_doc*1`
+
+	* `POST devops*_update*1` `{ “doc”: { “title”:”devops1”}}`
+
+	* 직접 API를 날린다면 뭔가 이벤트 상황일것이다. 일반적으론 호출 할일이 없을테니까. 중요한건 
+
+
+---
+
+
+
+## CH04_04 ELK Component Kibana
+
+* Elasticsearch 색인 데이터를 검색하고 시각화 해주는툴
+
+	* discover, dashboard, canvas, lens
+
+	* KQL(Query Lang), es cluster monitoring(X-pack)
+
+		* Term:
+
+			* text: a b c 
+
+			* text: “a b c” 문장
+
+		* Boolean : response: (200 or 400)
+
+		* Range : bytes > 100 and bytes < 1000
+
+		**Exist: currency:**
+
+		**Wildcard machine.os:win**
+
+* 컴포즈하고 샘플데이터 추가 -> Dev Tool -> 기본적인 KQL 로 조회가능
+
+* `Discover`는 인덱스로부터 시간과 키워드로 데이터를 조회할 수 있다.
+
+	* `toggle columm in table`로 데이터 뷰를 바꿀 수 있음 마치 RDB처럼 동작한다. 보기도 좋아
+
+	* 이런 검색문들은 save해놓고 반복적으로 쓸 수 있다.
+
+	* KQL을 GUI 로 만들어준다. (JIRA에도 있던거네)
+
+	* popular 등 다양한 비쥬얼라이제이션과 통계들을 볼 수 있다. (오호)
+
+* Stack Management
+
+	* 인덱스 정보들을 관리할 수 있다.
+
+* Stack Monitoring을 통해 관련 툴들의 헬스를 체크할 수 있다.
+
+	* 도커에 metricbeat.yml 을 등록해놓아 `metricbeat`를 설정해 데이터를 노출시켜놓는다. 
+
+
+---
+
+
+
+## CH04_04 ELK Component Beat
+
+* 원래는 Logstash의 일부였으나 기능이 너무 커져 분리
+
+	* 	audit, File, Metric, Packet, Heart(uptime), Winlog, Function(서버리스용)
+
+* 도커구성
+
+	* nginx(host Vol 마운트) + shipper(filebeat.yml, log mount)
+
+	* .yml content -> `log path`, `output.elasticsearch:`
+
+	* 파일비트가 던지는 것을 관리하는 ILM 설정 해주지 않으면 디폴트 정책 사용 
+
+* 키바나 구성
+
+	* 이제 KIBANA - Stack Mag -> Create index pattern (name, timestamp) 로그가 수집되기 시작한다. 한줄짜리 메시지가 수집되기 시작하면 각 로그들이 키밸류로 다 쪼개져서 테이블로 만들 수 있는 상태가 된다.
+
+
+---
+
+## CH04_04 ELK Component Logstash
+
+* 인풋 -> 필터 -> 아웃풋 파이프라인 구축해주는 데이터 수집 엔진, jRuby (Ruby voer JVM) 
+
+* Pipeline
+
+```
+
+input {}
+
+filter {}
+
+output {} // 어디(엘라스틱 + 인덱스) 로 보낼지 , 메타정보를 컨트롤 할 수 도 있다.
+
+```
+
+*  output은 인덱스 관리의 기준이 된다. (롤오버) ILM을 안쓰면 로그스태시에서 메타데이터로 날짜를 넣어(YYYY MM 같은) 인덱싱할 수 있다.
+
+****filter*
+
+	* grok pattern: `PATTERN: {identifier}` 이런식으로 정의를 해놓으면 JSON으로 만들어준다. Serializer의 역할
+
+	* mutate: 플러그인들이 많다. rename, uppercase, join, copy, sub 등 비트 사이의 추상계층이므로 여기서 값을 잘 정의해놓으면 비트에서 설정을 변경할 필요가 없어진다 . convert ( 다이나믹 타입을 바꿀 수 있다, 인덱스를 갈아 엎지않고 그냥 여기서 바꾸면 좋다)
+
+```
+
+filter {
+
+  mutate {
+
+   split => { "hostname:" => "." } // 해당 문자로 list로 만듬
+
+   add_filed => { "shortHostname" => "${[hostname][0]"}
+
+   }}
+
+```
+
+	* rename을 여러번하고 종속성을 가질때 sequence가 보증되지 않는다. 주의!
+
+```logstash.yml
+
+config.reload.automate: true // (프로세스를 자동으로 재기동 시켜줌, 실습에 유용)
+
+```
+
+* 이제 Elasticsearch 로 바로 보내지 않을거니 Beat의 설정도 로그스태시로 보낸다.
+
+	* grok은 값을 후처리를 하기 위해 유용하다. For example, `gioip`플러그인은 퍼블릭 IP의 지리적 정보를 보여준다. 그러면 이걸 위해 Host IP를 grok으로 잡아서 인자(`source`)로 던져줘야한다. 
+
+
+---
+
+
+
+## CH04_04 ELK Component in Kubernetes
+
+* Kubernetes 에서 각 노드에 설치된 비트가 logstash를 바라보게 만드는 구조
+
+	* elasticsearch와 kibana는 Kubernetes 와 독립적인 환경에서 실행, 안에서 운영하면 언제 죽을지 모르니 안정적이지 않다.
+
+	* EKS든 도커 데스크탑 환경이든 큰 차이는 없다. (ingress 설정만 다르다)
+
+* 구성
+
+`host.docker.internal:9200`으로 output
+
+구성을 마치면 index create
+
+
+---
+
+
+
+## CH04_04 ELK Component aws SaaS 이
+
+* 시나리오 1. node -> watch subscription filter -> lambda -> Elasticsearch 
+
+* 시나리오 2. node (with fluent bit) -> aws KINESIS -> Elasticsearch 
+
+	* 키네시스  (메시지스트림  만들어줌), 람다를 불러서 로그를 가공할 수 있다.
+
+		* fluent bit는 이 만들어진 스트림을 가르키게 한다.
+
+	* 
+
+* aws tf 구성 ->  argo CD로 app 및 LoadBalancer ctrl makefile 배포 ->  아르고 synk
+
+* 렌즈 대신 중앙 집중 로그관리 
+
+
+
+
+---
+
+
+
+# Part 8 AWS 기반 보안
+
+* 클라우드가 완벽하지 않다 .정보유출사건이 간간이 있었다.
+
+* AWS Shared Responsibility Model
+
+	* 클라우드의 보안, 클라우드에서의 보안
+
+	* PaaS -> CaaS -> SaaS 하지만 결국 data는 항상 사용자의 책임
+
+* Security Service
+
+![](/BearImages/29AC0C7E-4A0E-49C3-B371-1776336F5D2D-76434-00000F0197EF3C7C/EA88D17B-DB0C-401F-9FAC-829770588D4E.png)
+
+
+
+* CloudTrail, Audit 서비스  CloudWatch 
+
+* Amazon GuardDuty 보안 자동화 서비스
+
+* Amazon Inspector 검사 서비스
+
+* S3 - Amazon Macie —> Security Hub (보안 중앙관리)
+
+* AWS WAF (엣지단계 동작) AWS Shieled(DDOS)
+
+* tenant를 구분하는게 가장 좋다. 컨트롤 타워, Devops, Security Account 나누면 운영이슈가 발생한다.
+
+
+---
+
+
+
+## AWS IAM
+
+* 	Root, User - Role, STS (Security Token Service) 임시 발행 life time 존재
+
+* AWS 서비스는 API 콜을 통해 이뤄지고 이때 SigV4로 사인된다. 이 사인을 검증하는게 IAM
+
+* Policy
+
+	* SCP (Service Control Policy)
+
+		* org 내 정책, OU  or AWS Account 레벨에선의 정책
+
+	* Permission Policy, Permission Boundary
+
+		* 정책과 바운더리 교집합이 사용가능한 자
+
+	* Session Policy
+
+		* sms, federation 시 권한 제어 
+
+	* Resource-based Policy
+
+		* identity가 아니라 리소스 자체에 권한제어(S3, SQS, KMS, ECR)
+
+	* Endpoint Policy
+
+		* Gateway type vpc endpoint
+
+* IAM Policy
+
+	* Effect (Allow, Deny)
+
+	* Principle ( 대상, 누가?)
+
+	* Action ( 행위 ) 
+
+	**Resource (무엇을) `"Resource":"are:aws:s3:::DOC/***test**”`
+
+	* Condition
+
+		* 컨디션 오퍼레이터를 통해 태그를 정책을 강제할 수 있다 .
+
+
+
+* `Event Bridge(AWS의 cron)` -> lambda -> IAM Policy 
+
+
+
+* User Group
+
+	* 여기에 User와 Policy를 Attach
+
+* IAM Role
+
+	* Policy를 Attach를 해서 리소스나 아이덴티티에 권한 부여 가능
+
+* Access Mng 절차
+
+	* Identity에 붙이는 권한, 리소스 베이스 권한의 교집합이 사용가능하다. 모든 리소스가 리소스 베이스 policy를 가지는건 아니다.
+
+	* Permission boundary && Identity based Policy && Resource base Policy
+
+		* SCP 에서 Organisation SCP 를 걸었으면 또 이것도 추가
+
+* 동일계정일때는 한쪽 (아이덴티티, 베이스) 만 되어도 되지만
+
+	* 다른 계정일때는 교집합이 되어야 한다. 
+
+
+---
+
+
+
+### Assume (재밌는 요소)
+
+* 컨셉: EC2에 정책을 Attach하지 않고 (깔끔하게) 요청을 하려면 EC2의 롤이 관련된 롤을 Assume하게 만들면 된다.
+
+1. 예를 들어 한 `Master-Role`이 `Master Policy`를 가지고 있다.
+
+2. `Master-Role`의 `Trust Relationship` 탭에서 `Action:AssumeRole` `Principle: {role:prod***role}`이라고 설정하면 prod***role은 마스터롤을 Assume할 수 있게 된다.
+
+3. 이렇게 하면 prod_role에 아무것도 attach안하고 권한을 얻게 된다.
+
+4. `vi  ~*.aws*credentials`
+
+5. `[assume] region: , credential***source, role***arn:master_role` 이렇게 profile을 만들어놓고
+
+6. `aws —profile assume s3 ls` 이렇게 하면 assume이 된다.
+
+### Switch Role 컨셉
+
+1. assume 설정을 해놓고 게정 메뉴에서 스윗치를 한다.  할때 마스터 롤이 A에서 Token을 준다. 
+
+### terraform runner Role
+
+* 각 유저가 이 권한을 Assume하도록 권한을 구조를 짜면 편리하게 권한 관리 가능
+
+1. runner 롤을 만들고 dj에 대해 trust relationship을 등록해준다.
+
+2.  aws configure —profile  dj-partial -> 액세스키를 물어보면 runner role에서 발급한 액세스키를 입력한다.
+
+### ABAC (Attribute-based Access Control)
+
+* 태그를 기준으로 컨트롤 하는걸 말한다.
+
+* 데브 유저는 데브 EC2를.. 이렇게 컨트롤
+
+
+---
+
+
+
+## IAM 보안 Best Practice
+
+* `ROOT` Account - 사용하지 않는게 베스트, MFA를 활성화하고 그리고 다음 방법을 통해 사용을 감시한다.
+
+	1. Cloud Trail 생성 + Cloud Watch 에 로그 남기기
+
+	2. EventBridge -> rules -> Event Pattern (custom) -> 로그인 and ROOT -> SNS -> publish
+
+	3. Create SNS Topics with Access policy (root login)
+
+* `#user`  - 강력한 암호정책 사용, MFA, Access Key 공유, 주기적 변경, Access Key 삭제
+
+	1. password policy 정책
+
+	2. 사내망 -> VPN or DX -> MITM proxy (외부 액세스키를 사용할때 소스를 보고 액세스 컨트롤 가능) -> 사용자(인터넷)
+
+* IAM Policy - 최소 권한 제공
+
+1. 	managed Policy 매니지드 폴리시를 사용하는 것을 추천
+
+	1. MP는 AWS에서 만들어놓은 룰셋으로 나름 보장됨
+
+	2. Custom defined policy도 괜찮다. 
+
+2. inline Policy란
+
+	* IAM -> Roles (add inline policy) -> JSON으로 입력해서 만드는 임의의 정책의 타입
+
+	* 특정 Role 에만 적용이 되고 검색이 되지 않는다. (치명적일 수도 있겠다) 임시적으로 쓸때만 사용
+
+	* 컴플라이언스에 맞춰 정책 설정 (IP, ABAC, UserAgent, MFA)
+
+## 	EC2
+
+* AccessKey 사용 하지마, Role 쓰고
+
+* IMDSv2 사용, Instance meta data 
+
+	* v1에선 curl 로 요청하면 필요한 정보들을 얻을 수 있다. 여기에 시크릿도 포함된다.
+
+	* v2에선 unauthorized 된다. `TOEKN=curl -x PUT  ...` 이렇게 ttl token을 받아서 요청을 해야 시크릿을 받을 수 있다.
+
+	* 테라폼에서  token을 요구하거나 최대 HOP도 지정할 수 있다. 
+
+	* EKS 환경에서 파드들은 워커노드의 롤을 받아서 작동한다. 그러면 과도한 권한을 받게 되는데, 이때 쓰는게 서비스 어카운트 (EKS IRSA iam role for service accounts)
+
+		* 이렇게 되면 명시적인 권한만 갖게 된다.
+
+## IAM 보안 자동화
+
+* 특정시간, 익스파이어, 크론 등 자동화에 따른 동작
+
+* 람다 js 로 작성한 로직플로우
+
+`유저 정보를 다 가져온 다음 키를 map 이터레이트 하면서 메타데이터를 기준으로 만료든 뭐든 하는 구조`
+
+* Event Bridge 에서 이 람다를 호출한다. 이런거 안하고도 람다 스스로도 period를 지원한다. 
+
+
+
+## IRSA
+
+* 	파드가 노드의 권한을 assume하는 문제를 해결하기 위해 큐브아임 같은 서비스를 쓴다. (iam 컨트롤러 서비스, assume 여부를 판단해주는 서비스, 별도로 설정할 필요가 없으니 좋지) 이런 서비스를 안쓰고 OIDC(Oauth2.0)를 쓰는 대안이 있다.
+
+![](/BearImages/379D5BF2-60F7-4233-A912-75E61788D0D8-76434-000010600D678BBF/96919664-63B8-4A1A-8DFF-B44909EA9723.png)
+
+1. EKS에서 enable_irsa=true를 활성화
+
+2. yml에서 정의하여 서비스 어카운트를 만들어서 파드에 붙이고 
+
+3. 서비스 어카운트 annotations: 에서 만들어준 롤을 정의해준다.
+
+```
+
+serviceAccount:
+
+  create: true
+
+  annotations:
+
+    eks.amazonaws.com/role-arn: >-
+
+      arn:aws:iam::552661052297:role/aws-cli-role
+
+  name: aws-cli
+
+```
+
+
+---
+
+
+
+## AWS EC2
+
+* Related concept : IaaS, EIP, ENI, SG, AMI, EBS, EFS, Key pairs
+
+1. 퍼블릭 -> 프라이빗 존 방법을 가장 많이 쓴다. 이 구조는 외부에 열려있다는게 문제(SG, RACL로 막긴 하지만)
+
+2. VPN -> 프라이빗 존 이 방법이 좋다.
+
+* EC2 들어가면 authorized_keys에 키페어에 등록한 pem이 등록이 되어있지. 그래서 ec2유저로 접속을 할 수 있잖아 당연한 거지
+
+
+
+*  일반 유저를 쓰고 싶다면
+
+	1.  `ssh-keygen -t rsa`로 키를 생성하면 `test, test.pub` 파일이 생성된다.
+
+	2. 이제 EC2가서 `useradd -m test`  유저 생성 `cat *etc*passwd | grep test` 확인
+
+	3. su - test   `vi ~*.ssh/authorized_keys` 에 `cat ~/.ssh*test.pub | pbcopy`의 결과물을 넣는다.
+
+	4. `chmod 700 ~*.ssh` `chmod 644 ~/.ssh*authorized_keys` 
+
+	5. 이제 기본 키페어가 아니라 추가한 유저로 좁속을 할수 있다.
+
+* 서버마다 별도의 키페어를 설정하면 가장 좋지만 운영코스트가 높아진다.
+
+
+---
+
+
+
+##  CH03-01 세션매니저 Systems Manager(previous: SSMSimple Systems Manager) 
+
+* 기본적으로 사용하는 AMI에는 설치안해도 SSM 매니저 에이전트가 설치되어 있다. 다른 이미지를 쓸때는 설치해줘되는데 문서참고
+
+* SSM이 에이전트와 통신을 하게되는데 권한도 필요하다.
+
+	****EC2를 생성할때 정책에 SSM Assume 을 주면된다.*
+
+* SSM이 있으면 웹으로도 바로 접속이 가능 (ssm-user, sudo 권한이 있음) 
+
+* 이걸 쓰면 22번 포트 닫아버리고 SG를 비워버릴 수 있음
+
+
+
+* 보안 세션을 로깅하는 니즈가 있다면 `AWS system manager` -> session manager
+
+	* idle session time
+
+	* KMS encryption
+
+	* default user 설정
+
+	* CloudWatch 설정 (실시간 파이프라인을 할 수도 있고, 로그를 업로드 하는 방식 두가자 지원), 이걸 활용해서 명령어 감시도 할 수 있음. 이런 키관리, 명령어 감시, 솔루션들이 많다. 이런걸로도 충분히 활용할 수 있다~ 압도적이다.. 떠 먹기만 하면된다. 데이터는 이미 시스템에 충분하니 조금만 건들여주면 상용 솔루션에서 하는걸 다 해줌.
+
+###  aws-cli 에서 SSM을 호출해서 접근하는 방법
+
+1. .ssh/config | grep ~~A 6 Proxy 에 보면 `aws ssh start~~session ... /prod.pem` 이런 명령어를 활용할 수 있게 셋팅이 되어 있다. 이걸 셋팅해놓고 `ssh i~~{instance~~id}` 이렇게 바로 접근이 가능해진다. 매번 pem을 바꾸는게 아니니까 혁신..!
+
+2. 방법 2 go lang으로 커맨드를 만든다. 아니면 배시쉘이든
+
+arg로 인스턴스를 받고 aws ssm 명령어를 통해서 접근을 하도록 한다.
+
+* 이제 이런걸 기반으로 접근을 통제 및 로그 대시보드를 만들면 되는데 ‘HIWARE’ 같은 솔루션이 이런 일을 대신 해준다. (중앙관리를 할 수 있기 때문에 SSM을 거쳐서 하는게 좋아보인다)
+
+## CH03-02 EC2 백업
+
+* 저장공간을 활용하는 두가지 방법
+
+	* EC2 에 EBS 2개를 올리는 상황에서 한개는 루트 한개는 도커용으로 쓸 수 있겠지. 전체를 이미지화 시켜서 동일한 EC2를 찍어 낼 수 있지. 이걸 AMI라고 한다.
+
+	* 각각의 EBS별로 백업을 하고 싶을땐 EBS Snapshot을 만들고 이를 새로운 EC2의 볼륨에 attach 시키는 방법도 있다.
+
+* snapshot 은 라이프사이클을 가지기 때문에 백업으로 쓸 수 있다.
+
+* apply 한 뒤 `lsblk`로 마운트 상태확인가능
+
+* EBS가서 항목을 선택해서 태그를 달고 
+
+* AMI를 백업하고 싶으면 event bridge 를 이용해 AMI를 찍어낸다.
+
+* 이런걸 해주는게 또 `AWS backup`
+
+	* Backup vaults
+
+	* 디비든 이미지든 다 백업을 할 수 있고 리텐션 등 플랜도 설정가
+
+
+---
+
+## CH03-03 EC2 AMI 
+
+AWS Golden Image : Standard, 필수 패키지가 설치되고 , 보안 조치가 완료된 것을 일컫음
+
+골든 이미지는 패치가 있을때 마다 자주 생긴다. devops의 관점에선 이런 이미지를 만드는 것의 절차를 고민해봐야한다.
+
+* `Packer` (Build automated machine image tool, support multiple platform) 를 이용해서 이걸 해보자.
+
+	* 코드푸시  -> 코드빌드로 트리거 -> 패커가 ec2 start, sensible playbook 실행 -> AMI 백업
+
+* 위의 절차를 대신 해주는 서비스 `AWS Image Builder`
+
+* PK working process
+
+	1. ec2를  띄우고
+
+	2. buildspec.yml ~~> `패커 설치`, `패커 .hcl 검사`, `packer build -var~~file …`
+
+	3. ami.pkr.hcl ->`source “amazon_ebs”` 리소스 사용
+
+		1. `ami_users` 만든 ami를 공유해야할때 쉐어링할 아이디를 넣는다.
+
+		2. vpc, subnet, SG, metadata_options provision 마지막으로 build pie
+
+```ami.pkr.hcl
+
+build {
+
+  sources = [“source.amazon-ebs.this”]
+
+
+
+  provisioner “shell” {
+
+    inline = [“sudo amazon-linux-extras install ansible2 -y”]
+
+  }
+
+
+
+  provisioner “ansible-local” {
+
+    playbook_dir  = “playbook”
+
+    playbook_file = “playbook/${var.playbook_file}”
+
+  }
+
+
+
+  provisioner “shell” {
+
+    inline = [“rm .ssh/authorized_keys ; sudo rm /root/.ssh/authorized_keys”]
+
+  }
+
+}
+
+```
+
+```playbook.yaml
+
+
+---
+
+- hosts: localhost
+
+  connection: local
+
+  gather_facts: true
+
+  become: true
+
+  vars_files:
+
+    - vars/main.yml
+
+  roles:
+
+    - { role: 00_cw_agent }
+
+    - { role: 01_docker }
+
+```
+
+* !Codebuild 로 위의 절차 똑같이 하기
+
+	1. Code source, branch event
+
+	2. Web hook
+
+	3. Managed Image `Amazon linux 2`
+
+	4. Service role -> 주변 라이브러리 참조하는 등 권한이 필요하다. 그래서 이걸 롤을 준다.
+
+	5. 워커컨테이너 설정 - 구동 네트워크 위치  (사설 망에 있으면 라이브러리를 참조 가능하겠지)
+
+	6. compute 사양
+
+	7. VPC내에 구동 or 밖에서 구동
+
+	8. CloudWatch  설정
+
+
+---
+
+## CH03-02 EC2 inspector(v2)
+
+* Feature. 
+
+* 자동 취약점 점검 
+
+	* support EC2, ECR
+
+	* Report (Severity rating, affected resource info, how to remediate)
+
+	* Central management
+
+	* Integration with AWS Service
+
+![](/BearImages/B52DB2E6-A119-4523-96B9-ACCBD13758AA-76434-000010B203767F48/E5277150-8640-4A1A-A7D8-9A914635F661.png)
+
+* 관리자를 위임할 수 있고 각 계정의 인스펙터에 잡혀있는 취약점을 루트 관리자 입장에서 모아서 볼 수 있다.
+
+* Active, Suppressed(예외처리), Closed(조치, 30일 뒤 삭제) 
+
+* 스캔시점
+
+	* 새 인스펙터 발견, 인스턴스 시작, 소프트웨어 설치, CVE 업데이트 , 30일 동안 스캔을 하지 않을시
+
+* 기존에는 에이전트를 설치했어야 했으나 SSM agent에 통합되었다.
+
+* Basic scanner -> Enhanced scanning(과금)을 사용하면 
+
+	* 패키지 취약(기본) + 프로그램 취약성을 점검한다. 
+
+	* 다른 서비스 security hub, event bridge 도 지원
+
+* 데비안, 오라클 리눅스, 각 프로그램 랭귀지별 지원하는 리스트가 따로 있음
+
+* 무료 버전은 clear project를 내장하여 사용하고, 프로는 별도 개발 스캐너 사용
+
+
+---
+
+# Part4 네트워크 보안
+
+## AWS VPC 소개
+
+* routing table 은 subnet association이 가능하다. (여러 서브넷에 적용가능)
+
+	* Edge Association - IGW, VGW
+
+	* Route propagation
+
+	* VGW
+
+* NAT는 프라이빗에서 인터넷 접근을 허용하기 위해 사용된다.
+
+	* 2가지 단점 최대 bandwidth가 정해져있음. IPv4만 지원
+
+* VPC - Middlebox routing
+
+	* Middlebox routing 을 생성할 수 있다. Source -> middle -> destination 
+
+	* middle로는 보안장비, ec2 를 지정할 수 있다. 
+
+	* 시나리오
+
+		1. Ingress traffic 을 검사. 중간에 Firewall 앱을 넣으면 되겠지
+
+		2. Subnet to Subnet 간 검사 하도록 구조를 짤 수도 있다.
+
+		3. GLB -FW를 통한 트래픽 검사. VPC안에서 또 쪼갤 수 있는게 도와주는게 GLB
+
+			1. 만약 인터넷으로 향하는 트래픽은 GLB(+security appliance) 를 거쳐서 나게 할 수 있다.
+
+	**Account마다  VPC를 보통 생성한다. 공유할 수도 있다. 10.1 데브, 10.2 테스트 .. 등등 온프레미즈, 다중 클라우드.. 이런 환경에서**VPC IPEM*을 이용하면 Scope가 생성되고 Private, Public. 이 풀을 단위로 모니터링 및 리소스 할당을 관리할 수 있다. 
+
+		* 다른 VPC와 오버래핑 되는지 여부도 확인
+
+* tf로 생성한 자원들을 웹에서 수정하려고 하면 경고 문구를 뛰운다.
+
+## AWS VPC 트래픽 제어
+
+* SG (ENI에 설정하는 가상 방화벽) 주의!‼ EC2에는 ENI(ethernet network interface)가 붙는다. Default all deny, SG changing, Prefix list 활용
+
+	* in + out bound → soft limit 60 개 한계
+
+	* Network Interface 에 붙일 수 있는 SG는 soft limit 5개
+
+	* AWS 요청하면 하드리밋까지 늘릴 수 있음
+
+	* 핑을 보내면 리눅스에선 랜덤 포트로 리스폰스를 던진다. 스테이트풀 하기에 SG를 통과할 수 있게 된다.
+
+	* chaning : CIDR형태가 아닌 SG를 연결하는걸 말한다. 이렇게 관리하면 IP가 바뀌어도 데이터를 안바꿔도 된다. 다른 VPC간엔 연결(Peering)이 되어있을때 Chaining이 가능하다.
+
+		* Transit gateway는 SG를 지원하지 않는다.
+
+	* prefix list
+
+		* 자주 사용하는 IP 대역들을 관리(SG를 수 없이 연결하기는 힘들잖아)
+
+		* 예를 들어 사무실 대역
+
+* NACL 
+
+	* Stateless, rule number가 낮은걸 우선, subnet 단위, allow & deny
+
+* SG + NACL 전략 → 3 TIER arch
+
+	* public - 서비스하는 서브넷, 인바운드는 22 막고
+
+	* private - ELB SG만 허용 
+
+	* RDS  - EC2 SG만 허용
+
+	* 	NACL은 외부에서 ELoadBalancer 앞에 있다가 DDOS를 차단한다.
+
+![](/BearImages/053BF0F4-5507-40F7-9DA3-887430F7098A-76434-000010E74D09C4D5/4E31F0DA-0AB3-40E1-AFD2-9567EC5D7217.png)
+
+* ANF (Network Firewall)
+
+## AWS VPC 프라이빗링크 엔드포인트
+
+* EC2가 참조하는 서비스는 VPC 밖에 있는 경우가 많다. 별도의 로직이 없다면 이럴 땐 NAT를 통해서 나가게 된다. NAT 부하 비용 + 만약 컴플라이언스 이슈가 굉장히 강한 비즈니스라면 이런 외부로 나갔다가 다시 들어가면 안되는 니즈가 있다. 
+
+![](/BearImages/B09B6713-ECC1-4843-AEBA-F59C11E467F5-76434-000010ECCAC4F83A/FF12DDFC-092B-4B4F-961A-89EE100248AA.png)
+
+* 그럴땐 인터넷으로 나가는 것은 프록시를 통해 나가도록 처리할 수 있다. (프록시의 코스트가 들어간다) 심리스하지 못하다 (간단)
+
+* 이런 니즈를 충족하기 위해 VPC PrivateLink
+
+	* VPC -> AWS 서비스, 다른 AWS Account 서비스, AWS Marketplace 서비스
+
+	* IGW, NAT, G/W, DX, VPN 을 안써도 된다!
+
+* Endpint 는 프로듀서와 컨슈머 둘로 나뉜다.
+
+
+
+Consumer 입장에서 사용할 수 있는 2가지 Endpoint
+
+* Private LINK링크형 엔드포인트
+
+	* 특정 ENI에 서비스로 가는 링크를 만든다.
+
+	* SUBNET에 맞는 IP를 받는 ENI. ENI에 SG도 붙일 수도 있고 IAM policy도 붙일 수도 있다. 
+
+* 게이트형 엔드포인트 (GW endpoint, GW LoadBalancer endpoint)
+
+	* S3, DynamoDB 서비스만 지원
+
+	* Routing 규칙을 추가해서 사용
+
+	* SG, IAM Policy (X)
+
+	* AWS 외부에서는 사용 (X)
+
+* Producer - Endpoint Service
+
+	* 우리가 사업자라면? 엔드포인트 서비스를 이용해 다른 사람들이 우리 서비스를 consume할 수 있게 설정해야한다.
+
+		* NLB(endpoint service) - interface endpoint
+
+		* GWLB - gwlb endpoint
+
+	* 위 두가지 타입을 이용해 컨슘을 할 수 있다.
+
+* VPC를 통해 연결하고 S3로 연결시키면 패킷을 인터넷망에 노출 안시키고 보낼 수 있다.
+
+## AWS  VPC 프라이빗링크 GWLoadBalancer 엔드포인트
+
+* 네트워크 관리자의 니즈
+
+	* 네트워크 시큐어를 배포 및 확장, 관리
+
+	* IDS, IPS도 하고 싶고, egress domain base filtering도 하고 싶다.
+
+	* IG와 EG가 방화벽으로 트래픽을 보내는 구조로 쓰는데
+
+* Firewall로 트래픽을 몰면 failover 문제가 생기니 HA를 준비한다. 이런 문제를 해결하기 위해 GWLoadBalancer 가 출시
+
+	* GWLoadBalancer 터널링 프로토콜 사용
+
+	* L3 Gateway L4 부하 분산ㅁ
+
+	* VPC  Endpoint service 등록 가능 (by Service producer) -> RT에 등록하면 됨
+
+![](/BearImages/988132F1-9EAB-4C74-8DDF-3AC699F094F1-76434-000011462BFD7B43/FDEF81FA-D297-4A33-9A24-8E6661D9359E.png)
+
+* 이런 아키텍트를 하고 싶을때 3rd 파티 제품이 GENEVE tunneling 프로토콜을 지원하는지 확인
+
+## AWS Network firewall (ANF)
+
+* stateless + stateful Policy ~~> NACL 과 비슷함, Pass-Drop~~Forward(to Stateful)
+
+![](/BearImages/DFA2291D-BB4E-4EE6-8885-EE4C5DB1F372-41471-000011E76646707C/3A58FBF8-B578-4FFB-940D-98D3CD826A60.png)
+
+
+
+*  suricata, domain 필터링, 통합관리
+
+![](/BearImages/2A6414FE-ADE2-4B23-A9C3-9236BB21777B-41471-000011F18C7787C0/CD11A5D8-A7BC-49C7-99F3-BB4CEE0B98D8.png)
+
+* 나가고 들어오는 패킷들은 방화벽 서브넷의 엔드포인트를 거치게 되고 이때 AFN을 한번 거치는 구조로 설계한다.
+
+* only Stateful 리퀘스트만 로깅을 지원한다. 방법은 CloudWatch, Kinesis, S3
+
+	* Unique Contributor Insider 기능을 통해 요청 소스를 시각화 할 수 있다. 
+
+* ANF는 여러개 일 수 있고 이런걸 중앙관리할 수 있도록 매니저를 제공 하고 있다.
+
+	* 허브 앤 스포크 형태로 VPC를 엮어서 관리할 수 있게 해주는 `AWS Transit Gateway` Firewall이 피어링을 지원하지 않기 때문에 유일한 선택지.
+
+* VPC FIRE WALL -> 패스, 포워드, 드랍을 결정하고 포워드를 하게 되면 도메인 기반으로 허용하게 된다.
+
+* suritaka 지원
+
+```suri.rules
+
+alert tcp any any -> any 80 (msg:"80site.com Access"; content:"GET /"; content:"Host: "; content:"80site.com"; sid:10001; rev:1;)
+
+alert tcp any any -> any 443 (msg:"443site.com Access"; flow:to_server,established; tls_sni; content:"443site.com"; sid:10002; rev:1;)
+
+```
+
+이런 형식으로 line으로 정의하는걸 말함 (왜 써야하지? 웹에서 룰을 만드는 것도 잘 되어 있는거 같은데)
+
+* 정리
+
+1. AWS managed fire wall
+
+2. SG나 NACL보다 더 복합적 기능을 제공
+
+3. TG와 함께 하면 엔드포인트 아키텍트가능
+
+4. 여러 account를 통합해 관리할 수 있는 기능
+
+
+---
+
+## AWS WAF
+
+![](/BearImages/D6608CCE-62C3-4D60-9666-A1EEAA34F57E-41471-00001209AB65A747/62A4C680-9862-4A34-A3FF-70EC8F030F17.png)
+
+**L7 보안 위협 대응 서비스, 지원(API GW, App sync, ALoadBalancer, CloudFront)**
+
+* SQL injection, export code, malware → WAF
+
+* AWS Shield (DDOS), 방화벽(AFN), 접근제어(NACL, SG), 격리(VPC)
+
+* 전통적인 3티어 구성과 CloudFront-EdgeLocation이라는 기본적인 서비스 운영
+
+	* 이런 구조에 SQLi, XSS 공격이 들어오면 막아낼 수가 없다. WAS가 부하를 먹고 요금만 왕창
+
+	* 그래서 이걸 앞에서 막아주는게 WAF를 통해 악의적 공격을 차단
+
+* 셋팅
+
+	* Web ACL 생성
+
+	* 보호할 서비스 연결
+
+	* 규칙 정의 (Rule group, IP set, Regex set)
+
+* WAF 규칙
+
+	* AWS managed rule -> 1500개 안에서 쓰면 무료
+
+	* Marketplace
+
+	* Custom rule 룰을 false-positive같은 규칙을 지정할 수 있다. 워크로드에 맞는 조정 가능
+
+![](/BearImages/81B141C1-9BA6-4889-ADB2-8133AF8970E0-41471-000012135A37DC3B/2D629EB7-D83D-4BD3-962F-FFE641B3AA37.png)
+
+* 룰 순서에 따라 적용하고 뒤로 포워드
+
+* 로그도 되는데 룰에 대해 어떤 검사를 받았는지 다 남는다. 로그 양이 방대하다.
+
+* 관리할게 많다보니 자동화에 대한 니즈가 있고 이걸 해주는게 처음 이미지에 나오는 Athena, Lambda를 활용한 커스터마이징
+
+* DDOS를 대응하기 위한 전략
+
+	1. ALB만 트래픽을 받도록 접근제어를 구성
+
+	2. EC2가 죽어도 서비스 되도록 HA구성
+
+	3. AWS가 제공하는 !‼SLA(Service-Level Agreement
+
+)를 잘 분석해보기
+
+	4. NACL에 로그기반으로 정책을 심는 방법도 고려해보기 (과도한 접속 차단)
+
+	5. 정적인 서비스를 프론트에 배치하면 디도스 대응이 된다.(비용이 나가는거 아닌가?!‼)
+
+	6. 디도스를 탐지하는게 중요하다 (메트릭 기반의 알람, 람다 트리거, WAS로그를 통해 메트릭화)
+
+
+
+
+---
+
+## AWS Shield
+
+* 디도스의 공격은 패턴이 명확하지는 않지만 weak-point를 최소화하고 HA 구성, 공격 대응르 위한 계획을 수립하는게 필요하다.
+
+* Shield Advanced
+
+	* Standard 는 리스크를 공유하기 위해 기본적으로 제공
+
+	* Advanced는 DRT(Response Team)의 24x7 지원, DDOS 가시성 제공(CloudWatch metric, 공격 진단 리포트, 글로벌 위협 대시보드)
+
+	* DDOS 사용비용 경감
+
+		* standard 써도 로그 증빙자료를 만들어서 보내면 경감 받을 수 있다. (!‼ 이런 체계를 내가 만든다면 어떻게 해야할까?)
+
+
+---
+
+## AWS VPC 트래픽 로그 (VPC flow log)
+
+* 사용할 속성들을 문서를 참조해서 tf 생성. 클라우드 와치로 연결 (접속 로그를 메트릭화)
+
+* 바로 로그를 쌓자 마자 중국에서 SSH접근을 했네
+
+* 아테나 쿼리 결과를 저장하는 S3설정
+
+## AWS 보안탐지
+
+### CloudTrail
+
+* Single or Multi region, 로그는 다른 리전에 남는 경우가 있으므로 멀티 리전 감시를 권고
+
+* 90일로 한정되어 있지만 S3, CloudWatch 로 전달하면 된다. SNS와 연동도 가능
+
+* 기능에 따라 dev, test, prod, security 테넌트를 구분했다고 하자. 그러면 각 어카운트의 클라우드 트레일에서 로그가 생기게 되는데 S3버킷에 모아서 보면 된다.
+
+	* 데브옵스가 여러 테넌트를 다 컨트롤 해야할때 Organization 그룹을 쓰는데 클라우드 트레일에서도 `Enable all account in my organization`옵션을 제공한다.
+
+* CloudWatch -> lambda (정제) -> Kafka ~~> elascticSearch <~~ logstash 중앙 집중화 아키텍트를 쓰기도 한다.
+
+* 클라우드 트레일을 활성화하면 최초에는 management event(무료)가 활성화 되어 있다. (최대 5개까지 활성화 가능)
+
+* M event - control plane operation, AWS 리소스에 대한 작업 행위
+
+	* KMS 인-디크립션이 굉장히 과정이 많은데 이건 제외시켜서 볼 수 있다. 
+
+* Data event
+
+	* Data plane operation - ex) S3 object api activity (Get Object), Lambda (Invoke API)
+
+* insight event
+
+	* AWS AI 기반 기계학습을 통해 비정상적인 행위 로깅
+
+	* API Call rate
+
+	* API error rate
+
+* 로그에 남는 useridentity 의 종류
+
+	* Root, IAMUser, AssumeRule, FederatedUser, Directory, AWSAccount, AWSService(Beanstalk처럼 알아서 움직이는 애들), Unknown
+
+### GuardDuty
+
+* 위험 유형 (Port Scan, 브루트) 인스턴스 침해 (C&C Activity, Bitcoin Mining), 어카운트 침해(소스코드에 계정정보가 있다면 자원을 마음대로 사용가능)
+
+	* 인스턴스가 침해되면 메타데이터로 키를 가져와 자원을 가져온다. v2를 쓰면 막을 수 있음
+
+* 로그를 기준으로 워크로드 동작 감지, 위협탐지, 미승인 활동 모니터링, No Agent, Sensor, Appliance, 머신러닝 기반
+
+* Support - ec2, IAM, eks, S3
+
+* 데이터 소스 - VPC Flow logs, DNS logs, CloudTrail, EKS Audit logs
+
+![](/BearImages/CEBD8550-2317-4B94-B81A-76598B523291-41471-0000149A3C18F53C/3CC934CB-71BE-4FB5-98AA-401B2A93DB51.png)
+
+* member account max 5000, 통합된 조회 및 관리 기능, 신뢰 및 위협 IP 업로드 기능
+
+* Security Level (low, medium, High)
+
+* Reputation IP ( 각 비즈니스에 맞는 Trusted 정보, SaaS를 빌려쓴다거나) 를 등록해 탐지 효율 증가
+
+	* CrownStrike
+
+	* ProofPoint
+
+	* 고객정보
+
+* S3 protection 
+
+	* AWS Macie 기능 포함
+
+	* 활동에 대한 이상 및 위협 탐지 기능
+
+![](/BearImages/535F8780-2469-4858-81FE-CB7A9881319B-41471-0000149C57491F97/FF5FB368-BDC3-4714-8571-A7B09256F69A.png)
+
+* 템플릿을 정해서 알림 가능
+
+* 자동화 아키텍트
+
+![](/BearImages/300A474E-F35B-4B4A-838F-C2BBF2F81513-41471-0000149D14F8DF9C/4677711A-9E0A-4232-B09A-01B919AEAD5A.png)
+
+* 가드 듀티에서 찾아낸 파인딩들을 다른 서브에 접목할 수 있다.
+
+### AWS Macie
+
+* 민감 정보 검색 및 보호 서비스, 기계 학습 및 패턴 일치를 활용, S3에 저장된 데이타에 대한 보안 및 프라이버시의 가시성 제공
+
+* Public access, sharing, encription
+
+* `Discovery result` 에서 버킷을 만들어 정보를 담아야 한다.
+
+* Custom data identifiers`에서 반응할 키워드를 셋팅
+
+* `JOB`메뉴에서 이제 버킷을 대상으로 검색을 할 수 있다. (과금도 예측해서 보여준다) 샘플링 기능이 있어서 어느정도 가려서 볼 수 도 있다. 스케쥴 설정 가능, 특정 태그의 오브젝트만 검색 할 수도 있다. 가드에서 쓰면 싸게 쓸 수 있는데 Macie를 쓴다는건 커스텀 룰이나 스코프를 사용하기 위해서다.
+
+* 발견한파인딩에 대해 SNS, CHATBOT을 이용해 모니터
+
+### Security Hub
+
+![](/BearImages/959E2DB9-B24E-4D99-8238-99D86D7FB9D6-41471-000014A6B6912141/C5256FB9-C251-4897-BAD6-75A0DBE3897E.png)
+
+* 특성
+
+	* 멀티 어카운트 & 서비스를 중앙화
+
+	* ASFF (Security Finding Format)
+
+		* 이 포맷을 지키면 다 통합될 수 있다. 
+
+	* 규정 위반 및 체크 자동화, 통합 대시보드, 손쉬운 사용
+
+* EKS의 정보는 Aqua 큐브벤치가 잡으로 존재하며 허브에 전달 -> 
+
+![](/BearImages/5FC26E7E-F1A8-41F5-9FE8-E374F9BB4CEE-41471-000014A7D546F7DD/3A889130-ADF4-4007-8DC6-E7869C054DD4.png)
+
+* 규정준수에 대한 스코어링을 제공한다. 제공 기준.
+
+	* PCI DSS (Payment Card Industry Data Security Standard)
+
+	* CIS AWS (CIS AWS Foundations Benchmark standard - AWS Security Hub)
+
+* Insight (필터링)
+
+	* 연관 검색 필터, 우선 순위 지정, AWS pre-defined Insight
+
+	* Custom Insight 사용 가능
+
+* 굉장히 많은 서비스들이 다 인터그레이션이 된다.
+
+* Custom actions - 여기서 정의한 값을 다른 서비스에서 사용할 수 있다. 파인딩이 너무 많으니 필요한 기능
+
+* 
+
+
+---
+
+# bonus Part AWS EKS
+
+
+---
+
+
+
+# AWS 관리형 쿠버네티스 클러스터 EKS
+
+### 개요
+
+* 제어 영역(Control Plane)을 직접 프로비저닝하거나 관리하지 않아도된느 편의성
+
+* 노드 구성의 자유도
+
+* 멀티 AZ 고가용
+
+* 클러스터 업그레이드 편리
+
+![](/BearImages/48B44BEF-01CE-4A19-80B7-22C4F9E19537-41471-00001602007626D6/046624F2-5C67-4558-94A3-5276FF1E53D0.png)
+
+* 구성도
+
+	* customer VPC (사용자의 VPC)
+
+	* EKS VPC (Controll Plane) -> 대신 컨트롤
+
+	* ENI (Private Link)를 통해 컨트롤 받는다.
+
+* 로드밸런싱
+
+	* 서비스 (ExternalName, Node 등), CLoadBalancer로 구성, annotation 설정을 통해 NLB로 구성 가능
+
+	* 인그레스 L7기능을 위해선 추가애드온 설치필요. ALoadBalancer 로 구성
+
+* 파드 네트워킹
+
+* AWS VPC CNI
+
+	* 기본적으로 설치되어 있는 네트워크 애드온
+
+	* EC2는 모두 ENI를 가지고 IP를 받는다. ENI의 secondary IP를 통해 노드 내 파드가 동일한 VCP IP 대역의 IP 할당 ( ENI IP주소 제한 만큼 노드의 파드 개수가 제한됨) -> but 요즘에는 IP prefix 기능이 생겨 제한이 풀림
+
+![](/BearImages/8E422652-6B46-42AE-8098-D0328F1AFE56-41471-0000160ABEA39294/A90D3B2A-30D6-4FCA-B1E3-9E7897760690.png)
+
+* 저장소. EBS built-in StorageClass
+
+	* gp2 타입의 EBS에 대한 StorageClass 내장되어 바로 사용 가능
+
+	* EBS & EFS CSI Driver -> CSI 드라이버 구성을 통해 EBS/ EFS의 최신 기능 사용 가능
+
+* 로그 및 메트릭
+
+	* 로깅 옵션을 통해 API Server, Audit, Scheduler, Controller Manager 등 CloudWatch 로 수집
+
+	* 노드 -> 기본 기능엔 없지만 Fluentd, Fluent Bit을 통해 CloudWatch 하라고 가이드하는 중 
+
+* EKS 를 사용해야하는 이유
+
+	* 클러스터 운영보다는 실제 비즈니스 운여에 집중하기 위해 (Control plane)이해하는게 쉬운 일이 아니라
+
+	* 인프라 비용을 넘어 관리비용도 고려 (직접 제어를 프로비저닝 하는게 비용은 더 쌀 수 있지만 인력이나 시간을 고려)
+
+
+
+### EKS 클러스터 구성 (웹콘솔)
+
+* 사전준비. 
+
+	* EKSClusterPolicy, EKSVPCResourceController 두개의 정책을 연결 시킨다. 
+
+	* SG for Control plane : Cluster SG 라는 기본 그룹이 생성된다.
+
+* 클러스터 구성 마법사
+
+	1. 추가해놓은 IAM ROLE 추가
+
+	2. VPC, EKS, SUBNET, Private 서브넷에서 운영.
+
+	3. 클러슽처 엔드포인트 엑세스: 퍼블릭 및 프라이빗으로
+
+	4. Kubernetes 애드온 설정
+
+	5. 제어 플레인로깅 로깅량이 많기 때문에 비용을 아끼기 위해 비활성화.
+
+### EKS 클러스터 구성 (테라폼)
+
+1. 테라폼 레지스트리 - tedilabs - eks-cluster 모듈을 사용
+
+2. define을 보면 웹콘솔에서 만들때 쓰는 정보가 다 들어있음. 엔드포인트에 대한 접근은 allow all 비추천
+
+### Kubectl을 이용하여 EKS 클러스터 연결
+
+* 클러스터 연결에 필요한 정보추가
+
+	* `aws eke update~~kubeconfig -~~region= ~~-name -~~alias=`
+
+	* `cluster kubeinfo` 
+
+
+
+### aws-auth ConfigMap 관리
+
+* EKS 제공 연결방법 aws-auth ConfigMap
+
+	* aws~~aim~~authenticator
+
+	* EKS NodeGroup Fargate도 클러스터 연결을 위해 동일 인증방식을 사용. 노드그룹과 파게이트 사이에서도 인증이 필요하다. 
+
+``` IAM User 매핑 예시
+
+mapUsers: |
+
+  - userarn
+
+    username
+
+    groups:
+
+      - system:masters  (중략)
+
+```
+
+
+
+```IAM Role
+
+data:
+
+  mapRoles:
+
+    - roleARN: 
+
+```
+
+### 노드그룹 생성 (웹콘솔)
+
+* 관리형 노드그룹 (managed NodeGroup)
+
+	* ASG(Auto scaling Group) LaunchTemplate 기반
+
+	* EKS가 EC2 인스턴스의 프로비저닝과 라이프사이클 관리
+
+	* 안전한 버전 업그레이드 및 노드 종료 지원
+
+* 사용자 관리 노드 Self managed Nodes
+
+	* AWS EKS 에서 제공해주는 EC2 AMI 사용
+
+	* 설정 자유도 높음
+
+* 클러스터 만들기
+
+	1. IAM 에서 정책 3가지 연결
+
+	2. SG for node Group - 기본적으로 Cluster SG 에 연결됨. self managed node를 쓸때 이부분을 생성해줘야함
+
+	3. 노드 생성 후 해야 하는 작업 EKS에 클러스터 접근 정보를 줘야한다. 
+
+* 노드 만들기
+
+	1. 앱 이름
+
+	2. IAM (ec2CNI_policy, worker node policy, ec2containerReadonly) 정책을 가진 역할 생성
+
+	3. 시작 템플릿 ( 고급설정 ) 
+
+	4. Label, Taint 값을 설정할 수 있음
+
+	5. 노드 그룹 조정 구성 2개
+
+	6. 노드 그룹 네트워크  서브넷 ( ec2가 실행될 넷), 원격 액세스 설정
+
+* Auto scaling 그룹, 인스턴스도 만들어진걸 볼 수 있다. 
+
+	* `kubectl get node -o wide`로 조
+
+### 노드그룹 생성 (by TF)
+
+* 레지스트리 (모듈)에서 Auto Scaling, kubernates***conifg***map 두가지 모듈을 쓸거다.
+
+* 리소스 구성
+
+	* Launch Template - Auto-scaling Group 구성 목적
+
+	* ConfigMap - Kubernetese~~system 네임 스페이스에 aws~~auth ConfigMap 구성 -> 클러스트 인증 제어 기
+
+* 생성한 뒤에 `cat node-groups.tf`
+
+
+---
+
+# EKS 클러스터 활용
+
+## IRSA
+
+* Service Account, 파드가 클러스터 내 리소스에 접근하기 위해 존재. 하나의 파드는 하나의 Service Account를 가진다. 
+
+* 쿠버네티스의 SA를 위한게 IRSA
+
+	* 파드가 S3, DyamlnmoDB, SQS 에 접근하고 싶어함. 액세스키를 주자니 IAMUSER에 기밀값을 줘야하는 문제가 생김
+
+	* 그래서! ServiceAccount에 IAM Role을 연결시키는 기술이 IRSA.
+
+		* Role 생성시 OIDC Provier를 Trusted Entity로 붙이면된다.
+
+* 절차
+
+	1. 클러스터를 생성하고 나면 Identity 프로바이더 정보가 생성됨
+
+	2. IAM Identity Provier 등록 -> EKS OIDC Provier 정보 기입
+
+	3. 신뢰하게 된다. (HTTPS CERT랑 비슷하네)
+
+
+
+``` 
+
+kind: ServiceAccount
+
+metadata:
+
+	annotations:
+
+		eks.amazon.com/role-arn: "arn: ... rol/irsa-test"
+
+```
+
+```
+
+kind: Pod
+
+spec:
+
+	serviceAccountName: irea-test
+
+```
+
+
+
+	4. 위와 같이 서비스 어카운트 생성해서 파드에 연결 
+
+	5. iras.tf 에서 모듈을 사용해 `oidc***proviers***uirls` `trusted***service***accounts` `inline_policies`를 설정하여 계정과 정책을 연결한다.  
+
+	6. POD을 프로비전 하면 `aws sts get~~caller~~identity`를 통해 생성한 권한을 어슘한것을 확인할 수 있음.
+
+## metric server 구성
+
+* 필수 애드온, HPA(Horizontal), VPA (vertical pod Autoscaling)의 기준이 되는 메트릭을 수집
+
+* 설치
+
+	1. 설치는 제조사의 스크립트 참고 ( minikube 에선 `minikube addons enable metric-server`
+
+	2. 설치가 안되어 있으니 kubectl top node | pod 이용이 불가능
+
+	3. 준비해놓은 스크립트를 실행하여 리소스를 설치
+
+## external-secrets 구성
+
+* external-secrets 구성하여 외부 비밀 정보를 import, Secrets 리소스를 이용할 경우 선언적 관리가 없다. base64로 코딩되어 있으니 다 보인다. 그걸 문제를 해결할 수 있는게 ExternalSecrets.
+
+	* AWS Secrets Manager
+
+	* HashCorp Valult
+
+	* Alibaba KMS Secret Manager
+
+	* AWS system manager Parameter Store
+
+* External Secrets Contoroller
+
+	* 1) Kubernetese-APIserver의 리소스의 변경상태를 감지 2) ExSecrets을 가져와 3) Secret오브젝트를 생성하거나 갱
+
+* USE case
+
+	* backendType: 외부 저장소 종류
+
+	* data: Key 단위 기밀 데이터 매핑
+
+	* dataFrom : 여러 기밀 데이터 한 번에 매핑
+
+* 사용절차
+
+	* yamlml로 external 을 쓰겠다고 정의해놓고
+
+```external-secret.yaml
+
+kind: ExternalSecret
+
+sepc:
+
+	DataFrom:
+
+	- app/mysql # 이렇게 정의 해놓고 실제로 시크릿 밸류도 지정해주면 사용 끝!
+
+```
+
+
+
+	2. Store new secret 에서 `app/mysql` 생성
+
+	3. `kustomize . build`를 통해 적용될 코드를 보고. `kubectl apply . -k` 실행
+
+	4. 이제 파드에 들어가면 적용한 시크릿이 환경변수에 있는걸 확인 할 수 있다.
+
+	5. AWS Secret Manager에선 한번 만든 값은 삭제하는데 7일 이 걸린다. (7~30일)
+
+## aws~~LoadBalancer~~controller 구성 
+
+* ≈ 인그레스 컨트롤러 , 원래 이름은 ALoadBalancer~~ingress~~controller
+
+	* 원래 컨트롤러는 ELoadBalancer, NLoadBalancer 를 적용가능한데 쿠버네티스 버전에  종속되어 있어서 업데이트에 불리했음. 그래서 aws-LoadBalancer 로 독립시켜서 별도로 컨트롤 가능하게 해줌
+
+	* Feature: API 서버를 계속 보면서 ingress 오브젝트를 계속보고 변경 사항이 있으면 ALoadBalancer의 리스너나 룰을 추가
+
+	* Target Type 
+
+		* instance클러스터 노드의 NodePort 를 바라봄. 
+
+		* ip: 로드밸런서가 PodIP를 직접 바라봄
+
+* 자동 서브넷 디스커버리 ( 리소스 태그 기반으로 로드밸런서를 어디에 생성할지 결정), ALoadBalancer는 두개 이상의 AZ로 구성된 서브넷 필요. 이때 annotation기능을 통해 직접 지정이 가능
+
+* 인터넷 페이싱 ALB(public), Internal ALoadBalancer (Private) 두가지로 쓸 수 있다.
+
+	* `ebl1=1` `internal-elb=1` 각 각 이렇게 값을 설정하면 됨.
+
+### 설치
+
+1. 현재 ALB Contoller 는 Cert Manager에 의존성을 가지고 있음. 설치는 전용 스크립트로 진행 (install~~cert~~manager.sh) 스크립트를 통해 설치.
+
+2. `rbac.yaml` 의 IRSA ARN 값을 본인 데이터 값으로 수정
+
+3. `kubectl apply -k .`
+
+4. kubectl get pod 
+
+### 실행
+
+* 실행 내용 분석
+
+	* ALoadBalancer에서 적용하는 다른 서비스들의 권한도 들어가 있는걸 볼 수 있다.  WAF같이
+
+	* 서브넷에서 태그를 정해서 디스커버리가 동작할 수 있도록 셋팅 
+
+
+---
+
+# EKS Fargate
+
+## 소개
+
+* Control Plane을 구성하고 노드를 만들때 EC2와 Fargate를 지원했다. 
+
+	* Fargate 노드를 직접관리하지 않고 컨테이너를 띄어서 쓰는 서버리스
+
+	* Data Plane에 대해선 반쯤 매니저 해줬었음.  Fargate를 씀에 따라 이제 데이터 노드도 완전 관리로 할 수 있게 되었다. ( 모든 문제를 해결 할 수는 없다)
+
+![](/BearImages/C1A1C436-B081-469B-A3D7-AC7F1132D89B-73175-00001DA913C2A61E/E83D4622-9DFE-4D12-8C2E-74CB9B96B47E.png)
+
+* Pod Execution Role (≈ Instance Profile)
+
+	* Fargate에서 실행하기 위한 롤 ECR 이미지 다운로드, 로그 전달 등의 목적으로 생성하는 롤
+
+	* 파드 컨테이너는 해당 권한을 적용받지 못한. IRSA로 할것
+
+* Fargate Profile
+
+	* 어떤 파드를 파게이트로 어떤 서브넷을 실행 시킬지 결정
+
+![](/BearImages/227DBB9D-0F59-4BC7-955D-6F1E9ABEFA43-73175-00001DAAD19D6C27/F2239BCE-E7D2-47A2-BC7F-6CA4297D47EF.png)
+
+* 파게이트 유즈케이스
+
+	* 배치성 워크로드 24시간 가동이 아닌 일시적 잡에 유용함. 
+
+	* 클러스터 애드온, 다른 워크로드로부터 영향을 최소화하고 싶은 클러스터 애드온
+
+		* 메트릭서버, 코어 DNS
+
+		* 독립저으로 구성하면 앱 파드가 부하를 먹을때에도 영향을 받지 않는다.
+
+* 특징
+
+	* 파드 1개에 노드 1개. 공식적으로 지원하는 파드의 갯수는 정해져있다.
+
+	* 10pod, 매일 1시간 한달 0.25vpc 로 한달 5$
+
+* 장점
+
+	* 노드를 직접 관리하지 않아도 됨
+
+	* 실행시간만 작다면 비용절감 가능
+
+	* VM 수준의 격리 가능. 다른 파드와 자원을 공유하지 않음. 
+
+* 단점
+
+	* 데몬셋을 지원하지 않음. 데몬셋(1+1)에 구성이 있다면 사이드카 아키텍 도입필요 (로그, 메트릭)
+
+	* 리소스 제약사항 문제 ( 최대 4vCPU와 30GB 메모리)
+
+	* GPU 사용 미지원
+
+	* ALB/NLoadBalancer 에서 파드를 바라볼 때 타겟을 노드가 아닌 IP로 구성해야 함.
+
+	* 추가 권한이 부여된 파드는 활용 불가
+
+	* IG와 직접 연결되지 않은 Private서브넷에서만 실행 가능 즉 NAT를 붙여야한다. 월 7만원 나옴. 
+
+## 사용해보기
+
+PublicSubnet 에 0000을 IG에, PrivateSubnet 은 0000을 NAT로 설정
+
+### 사용방법
+
+1. 	EKS 클러스터 생성
+
+2. Fargate Pod Execution Role 생성
+
+3. aws-auth ConfigMap 에 pod Execution Role 등록
+
+4. Fargate Profile 생성
+
+	* PrivateSubnet  설정, 가장 중요한건 selector { }
+
+5. Fargate Profile 조건에 맞는 Pod 생성
+
+	* 21~~eks~~fargate 디렉토리에서 `deployment.yaml`에서 DP 매니페스트가 있음. 
+
+```
+
+	lables:
+
+		app: hello
+
+		eks.amazone.com/compute-type: fargate
+
+```
+
+	* 
+
+
+---
+
diff --git "a/Bear/\360\237\215\217 \353\254\270\354\236\245 1\354\260\250 \354\240\200\353\245\230\354\247\200.md" "b/Bear/\360\237\215\217 \353\254\270\354\236\245 1\354\260\250 \354\240\200\353\245\230\354\247\200.md"
new file mode 100644
index 0000000..1d3596e
--- /dev/null
+++ "b/Bear/\360\237\215\217 \353\254\270\354\236\245 1\354\260\250 \354\240\200\353\245\230\354\247\200.md"	
@@ -0,0 +1,117 @@
+# 🍏 문장 1차 저류지
+
+#living/sentence
+
+
+---
+
+# 1차 요약본 about 멘탈케어
+
+상담사가 쓰던 기법: 
+
+무엇이 문제인가요
+
+사회 생활하면서 어느떄가 힘들었나요
+
+어릴때 무슨 일이 있었나요
+
+그렇게 생각하게 된 어떤 경험이 있나요?
+
+꿈이 뭐였나요
+
+
+
+인지오류5선 - 인지치료
+
+1) 지레짐작 그렇게 생각할 충분한 근거가 있나? 내가 내 느낌에 매달리고 있지는 않나? 다르게 생각해볼까?
+
+2) 내탓하기 불필요한 죄책감 책임감을 안고 살아갈 필요 없다. 내가 그렇게 생각하는 근거는 무엇인가? 나는 이일의 전체를 보고 판단한것일까? 다르게 생각해볼까. 사람은 각자 자신을 주인공이라고 생각하고 산다.
+
+3) 강박적 의무감 완벽주의는 도움이 안된다. 조금씩 성취의 경험을 쌓아야한다. 내가 생각하는 것보다 조금 못하면 어떻게 될까? 내 기준이 현실적으로 타당한 기준일까? 완벽한 사람은 없다. 
+
+4) 극단적 생각 - 거부도 더 크게 생각하고 고통도 더 크게 생각한다. 그게 타당한지 생각해보자. 정말 일어날까 정말로 나를 거부할까 정말로 그 결과는 끔찍할까? 나는 어떤 해결책도 찾을 수 없는 걸까? 부족한게 있으면 다른걸 잘하면 된다. 해결방안이 중요하다. 어차피 모든 사람에게 인정과 사랑을 받을 수 없다. 연예인도 그런건 못한다. 넌 평범하다. 내 가치는 내가 정한다. 남의 평가에 계속 휘둘리면 실망밖에 못한다. 부정적 사건이 일어나도 인정을 구걸하지 마라. 
+
+5) 흑백논리. 실제로 나에게 점수를 매기는 연습을 하자. 내가 한 행동이 정말 0점일까? 이걸 잡아내면 좌절과 열등감을 벗어낼 수 있다. 
+
+
+
+
+
+* 치료를 하다가 일시적 퇴보가 올 수 있다. 난 실패한게 아니라 오늘 무너졌어도 지금까지 한 노력이 헛되지는 않았어 일시적인거야 고치는 과정 중에 오르락 내리락 하는 것은 너무나 당연하거야 하고 내일 치료를 계속하면 된다. 
+
+* 사람들을 관찰하는게 중요하다. 자전거 타면 넘어지고 무섭지만 어느날엔 자유롭게 타는거다. 자꾸하다보면 어느날 자유롭게 생활한다. 작은 성공이라도 꼭 보상을 하세요. 잘한 것만 생각하세요. 자주 자주 정기적으로 나가서 사람을 마나라. ㅛ교회 볼링 배드민턴 동아리 소개팅
+
+* 직면할때는 5개정도 질문을 준비하고, 웃고 리액션해주고 다 좋아한다. 오가는 젤리속에 싹트는 우정, 휴지 챙겨주고
+
+* 무엇보다 자신을 수용해야한다. 나의 가치를 남의 평가에 걸지 않고 내가 평가해야한다.  나를 수용해야한다. 나를 단점 평가하는 노트를 쓰고 바꿀 수 있는건 (O) 아닌건 (X) 수용해라.  그리고 "그것도 나의 일부분이야 나는 나의 모든면을 받아들인다" 이말을 하루 20번을 한다. 한달만 한다. 세상이 달라진다.
+
+* 장점도 노트에 적어본다. 어릴떄부터 지금까지 나는 ~한 사람이다. 자꾸 자꾸 말하면서 받아들인다. 나를 인정하는 것은 타인의 몫이 아니라 내 몫이에요. 나를 사랑하는 것도 타인의 일이 아니라 내 일입니다. 
+
+* 새사람으로 태어나라는게 아니라 너무 힘든 부분은 연습에 원래 어느정도 바꿀 수 있다는거죠. 3-4년 보고 합시다
+
+
+
+
+
+* 융이 청소년기에 겪었던 전환증상, 융은 그 전환증상 때문에 인생이 어두워질것을 두려워했고 돌파하고자 모든 것을 각오했다. 그러자 전환증상은 사라졌다. 그리고 그가 바라는 대로 배는 나아갔다.
+
+
+
+* 편한게 선택의 기준이 되면 안된다. 아이디얼 리스트는 현실에 안주하는 사람들을 돌파하는 사람이다.
+
+
+
+* 내 인생에 벽이 있다면, 지금 당장 해야 할 일
+
+	* 벽을 깨고 나면 세계에 대한 인식이 변한다.
+
+	* 무조건 좋다고는 못한다. 하지만 허술한 벽들이 있다는 것도 알게 되고 
+
+	* 넘어진 벽은 다리가 되어준다. 또 다른 세상을 알게된다.
+
+	* 그리고 돌아볼때 내 세계가 바뀌었음을 알게된다.
+
+	* 그러니 일단 노크는 해봐라.
+
+
+
+* 구피질과 신피질이 원하는 것이 다를때 피로가 쌓인다.  신피질이 시키는대로 구피질을 억압하기 때문이다. 
+
+
+
+
+
+"최악의 스트레스는 문제를 통제할 수 없다는 느낌, 무력감이다." => 무력감을 느낄때는 바로 조치가 필요하다. 문제를 일으킨 사람, 상사. 동료, 친구 누구든 좋다. 그대로 두지 말자.
+
+
+
+너무 먼 목표를 이뤄내야한다고 압박받으면 누구나 힘들다.   해낼 수 있다고 자신하는 목표를 설정해 조금씩 나아가 끝에는 잘하는 자신을 즐길 수 있으면 그만이다.
+
+
+
+**skeptical**
+
+* 궁금한게 있으면 순식간에 검색으로 알아내는데 익숙한 세대
+
+* 남들이 수십년 동안 노력해 얻은 결실을 미디어로 10분 만에 보는데 익숙함
+
+* overnight success 하루 아침만에 성공하기를 기대를, 성공자체를 쉽게 봄
+
+* [내생각] 운동과 마찬가지다 실행 중에 이론을 더하고 근육의 감각을 알고 실행하면서 오류를 수정하고 매일 인내하고 더 나은 방법을 찾는 과정이 1년 3년 5년 10년이 걸리는 성공의 과정. 왕도가 없다.
+
+* 포스트 모더니즘은 절대 불변의 진리는 없다가 핵심. 자기 세계에 발들이지 말라는게 요즘 시대의 방법. 이게 내가 믿는거다. 라고 말함. 자기를 당당하게 믿지말라고 말함. 믿지 말라고 말할 수 있는 사람들이 유튜브를 해야한다.
+
+* 변혁의 사고(I don't care, Do it,  Dream) vs 노예의 사고(평균, 결정론)
+
+* 그러니까 유튜브 좀 하세요
+
+
+---
+
+**익명의 트위터리안**
+
+“자신의 마음을 동할정도로 자극적이지 않기 때문에 딴짓을 한다. 도파민의 부족상태, 그리고 그러한 상태가 되는데는 딴짓이나 다른 행동이 너무 자극적일 경우일 확률이 높다. 소비, SNS, Porn”
+
+
+---
+
diff --git "a/Bear/\360\237\215\263Recipe.md" "b/Bear/\360\237\215\263Recipe.md"
new file mode 100644
index 0000000..f5e082a
--- /dev/null
+++ "b/Bear/\360\237\215\263Recipe.md"
@@ -0,0 +1,97 @@
+# 🍳Recipe
+
+#living/Diet
+
+
+---
+
+# 괜찮아 보이는 요리 및 재료 및 요리기법
+
+* 올리브유
+
+	* 가격순 ‘엑스트라 버진(프리미엄 엑스트라 버진)~~버진(extra virgin)~~퓨어(pure)
+
+	* E.Virgin. 프리미엄 영양이 가장 풍부, 샐러드 용도 시중에 가장 많이 팔림
+
+	* 버진. 파스타 생선요리
+
+	* 비싼 것일수록 열에 약하다. 샐러드 용도. 퓨어에 가까울 수록 170도까지 사용가능
+
+* 올리브유 요리 기법
+
+	* 마늘 9쫑 넣고 미리 다 익혀놓고 토마토 나중에 (+향신료) 올리브유로 볶기
+
+	* 볶을때 온도는 80도 120도 안에서 논다. 따라서 문제 없음
+
+	* 면을 삶아놓고 말린 후에 양념을 부으면 양념이 면에 잘 베인다.
+
+* 적채요리 (1/4쪽 기준)
+
+	* 결의 반대로 썰어서 잘고 >> 씻고 >> 버터볶고 >> 소금 1/3큰술 >> 적당히 볶다가 10분 기다림 (숨 죽이기) >> 식초 2-3큰술 >> 설탕 2큰술 >> 졸이듯이 보라색 국물 나올때 까지 >> 더 볶으면 부드럽고 >> 후추넣을려면 넣고
+
+	* 버터미리 잘라놓고 냉동하는 방법
+
+* (냉장고) 6시간 불리고 병아리콩 15분 삶는다.
+
+* 강된장
+
+	* 멸치국물에 땡초다진거 표고버섯  양파다져서 물잠길정도로해서 야채익을때까지 끊이면된다
+
+* 고추장 볶음
+
+	* 너 고추장볶음 해봤나 먼저 소고기넣고볶고마늘이랑  표고버섯 양파랑다져서 보끔다음 고추장넣고볶으면 오래먹을수있다 맛술 참기름 깨소금첨가하면 끝
+
+* 만능간장
+
+	* 매실발효 1컵, 간장 1컵, 청주 1/2컵, 홍고추, 생강, 다진마늘 넣고 끓여서 걸러내기
+
+* 강된장: 멸치국물~~땡초다진거-표고버섯~~양파다진거 익을때까지 끊이기
+
+* 불고기맛 양념
+
+간장 1T, 백설 매실청 1*2T, 마늘소스 1t, 참기름1*2t, 깨소금1t, 후추를 섞어 불고기양념을 만든다.
+
+
+
+
+---
+
+
+
+# 다이어트 관련 지식
+
+### 린매스 정리공간
+
+* 린매스업 식사량 - (자극 정도에 따라 유지칼로리 1.0 ~ 1 .1배 섭취)
+
+
+
+### 리피드 
+
+* 일주일에 한번 24시간~48시간 시간 동안  유지칼로리를 섭취해주는 전략. 이때 더 먹는 칼로리는 탄수화물로만 채운다. 
+
+
+
+### 다이어트 브레이크 
+
+* 3주 다이어트를 진행했다면 1주는 유지 칼로리를 먹되 추가되는 칼로리는 오직 탄수화물로만 섭취 (지방 20%, 단백 2.2g는 보장할것)
+
+
+
+### 운동회복이론
+
+* 최대회복볼륨(MRV): 최대량은 정해져있고 부위마다 MRV가 있다. 때문에 MRV가 큰 곳은 휴식이 더 길어야한다.
+
+* 디로딩: 4~6주에 한 번 완전히 쉬거나 낮은 수준의 운동(실패지점까지 하지 않는)으로 휴식을 가지면서 중추신경계의 피로를 제거하는 과정
+
+* 운동일지를 통해 컨디션을 체크하면 디로딩의 필요성을 알 수 있게 된다. 퍼포먼스의 급격한 약화가 오면 디로딩을 하면 된다.
+
+
+
+### 아나볼릭이론
+
+* 커팅 - 바디 리컴포지션 - 린매스업 - 벌크업 이런 순으로 많은 칼로리 섭취에 따른 아나볼릭 전략이 존재한다.
+
+* 특별히 바디 리컴포지션이라고하여 별도의 행동을 하는것 아니다. 어떤 상태에 있는 사람들 특히 초심자들은 활동칼로리 정도를 먹거나 덜 먹더라도 근육양이 증가하는 것을 발견하기 때문에 바디 리컴포지션이라는 이름을 붙여준것이다. 이런 효과를 기대할 수 없는 사람들 (특히 식단을 잘 관리해온 고급자)들은 활동칼로리 만큼만 먹는 전략보다 조금식 지방을 늘려나가는 전략이 유효하다.
+
+* 운동을 하면 그날 운동이 잘되든 안되든 집중력을 잃는다. 때문에 집중력을 잘 활용하기 위해 한번에 볼륨을 넣을 수 있는 복합다관절 운동이 내츄럴한테 유용하다.
\ No newline at end of file
diff --git "a/Bear/\360\237\216\273Classic record.md" "b/Bear/\360\237\216\273Classic record.md"
new file mode 100644
index 0000000..d7f2dc9
--- /dev/null
+++ "b/Bear/\360\237\216\273Classic record.md"	
@@ -0,0 +1,16 @@
+# 🎻Classic record
+
+## 주의 깊게 들은 노래들
+
+사라반데 - 헨델
+
+사육제 - Swan
+
+스프링 1 - 비발디 사계
+
+발퀴레 - 바그너
+
+
+---
+
+#Culture&Sense
\ No newline at end of file
diff --git "a/Bear/\360\237\217\213\360\237\217\275\342\200\215\342\231\200\357\270\217 Workout Mainline.md" "b/Bear/\360\237\217\213\360\237\217\275\342\200\215\342\231\200\357\270\217 Workout Mainline.md"
new file mode 100644
index 0000000..e46c00d
--- /dev/null
+++ "b/Bear/\360\237\217\213\360\237\217\275\342\200\215\342\231\200\357\270\217 Workout Mainline.md"	
@@ -0,0 +1,767 @@
+# 🏋🏽‍♀️ Workout Mainline
+
+#living #mainline
+
+
+---
+
+Day 1 무분할A, 데드리프트
+
+Day 3 무분할B, 롤아웃
+
+Day 5 무분할A, 데드리프트
+
+Day 7 무분할B, 롤아웃
+
+
+---
+
+
+
+## Workout Great Principle
+
+* 먼저 힘 쓴곳이 운동을 한다. (특히 전완근이 일하게 하지마라)
+
+* 아나토미 자세를 잡으면 알아서 코어 활성화된다.(힘빼고 등세우고)
+
+* 물흐르듯이 해야 운동이다. 이상한곳에서 뻣대고 버티면 어깨나 무릎처럼 중간 관절이 혹사한다.
+
+* ***자극이 오는지 확인해 모르겠으면 그냥 머신으로 하는게 300배 이득 알때까지 머신으로 해라***
+
+* 각종 컬 및 어덕션 운동을 할때는 몸을 회전축에 맞춘다.
+
+* 고관절에 힘이 들어가는게 하체운동이다. 뒤꿈치를 밀고 뒤꿈치로 당기고
+
+* 먹는게 편하고 소화가 잘 되는게 최고다
+
+* 수단과 방법을 가리지 않고 근육을 괴롭힌다. 그런데 관절이 편해야한다.
+
+*******근본: 힘이 작용하는 반대 반향으로 힘을 쓰느냐****
+
+*******왜 부상당했는지 체크하고 다시는 그렇게 안한다.****
+
+*******부상당하면 더 힘을 줘서 관절을 붙잡아야한다.****
+
+*******볼륨보다 타겟자극이 가고 있는지 확인하는게 최우선****
+
+
+
+
+---
+
+*여기서 기록하는 무게들은 1RM이 아니라 8회를 완벽한 동작으로 할 수 있을때 기록한다
+
+
+
+# 하체 
+
+* 하체에 대한 전반적인 팁
+
+	 * 무릎이 아플때 팁: 무릎을 95도 이상으로 펴고 살아라. 양반다리 하지말고, 서서 짝다리 할때 무릎을 굽혀서 근육으로 무게받기. 무릎 밑에 옷깔고 자기.
+
+
+---
+
+## 스쿼트 (고블릿: 12.5kg, 프레스 머신 100kg)
+
+	1. 엉덩이를 먼저 빼면서 골반과 무릎이 동시에 접히면 수직으로 내려간다 ( 상체는 수직으로)
+
+	2. 무릎이 먼저 접혀서 무게를 받치면 부상, 힘이 앞에 쏠리면무릎이 아프다. 
+
+	3. 중앙~뒤꿈치가 이상적. 발바닥에 힘을 이동하는게 핵심. 발바닥힘으로 해라. 아나토미. 자세 유지
+
+* 게르만 레슨:
+
+	1. 1원칙:  발방향, 무릎방향 일치 
+
+	2. 2원칙: 무게는 무조건 뒤꿈치로 해서 엉덩이 스쿼트만 해라 
+
+	3. 3원칙:  20회 이하할 수 있는 무게로 해라
+
+	4. 뒷편에 8할, 허벅지 앞이 주동근이 되면 끝장 (무릎이 앞에 나가지 말란 말은 무게중심을 발꿈치에 잡기 위해서 하는말)
+
+	5. 둔근과 대퇴이두가 잘 발달안하기 때문에 적응이 필요하다. 이후에 진짜 스쿼트를 할 수 있다. (문잡고 스쿼트하는거 추천)
+
+	6. 무조건 무릎이 자연스럽게 움직이게 각을 잡아라. 허리는 일자로
+
+* 지피티 레슨
+
+	1. 엉덩이를 뒤를 빼는건 앉으면서. 처음부터 그러면 복압이 안잡힌다. 브레이싱 호흡법으로 하면 이 밸런스가 잡힌다.
+
+* 강경원 레슨
+
+	1. 코어 근육이 훈련이 안되니까 밸런스를 못잡고. 과하게 엉덩이를 빼고 과하게 앞으로 빼면서 스쿼트를 하게 된다. 
+
+	2. 무릎과 골반이 동시에 움직여야 한다. 무릎이 먼저 움직이면 무릎만 힘쓴다. (제대로 동작을 하면 배, 대퇴 이두가 아프다) 
+
+	3. 무릎과 고관절이 동시에 빠진다. 고관절 먼저 x 무릎만 x 
+
+* 김명섭 레슨
+
+	1. 상체는 힘을 주지않는다. 브레이싱까진 말고 0.5복압만 해라.
+
+* 양코치 레슨 (가장 신뢰가 가는 레슨)
+
+	1. **다리 사이에 몸통 집어넣기**
+
+	2. **가슴을 편상태로 유지하기**
+
+	3. **두개 조건을 충족하는 발 거리와 무릎방향이 전부다**
+
+	4. **진짜 이게 정답이네**
+
+
+---
+
+## 레그 익스텐션 
+
+**원칙**
+
+* 햄스트링 유연성 확보 안되면 2 Joint 는 안됨. 
+
+* 무릎부터 힘을 쓰면 허벅지 근육이 모두 사용되지 못함. 골반부터 힘을준다 ⇒  대퇴직근 즉 허벅지를 들어야한다는 의미
+
+**양명섭 레슨**
+
+1. 상체를 당기며, 축구공 차듯이 위로 차올리기로 대퇴근 4개면 다 자극
+
+**양코치 레슨**
+
+1. 무릎을 전부 펴면 무릎운동이 된다. 적당히 밀어도 된다. 허벅지가 일을 하는것만 느껴도 충분해.
+
+2. 무릎과 의자 사이에 간격이 없도록 의자를 뒤로 민다음
+
+3. 뒤꿈치를 미는 느낌으로 하면 고관절까지 자극이 온다.
+
+4. 엉덩이를 바닥에 밀착
+
+5. 관절모양대로 무릎과 발이 11자 무조건
+
+
+---
+
+## 레크컬
+
+**양명섭 레슨 Two Joint**
+
+1. 대둔근에 힘을 먼저 주고 허벅지를 들면서 당기는 느낌으로 한다.
+
+2. 무릎 가동부는 자연스레 움직이도록 의식한다.
+
+3. 관절이 다 펴지지 않게 천천히 이완. **자극이 엉덩이 아래부터 무릎직전까지 왔다갔다하는걸 느끼면서한다.** 무릎까지 가면 부상.
+
+4. 엉덩이 힘쓰는게 익숙하지 않으면 엎드려서 엉덩이를 동작하는걸 연습한다.
+
+PLAN B One Joint
+
+****고관절을 절대로 머신에 붙인채로 햄스트링만으로 해야한다.*
+
+* 그 이상을 하면 (힘을 쥐어짜는 과정에서 무릎관절이 많이 긁히는것 같다) 무릎 박살 → 햄스트링운동이 아니게 된다.
+
+
+---
+
+## 워킹런지
+
+원칙
+
+* 일반적인 자세로 하면 무릎이 아프게 된다. (무릎이 발보다 앞으로 가고 무게가 앞으로 쏠리면 나쁜 자세. 앞다리 허벅지가 일을 하게 되고 무릎을 자극)
+
+* 이를 예방하기 위해 앞으로 무게를 밀다가 엉덩이를 빼면서 뒷 무릎을 쾅찍어버리면 무릎과 전퇴대신 엉덩이가 무게를 받쳐주는 모양이 나온다.
+
+
+---
+
+## 💛 레그 프레스 100: 
+
+1. 고관절이 받는게 아니라 근육이 받아야한다. 리듬을 느끼면서 계속 움직인다. 관절에서 버티는건 NG
+
+2. 하이 포지션, 일반 포지션 바꿔가면서
+
+3. 발과 무릎 방향이 일치하게만 해주면 됨 
+
+4. 상체는 힘을 빼고 자연스럽게 받고 던져야함 
+
+5. 오고 가는 속도는 일정하게 
+
+### 잡팁
+
+1. 마지막에 깔짝깔짝 후면 대퇴근 털기(모든 근육을 동일하게 쓰는게 아니다 보니 힘이 남아있다) 
+
+
+---
+
+## 💛 어브덕션 머신
+
+아웃타이트 A:
+
+1. 아나토미를 지킨다. (아나토미를 안하면 허리가 운동한다.)
+
+2. 근육 긴장안풀리게 유지하면서 운동.  
+
+3. 복부 힘주고, 살짝만 고관절을 앞으로 5도만 꺽는다. **엉덩이가 일을 하게 해야한다. 허벅지만 아프면 안된다.** 
+
+
+
+**양코치 레슨**
+
+아웃타이트 B:
+
+1. 축을 고정하고 엉덩이 중앙에 관절이 하나 있다고 의식한다. 
+
+2. 밀면서 다리사이에 몸을 집어넣는다. 
+
+3. 풀 가동을 엉덩이로 느낀다. 다시 돌아올때는 몸을 일으키고 arch를 자연스레 유지. 
+
+4. 살짝 들리는 느낌나도 괜찮다.
+
+
+
+### TIP and Advance
+
+1. 밴드쓰면 효과 좋다
+
+2. 개구리자세. 힌지를 많이 준 상태로 하체를 숙여 앞을 붙잡고 한다. 이 자세에서는 30도까지만 이완한다.
+
+3. 그냥 일어나서 한다. 힌지를 준상태에서 그냥 일어나서 해버린다.
+
+
+---
+
+## 💛 힙 스러스트:
+
+스트레이트 포지션 
+
+1. 허리 아나토미를 유지하고 쳐올린다. 완전히 쳐올리면 윗엉덩이까지 자극이 온다.
+
+2. 발은 15도 각도로 벌리고 발과 엉덩이가 너무 가까이 붙으면 허벅지를 쓰게 되니 다리를 멀게. 
+
+3. **고관절이 패드에 안떨어지게**
+
+4. 수축감을 느끼면서 천천히 진행하되 너무 내릴 필요는 없다. 
+
+5. **제대로 하면 코어에 힘이 확 잡힌다.** (코어에 힘이 안잡히면 허리힘으로 하는거)
+
+6. 의자에 앉지 않고 등받이에 기대고 한다. (발판을 넘어가잖아 너무 앞으로 앉으니)
+
+7. 중둔근이 하고 싶으면, 프로그 포지션(양반다리 느낌)
+
+
+---
+
+# 등 (다다익선)
+
+## 대원칙
+
+****등 운동 이완할때 관절을 빼면 긴장도 빠지고 어깨 운동이 된다.* ⇒ ***가슴을 이완시킨다는 느낌으로 당기고 그걸 가슴을 고정해놓고 최대한 팔을 보내면 된다.***
+
+* 가슴패킹을 해라. 가슴이 살린걸 유지하는한에서 등을 이완한다.광배근은 팔 상단에 붙어있다. 지나가는 관절. 등운동 공통. 주욱~ 가야한다. 힘을 빡주는 식으로 하면 최대 수축을 못함. 척추 아나토미를 지켜라 어느 순간이든
+
+* 
+
+## 💛 랫풀다운
+
+**양명섭 레슨**
+
+1. 와이드그립. 
+
+2. 항상 허벅지 위치와 케이블위치 조정을 일정하게 하고 해라. 
+
+3. 견갑골이 빠져서 최대로 이완되는걸 느낀다.
+
+4. 시소 타듯이 쭈욱 당기고 내가 쭈욱 밀고 익숙해지면 힙이 안뜬다. 
+
+5. 팔꿈치를 다 펴지 마라 (즉 데드행하지 말란 뜻) 데드행되면 광배힘이 풀림
+
+6. 새끼손가락힘이 광배근 운동의 증거
+
+7. 억지로 쥐어짜려고 목힘을 주면 상부승모근운동이 되고 광배에 힘이 안들어감. (제대로 못할거 같으면 중량조절을 하자 억지로 하지말고) 드러눕지는 마라. 줄을 수직으로 유지.
+
+
+
+**양코치 레슨**
+
+1. 넓게잡고 쇄골을 향해 내리면서 가슴을 넓게 펴라. 가슴을 펴는 방향으로 운동을 하면 어깨의 개입이 준다. 어깨가 바에 끌려가면 안되고 넓게 버텨야한다
+
+
+---
+
+## 💛 롱풀 [두께강화] 
+
+* 위에서 아래로 당기면 광배하단, 아래에서 위로 당기면 승모근이 사용됨. 그래서 다리를 적당히 펴줘야 자세가 나온다. 어깨-팔꿈치 순으로 수축, 이완. 수축을 제대로 해야한다.
+
+ 1. 코어 활성화 (등이 앞으로 견갑골이 다 빠지게 한다.)
+
+ 2. 당길때는 등을 먼저 뒤로 당기면서 팔꿈치를 뒤로 견갑골은 다 모은다. 힘이 부족하다고 아나토미를 풀고 배를 앞으로 보내버리면 안된다.
+
+ 3. 팔꿈치를 아래로 그리고 등 중앙으로 보낸다.   팔꿈치에 공간이 생기고 어깨가 뜨면 승모근 운동이 된다.
+
+
+---
+
+## 💛풀업 [견갑골근처 강화] 
+
+1. 데드행상태에서 시작해서 데드행상태를 게속 유지하지는 않는다. 옆구리로 당긴다. 팔꿈치가 등뒤로 가면 승모근과 삼두 운동. 견갑까지만 내려간다. 
+
+2. 가슴이 도착점을 노리는 느낌 (즉 심장을 앞으로 뽑으란 느낌)
+
+3. 내려올때 하나에 팔을 펴고 둘에 견갑골 오픈. ***팔보다 견갑골의 힘이 먼저 작용해야한다.***
+
+
+---
+
+## 💛케이블 암 풀 다운 [내로우 그립으로 하부광부] 
+
+1. 케이블 푸시다운과 달리 어깨를 들어올리고 호를 그린다. 
+
+2. 팔꿈치는 굽히고 안는 동작으로 바를 당긴다. 팔과 승모근 힘 뺴고 코어로 버티면서 당겨야 한다. 
+
+3. 덜덜 떨리면 안됨. 견갑골만 춤추듯이 뒷꿈치도 움직인다. 자연스럽게 하는데 정신을 집중해야한다. 
+
+4. 벌서는 느낌 받으면 잘못된 운동. 
+
+5. **팔꿈치를 구부리고 항아리를 안아서 배꼽까지 눌러주는 느낌으로 운동** 
+
+6. 50% 50% 로 내거티브로 운동
+
+
+---
+
+### 알아만 두는 운동
+
+* ~~덤벨스윙로우: [상부에 집중된 광배 쓰임을 극복]~~ 
+
+* ~~로터리 풀다운 (랫풀 대체)~~
+
+* ~~인버티드 로우: 풀업 ez 버전. 배워놓으면 공원에서 할 수 있을듯~~
+
+* ~~바벨로우(광배): 어깨를 누르고 옆구리로 팔꿈치 보내기. 승모근이 자극 될 수도 있지만 상관없다. 어깨를 눌러! (승모근 개입) 옆구리를 지나 등뒤로 보내는 느낌으로 몸은 고정.~~
+
+
+---
+
+# 어깨
+
+## 대원칙  
+
+* 소근육. 여기는 불탈만큼 해야한다. 다른 근육이 개입하지 않게 하는게 핵심. 몸통에서 떨어지는 만큼 소근육이 개입한다. 외전, 신전
+
+
+---
+
+## 💛사이드 레터럴 레이즈 b 지근중심 운동
+
+1. (12회 목표) 내회전해서 들어야 자극이 간다. 찝힘이 온다. 찝히면 외회전으로 하거나 각을 앞으로 둔다. 볼륨으로 조진다. 무거우면 가볍게. 자연스럽게 잠자듯이 올려라. 
+
+2. 앉아서 하면 승모근 개입x
+
+3. 팔꿈 살짝 구부리면 승모근 안움직임, 앞으로 올리기 측면으로 올리기 두가지 공략이 존재, 사이드하는게 일반적으로 좋다 (측면고립) 90도까지만 세트 중에는 긴장이 안풀리게. 팔 살짝굽히고. 등은 평평하게. 검지에 힘을 주고 덤벨로 물주듯이 기울인다. 
+
+4. 서서할 때는 옆으로 70도까지만 올려도됨, 고개를 조금 숙이면 어깨관절 여유 확보. 내회전해서 올려야 B를 쓴다. 
+
+
+
+**명섭 레슨**
+
+ 1. 90도까지 하되 충돌있으면 전면 삼각근 쪽이 쓰도록 각도조정 없으면 옆으로. 
+
+ 2. ***제일 중요한건 손가락에 힘을 주지않는다.***
+
+ 3. 자연스럽게 해야 원하는 근육에 자극을 줄 수 있음. (시작할땐 코어에서 힘이들어가고 내려올땐 광배에 힘이들어가게. 어깨는 힘이 약하니 혼자 힘으로만 버틸 순 없다)
+
+
+---
+
+
+
+##  💛리버스 팩덱플라이 35
+
+1. 가슴을 내밀어서 삼각근 개입 방지
+
+2. 끝까지 모아야함 (? 이건 무슨말이지)
+
+3. 팔꿈치 펴고 1 Joint, 팔을 수평으로 유지(내회전). 수평바 잡고 팔은 힘들어가지 않게 신경쓴다. 만약 너무 쉽게 쉽게 운동을 하고 있다면 팔힘으로 하고 있는거다.
+
+4. 살짝 앞으로 엎드리고 둥둥이랑 동작이 한지점으로 모이는 시점에 최고힘으로 민다. 
+
+
+---
+
+## 💛밀리터리 프레스
+
+1. 바벨 잡고 팔꿈치를 앞으로 보낸다. 
+
+2. 무게는 손으로 버티는게 아니라 흘려보내서 코어에서 안전을 유지한다. 
+
+3. 삼각근 타격을 위해 손목을 살짝 꺽어서 한다. (머리에 안부딪치게) 
+
+4. 살짝 뒤로 기대서 한다. 한번 팔꿈치 각도를 정하면 그대로 간다. 
+
+5. **내릴땐 어깨 수평까지만**
+
+
+---
+
+**💜**업라이트로우* <하단승모근 운동할 수 있는 유일한 방법>
+
+**A - 관절보호론**
+
+방법 a. 덤벨을 해머컬 처럼 들고 어깨까지만 올려. 
+
+방법 b.
+
+* 주먹 두개 범위로 잡는다
+
+* 내회전만 하지 말고 그냥 외회전 돌려버려 (만세, 겨드랑이 자랑) 
+
+* 수직으로 올리다가 어깨선에서 외회전으로 바꾼다. 
+
+* 전완근이 드는게 아니라 팔꿈치가 위로 올라가서 드는거다. 
+
+* 엄지는 그립에 안써도 됨 건들지도마. 
+
+**B - 측면 삼각근 운동**
+
+* 손목을 안으로 말고 몸에 붙여서 올리면 심장까지만 올려도 측면이 강하게 먹는다
+
+**C - 승모 수축감 중시론**
+
+* 손등이 앞을 보게 팔과 손목이 일자를 유지
+
+* 이러면 승모근의 수축이 유지된다.
+
+from 등운동 파트에서
+
+* 덤벨 업라이트:  로우를 땅과 평행하게 잡고 약간 비스듬하게 올리다가 마지막엔 지면과 수직으로 외회전. 젖꼭지 높이까지만 들어올린다. 
+
+
+
+
+---
+
+## 💛바벨 숄더 프레스
+
+1. 이두근이 귀옆을 지나가도록 종단점으로 모이도록 한다. 
+
+2. 몸은 아나토미 고정
+
+3. 수평선 이하로 내리진 말고 속도 일정하게(반동금지)
+
+4. ***승모근 안쓰게 어깨내리고*** 
+
+5. 수직으로 움직이고 수직으로 내려온다.
+
+6. 덤벨 숄더 프레스: 가동범위를 다 쓰려면 거의 팔을 다 펼때까지 해도됨.
+
+
+
+**양선수 레슨** 
+
+1. 너무 높게 안올려도 된다. 어깨 근육이 짧다.(승모근이 들어가기전에 끝낸다)
+
+
+---
+
+##  💛비하인드 넥 프레스 B> A > C 
+
+1. 찝히면 하지말고 프론트로 한다
+
+2. 팔꿈치가 뒤를 안바라보게 수평유지
+
+3. 코어에 압력 유지
+
+4. 어깨근육은 길지 않으므로 너무 내리지 않는다. (귓볼까지만 내린다) 
+
+5. 어깨만 아파야 한다. (삼두는 아파도 되) 
+
+6. 무게를 손 너무 뒤에서 안버티게한다. 
+
+7. **전완근 운동시키면 안된다. 손에 힘을 주지마(계란 잡는 느낌을 유지한다)**
+
+
+
+
+---
+
+~~-벤트오버 레터럴 레이즈 c: -~~
+
+~~A. 고개 숙이고 광배근 개입안하게 날개뼈는 놔두고. 양옆으로 플라이를 거꾸로 하듯이. 등을 라운딩 시키면 날깨뼈가 안정화된다. 딱 축늘어져 놓고 양옆으로만 이동. 시티드, 스탠딩 자유롭게. 팔과 손목으로 하는걸 주의.~~
+
+~~B. 팩덱플라이로 하자 그냥~~
+
+~~프론트레이즈a: 플레이트로 할때는 다 고립해놓고 어깨만 이용하게 중지 약지 새끼손까락으로 든다. 덤벨로 할때는 수평으로 딱 정확히 앞으로 보게끔 하고 머리까지만 든다. 전완.~~
+
+ ~~프론트 프레스 : 팔꿈치를 앞으로 보내고 원형의 운동방향을 가지면서 어깨를 보호한다. * 클라인 덤벨 플라이:고개 숙이고 45도까지만 하면 C를 다 쓴다. 이상은 승모근~~  
+
+
+---
+
+# 승모근
+
+* 원칙: 승모근은 라운드 숄더를 푸는 열쇠다.
+
+## 페이스풀
+
+1. 승모근이 들리지 않게 정확히 90도 각도로 당긴다
+
+2. 그립은 손가락이 3개 2개(검지엄지) 사이에 끼운다. 당기면서 로프를 더 벌린다.
+
+3. 당기는 목표는 미간을 때리는 느낌으로 수축할때는 빠르게 하는게 포인트
+
+4. 당기면서 살짝 만세하는 기분으로 곡선을 그려도 된다.
+
+## 💛 라잉 T바 로우25
+
+1. 가슴이 지지대에서 안떨어지게 유지
+
+2. 포지션: 견갑골과 팔꿈치만 기억. 좁게 잡고. 등은 중립. 
+
+3. ***가슴을 때지말고 최대 운동범위까지 팔꿈치 제쳐. 견갑은 고립시킨다.***
+
+
+
+**B - 서폿티드 T바로우** 
+
+1. 등을 과신전 X. 노젓들이 등을 올려야 한다. (=시티드로우) 팔꿈치를 뒤로 보내야한다. 
+
+2. 가슴은 고정시키고 광배근으로 운동하듯이 하면 되는데 대신 승모근이 비중이 더 크다.
+
+
+---
+
+## 슈러그 :
+
+으쓱. 약간 고개를 앞으로 보내고, 인클라인으로 할때 자극이 더 좋다. 팔꿈치를 살짝 굽혀주면 가동범위가 확 올라간다. 스탠딩 바벨로 할때는 살짝 숙여서 하면 가동범위업.  [어깨운동 끝나고 하면 굳]
+
+
+---
+
+# 가슴
+
+## 대원칙
+
+1. 아무리 무거워도 협력근개입이 덜 개입하도록 부드럽게 해야한다. 이렇게 못할거면 무게를 낮추는게 이득. 이렇게 할때만 중량을 주동근으로 처리할 수 있다. 
+
+2. 핵심은 어떻게 협력근 개입이 안되게 하느냐 어깨는 없다고 치고 가슴만으로 받아낼거란 인식을 하는것이다. 내가 가슴에 신경을 쓰면 알아서 허리가 아치가 된다. 
+
+
+---
+
+## 💛벤치프레스 30kg A B C 
+
+1. 협력근이 개입을 줄이도록 손 힘을 뺸다. 
+
+2. 일정한 속도로 가슴중앙부터 겨드랑이까지 이완수축을 느낀다. 
+
+3. 너무 많이 내리면 가슴에 힘빠지고 어깨가 받는다. (아 이래서 어깨가 아픈 거였나) 
+
+4. 앞으로 내보내는것도 적당히(어깨가 라운드 되면 대흉근 힘이 빠진다)
+
+5. 가슴을 내민다. 좀더 와이드하게 잡고 내렸을때 팔꿈치가 90도가 되는지 체크한다. 가슴을 느껴라. 최대 이완될때까지 찢어!
+
+6. 올리고 내릴때 수직으로 움직일 필요가 없다. 어깨가 편한 방향으로 비듬하게 \ 자로 운동한다. 오직 대흉근의 긴장에만 신경을 써라. 
+
+7. 쭉 가슴이 완전 펴질때까지 내렸다가 등이 다 펴지지 않을만큼한 올린다.
+
+
+---
+
+## 프레스머신 B
+
+1. ***어깨가 들리지 않는 높이에서 민다.*** 
+
+2. 손에 힘을 줘서 정확히 슈퍼맨 자세가 나와야한다.  이게 힘을 안주면 힘을 다른 관절에서 받게 된다.
+
+3. 공간이 생기면 힘이 안들어간다.  머리를 대면 등에 공간이 생긴다.
+
+
+--- 
+
+💛 인클라인 프레스 A B 20kg
+
+ 1. 약한곳을 먼저 단련한다는 관점에선 인클라인을 우선시 해야함.
+
+ 2. **천천히 이완 수축되는걸 느끼면 된다. 이것 뿐이다 진짜 이걸 못해서 난리인거지 ㅠㅠ** 
+
+ 3. 내릴때 살짝 턱을 당겨서 내려서 보기. 
+
+ 4. 편안하게 올리고 내리고 수직으로 일정하게, 수평까지만 내리고 꿈치는 살짝 몸이 붙인다. 
+
+ 5. 벤치 각도는 35도. 피니시 동작에서 살짝 모아준다 쇄골로
+
+
+---
+
+## 💛인클라인 덤벨 프레스 
+
+1. 내렸다가 올릴때 덤벨이 모이는게 최대수축 포지션
+
+2. 이두가 귀에 닿는 느낌 유지.
+
+3. 살짝 허리 신전. 팔꿈치가 어깨에 올라갈 필요없다. 살짝 몸에 붙인다. 쇄골 1/2 지점으로 올린다. 
+
+
+---
+
+## 케이블크로스오버
+
+1. 그냥 원조인트로 하는걸 추천. 기본은 안는거다. 
+
+2. 살짝 앞으로 수구리고 하나에 몸통이 먼저 내리고 둘에 팔꿈치로 쭈욱. 
+
+3. 팔힘이 아니라 팔꿈치에서 힘이 동작한다. **날개짓하듯이 자연스레 승모근이 수축 이완되는걸 느껴야함.** 
+
+4. 누르는게 아니라 끌어오는거다. 
+
+
+---
+
+* ~~딥스: 대흉근(아래), 팔꿈치를 벌려야 내회전이 된다. 숄더패킹금지. 손과 어깨에 힘을 미리 주지말고 중심만 잡는다. 하나둘 하면서 내려가고 올라올때 바를 민다. 몸통은 움직이지 말고 팔꿈치를 다 펴지말고. 내려올떄는 다 이완시키기.~~
+
+-방법B - 아래를 보고 무릎을 앞으로 보내고, 엉덩이를 살짝 대고 딥스하면 정확히 가슴만 타격-
+
+* ~~덤벨 풀오버 A: 라잉 트라잉셉션을 하는데 벤치에 옆으로 기대서 머리밑까지 내린다. 팔꿈치를 귀까지 주욱 내려준다. 목에 힘뺀다. 팔을 뻗으면 삼두, 광배가 많이 먹고 팔을 굽혀서 머리에 가깝게 하면 대흉근 중심. 길항근에 힘을 빼고 내려야한다. 걍 머리 뒤로 슉 던져버리고(저항X) 수직으로 올리고 당기고. 덤벨이 흔들리지 않게 수평유지.~~
+
+
+
+
+---
+
+# 삼두
+
+## 원칙
+
+* 팔 신전(종아리를 신전시키는 대퇴부와 비슷하다) 장두가 2조인트 이므로 이를 활용해야 통증을 피할 수 있다. 삼두 운동할때는 광배에 힘이 들어온다면 잘하는거다. (푸시다운을 하면서도 케이블 폴다운 하는 느낌이 나도 된다)
+
+* 
+
+
+---
+
+**💛**케이블 푸쉬 다운*: 타원형을 그리도록(장두 풀 수축) 삼두운동이니 어깨가 움직이면 안됨. 팔꿈치는 먼저 움직이지 않는다. 2) 어깨는 내리고 팔꿈치는 옆에 붙고 3) 운동할땐 손이 몸에 붙지않고 살짝 떨어지게
+
+**10kg 라잉 트라이셉스 (메인): 팔꿈치가 소리나면 안됨. 1) 천층인 어깨를 먼저 던지면서 내려간다 2) 눈을 지날때 팔꿈치를 구부린다. 3) 정수리에서 딱 멈춘다. 4) 팔을 펴고 -> 수직까지 들어올린다.** 광배에 힘을 줘서 안정적인 자세가 나와야 한다. (가장 천층이 광배, 어깨, 삼두 순으로)
+
+* 오버헤드 트라잉 셉션: 방법 A (팔꿈이 앞을 보고 고정된 상태로 운동. 천천히 내리기, 어깨는 내리고 승모근 개입 X), 장두 개발에 특화(거의 유일) B 던지듯이 내리고
+
+
+
+* 손날로 민다고 하고 피니시 동작에선 상완을 안으로 말면 팔꿈치부상이 없다.
+
+
+
+**이두**: 팔뚝에서 시작해서 견갑골에 붙어있다. 2조인트. 어깨가 먼저 힘을 써서 받쳐줘야 삼두가 힘을 쓴다.
+
+**💛**바벨 컬*: 1조인트로 운동할 수도 있지만 2조인트로 하면 완전하다. 팔은 몸쪽에 가깝게 붙인다. 딱 아나토미 자세로 한다. 무게중심으로 바벨을 끌어들이는 운동. 어깨가 딸려가지 않게 조심. 거울을 봤을때 이두에 상완이 덮히게 딱 수직유지  1) 크게 팔을 앞으보내고 2) 내가 하던대로 팔꿈치 고정한 상태로 들어올린다. 눈앞까지.  3) 다시 내리고 4) 팔을 내리고 // 잘 모르겠으면 머신으로 한다. (머신 효율이 제일 좋은 운동인듯함)
+
+	* 스트레이트바는 넓게 좁게 잡지마. 이지바로 하면 밖이 발달. 
+
+	* 덤벨로는 자유롭게 컨트롤 가능.
+
+
+
+* ~~해머컬(상급자): 상완근 용도. 1joint 어깨 고정시켜놓고 올리기만해~~
+
+
+---
+
+# 복부 및 코어 운동
+
+## 💛롤아웃
+
+1. 운동 끝 까지 복근에 힘이 들어간 상태로 할로우 자세 유지(복부를 천장에 붙이는 느낌). 
+
+2. ***둔근 힘주고 하체힘으로 밀다가 다 밀면 상체로 밀고*** 돌아올때도 하체의 힘으로 돌아온다. 
+
+3. 중간에 둔근 힘 풀리면 멈추고 다시 힘주고 진행. 
+
+4. **세트가 끝나기 까지 복근힘 풀지말고 계속 진행.** 
+
+5. 다리를 펴는거지 팔을 앞으로 밀지마라. 
+
+6. 당기면서 등을 화난 고양이 마냥 말아준다. 	
+
+
+---
+
+## 💛*데드리프트 [햄스트링, 대둔근, 기립근] 
+
+1. 광배근 방향으로 그립 (손들었다 내리기) 
+
+2. 항시 바는 몸에 붙어 있도록 컨트롤. 척추 중립자세를 유지하고 
+
+3. only 엉덩이 힌지로 숙인다. (무릎을 쓰면 대퇴가 힘을 쓰고 코어가 힘 빠진다.)
+
+4. 수행 절차
+
+	1. **팔을 내회전 해서 그립** 제대로 하면 등 전체에 계속 힘이 들어간다. 인사하듯이 허리를 숙이고 
+
+	2. 엉덩이를 빼고 
+
+	3. 무릎까지 내려가면 잠시 무릎 숙이고
+
+	4. 쭉 다시 올라오면 된다. **이때 머리를 든다는 느낌으로하면 허리가 안말린다.** 
+
+	5. 무조건 천천히. 등 안말리게 힘주고 
+
+5. 햄스트링 둔근에 힘이 안빠지도록 무릎을 쓰지 않는다.
+
+6. 스쿼트도 마찬가지다 고관절을 먼저 먹고 그 다음이 무릎.
+
+7. 빌더들 포즈잡는것처럼 팔꿈치를 살짝 굽히고 내회전해서 광배가 들게끔한다.
+
+8. **무조건 뒷꿈치가 운동하게 한다 원래그 데드리프트 뒷다리를 올린다.**
+
+**마지막 마무리는 엉덩이가 땅기는 힘으로 하는거다**
+
+
+---
+
+**💛**스티프 데드리프트:*
+
+덤벨로 하는데 발목까지 내리고 고관절을 최대한 뒤로이 발앞을 그냥 들어올려도됨. 
+
+허리를 완전히 수직까지 올릴필요없이 적당히 하다가 다시 숙인다 스티프는
+
+
+---
+
+**💛**코어 운동 세트*(A형 B형 왔다갔다 하면서 한다)
+
+A형) 엘보 플랭크, 사이드 플랭크(10초), 숄더탭, 슈퍼맨 플랭크, 점핑 잭, 트라이셉스 푸시업, 원엘보 플랭크, 크로스 마운틴 클라이머, 와이드 플랭크, 아웃사이드 마운틴 클라이머 
+
+B형) 러시안 트위스트(앉아서 허리를 뒤로 보낸채로 좌우로 팔회전) , 캣 앤 카우(허리를 폈다가 줄였다가. 펼때는 다리도 편다), 데드버그(뒤로 누워서 허리 중립하고 크로스하게 사지 뻗기), 플라잉독(사지로  버티면서 크로스로 사지 뻗기)
+
+
+---
+
+## 운동에 대한 조언들
+
+**초보일때는 무분할이 낫다. (1년)** **동일 볼륨일 경우 날을 쪼개는게 이득**
+
+
+
+## 하고 싶은 운동 리스트
+
+`농구 탁구 복싱 스케이트보딩 서핑`
+
+
+
+## 회복과 근육성장에 대한 조언
+
+* 언제 자든 상관없이 시간과 질이 중요하다.
+
+* 동화-이화 상태를 구분하는게 중요하다. 자기직전 밥먹는거 안좋아
+
+* 인터벌은 성장호르몬에 최고다. 잠자는거 만큼이나 효과가 있다.
+
+* 공복운동은 기본
+
+* 하체(A/B), 복근, 등(당기는 자세),팔, 가슴은  어깨 진정될때까지만 이렇게 하자. (어깨 운동 완전 배제)
+
+
+---
+
+## 인터벌 트레이닝
+
+* 전력 (30 ~ 60 seconds) - 회복레인지 (1~2minutes) 10세트
\ No newline at end of file
diff --git "a/Bear/\360\237\217\224bash shell.md" "b/Bear/\360\237\217\224bash shell.md"
new file mode 100644
index 0000000..f13da6a
--- /dev/null
+++ "b/Bear/\360\237\217\224bash shell.md"	
@@ -0,0 +1,1302 @@
+# 🏔bash shell
+
+노트 사용법
+
+1. H1에서 명령어 그룹핑, H2에서 명령어
+
+
+---
+
+## 기본적 규칙
+
+* 기본적으로 변수는 모두 전역. 함수 안에선 local 키워드 지원
+
+* 로그인쉘 ≠ 스크립트쉘
+
+* 쉘프롬프트(`$`)는 입력대기를 뜻함
+
+
+
+## 유닉스 기초... 기초
+
+* 쉘의 역사
+
+	* sh는 POSIX 표준을 따름 ( Bourne sh)	
+
+bash는 이제 표준을 따르지 않는다.
+
+
+
+* 입력을 넣는 방식
+
+	* command line 	`./test.sh 1 2 "string"`
+
+	* STDIN			`echo "1\n2\nstring" | ./test.sh`
+
+
+
+## 예약변수(Reserved Variable)
+
+* HOME, PATH, LANG, PWD, FUNCNAME, SECONDS(실행된 시간),  SHLVL(쉘 실행의 중첩된 깊이) 
+
+* OSTYPE, TERM(로긴 터미널 타입), HOSTNAME, HOSTYPE, LOGNAME(로그인 이름)
+
+* UID, USER, USERNAME, GROUPS, TMOUT
+
+
+
+## 특수 매개 변수 (Special Parameters)
+
+* $$ 현재 스크립트 PID
+
+* $? 최근에 실행된 명령어의 exit code
+
+* $! 최근에 실행한 백그라운드(비동기) 명령의 PID
+
+* $- 현재의 옵션 플래그
+
+* $_ 지난 명령의 마지막 인자로 설정된 특수 변수
+
+* $0 쉘 파일의 이름
+
+* $1 첫번째 파라미터
+
+**$** 전체 파라미터
+
+* $# 파라미터의 갯수
+
+
+
+## 매개 변수 확장(Parameter Expansion)
+
+* ${var} $var  같은 기능 이지만 전자가 더 범용성 있는 표현
+
+* ${var:위치} 문자열 추출
+
+* ${var:위치:길이} 문자열 길이만큼 추출
+
+* ${var:-단어}
+
+## 배열 (Array variable)
+
+* 배열 변수사용은 반드시 괄호를 사용 ${array[1]} 
+
+* array=(“a” ”b” ”c”)
+
+* array[4]=“d”
+
+* array=(${array[@] “e”)
+
+* echo "배열 전체 출력: ${array[@]}"
+
+* `echo "배열 전체 개수 출력: ${#array[@]}"`
+
+* 특정 요소 지우기 `unset array[4]`
+
+* 배열 전체 지우기 `unset array`
+
+
+
+## 논리연산 (arithmetic Operators)
+
+`&&, -a   논리 AND`
+
+`||, -o   논리 OR`
+
+```
+
+	* ** 거듭제곱(power)
+
+	* % 나머지값
+
+	* += -= *= /= %=
+
+```
+
+
+
+
+---
+
+# 문자열
+
+## 문자열 비교 String comparison
+
+<, > 아스키 알파뱃 순서에 더 작음
+
+-z    문자열이 NULL, 길이가 0인 경우
+
+-n    문자열이 null이 아닌경우
+
+
+
+## test, [
+
+* `type [` 을 해보면 이게 문자가 아니라 `a shell builtin` 으로 나온다. 
+
+* `[`도 하나의 명령어고 test 명령어다.  `]`은 인수를 닫는 마지막 인수로 사용된다.
+
+* 사용할 수 있는 옵션은 다음과 같다.
+
+	* -e 파일이 존재
+
+	* -s 파일이 존재하고 0보다 큰 경우
+
+	* -d 파일이 존재하고 디렉토리인 경우
+
+	* -x 파일이 존재하고 실행가능하면 (더 궁금하면 그때 검색해서 쓰라구 호호)
+
+	* -nt 더 최신의 파일인지 newer than (>)
+
+* if 할때 꼭 test를 안써도 된다. (`-q` 결과 미출력)
+
+```
+
+if grep -q "bin" sample.txt ; then
+
+```
+
+잡으면 0, 못잡으면 1을 반환하는걸 활용할 수 있다.
+
+
+
+## 🔥쉘 문법 검사
+
+sh -nv [script]
+
+* 실행전 명령어 검사 + verbose 
+
+
+
+## IFS(internal field separator) 
+
+* bash 의 기본값은 공백이다. 별도로 선언할 수 있다. 
+
+* `IFS=''` 이렇게 정의하고 개행을 넣는식으로 자주 쓴다. (파이프를 쓰면 개행이 기준이니까)
+
+`mkdir test;cd app; cd` 성공 여부 상관없이 계속 다음 명령어 수행
+
+`mkdir test&&cd test&&` 성공을 하면 다음 명령어 수행
+
+`mkdir test& cd test&` 백그라운드에서 실행을 의미
+
+
+
+## 쉘 환경변수 지정
+
+* `set -e`
+
+git pull;	make clean; 	make;
+
+* 이런 연속된 과정에서 $? 의 값이 0이어도 계속 실행을 하게 한다. 반대로 종료하려면 set +e
+
+* +x는 불필요한 로그를 찍는 원인이 될 수 있으므로 리트라이 할 때만 해줄 수 도 있다. 끄고 싶으면 set +x +e
+
+* set -o pipefail
+
+	* 파이프 사용시 이전 단계의 오류(non-zero exit code)를 승계하도록 하는 설정
+
+* set-o errtrace
+
+	* 일종의 디버그 모드 어디 함수에서 생겼는지 말해준다.
+
+ * 쉘 환경변수 관리
+
+	* 그냥 선언한 변수는 로컬취급으로 set 으로만 조회가능하나
+
+	* export로 선언하면 전역변수가 된다. env, set 조회가능
+
+
+
+##  exec 
+
+* 주어진 명령어를 실행하는데 새로운 프로세스를 실행하지 않고, 실행중인 쉘 프로세스를 대체하여 실행한다. 
+
+* 이 경우 실행이 끝나면 쉘이 끝나기 때문에 다른곳에서 ssh로 접근했다면 터미널은 끝나게 된다.
+
+* 쉘안에서 실행하는 명령어들도 별도의 프로세스라는걸 인식
+
+
+
+## EOF 를 통한 입출력
+
+
+
+```cat <<EOF > /etc/resolv.conf
+
+nameserver 8.8.8.8
+
+EOF
+
+
+
+cat <<EOF >> /etc/resolv.conf // 이렇게 덮어쓰거나 append 가능
+
+nameserver 8.8.8.8
+
+EOF
+
+```
+
+
+
+## echo
+
+* 배시쉘 함수에선 return 대신 echo를 쓰면 반환된다.
+
+* echo의 이런 동작특성이 햇갈린다면 값을 반환할때 외부 스코프 변수에 값을를 할당해라
+
+* echo 는 실행한 환경으로 값을 돌려준다. 그래서 [프로그램] > text 하면 에코에서 찍은걸 그대로 값으로 저장하고 유저는 볼수없다.
+
+`echo -e`  escape 문자를 사용하게 해주는 옵션 carriage return, new line 
+
+
+---
+
+유닉스 쉘 스크립트 예제 사전내용.
+
+
+
+
+
+## 리다이렉트
+
+`>`	명령 프롬프트 대신 장치에 명령 출력 (`>>`  append)
+
+`<` 	키보드나 핸들에서 입력을 읽지 않고 파일에서 입력을 읽기
+
+`>&` 	한 핸들의 출력을 다른 핸들의 입력으로
+
+`<&` 	다른 핸들의 입력을 읽어서 다른 핸들의 출력으로 
+
+`|` 	다른 출력을 읽어서 다른 명령의 입력으로
+
+`sort < file.txt > result.txt` 이렇게 쓰는것도 순차적으로 하는것과 같은 결과를 낳는다. `sort file.txt > result.txt`  입력을 지정해주는게 `<` 개념만 말고 가면 된다.
+
+
+
+## getopts 	
+
+* etopts 를 이해기 위한 기본 지식
+
+	* optionString ≈ flag
+
+	* optionArgument(옵션인수) 옵션스트링 뒤에 입력되는 값
+
+	* $1 이렇게 포지션 기반으로 하는것보다 좀 더 유연한 입력을 받기위한 getopts
+
+	* 옵션은 -abc 이렇게 사용해도 된다. 
+
+	* --구분자를 쓸 경우 우측에 있는 값은 옵션으로 해석되지 않아야한다.
+
+	* `$OPTIND` →  Option Indicator 처음 값은 1 이 값은 옵션의 포지션을 가르킴. 옵션과 옵션인자를 모두 카운트한다.
+
+		* `set -- -a 123; getopts; // 이렇게 호출하면 $OPTIND 는 3`
+
+	* 파일명이 들어오면 그 뒤의 옵션은 무시된다.
+
+* set -- [옵션]
+
+	* positional parameters 를 설정
+
+	* $@ 파라미터 전부를 참조
+
+
+
+* 입력받은 인수를 처리하는 명령어
+
+	* 이걸 실행할때마다 다음 $opt 값이 변함.
+
+	* $OPTIND는 구분자 '\s'마다 변함.
+
+```
+
+getopts "abh "
+
+	// arg없이 플래그만 있다
+
+getopts a:b:h 
+
+	// a와 b는 arg를 가진다. h는 플래그만 있다.
+
+	// a의 arg는 $arg_a 이렇게 호출 할 수 있다.
+
+while getopts "ab:h" opt
+
+do 
+
+  case $opt in
+
+    a) arg_a=$OPT
+
+  esac
+
+done
+
+```
+
+
+
+## case
+
+```bash
+
+for filename in *
+
+do 
+
+  case "$filename" in 
+
+    *.htm | *.html) // 이렇게 정규식을 이용하여 분기하고 
+
+      headname=$(filename%.*) // 파라미터 확장으로 값을 추출할 수 있다. (%)
+
+      mv "$filename"  "${headname}.tet"
+
+    ;;
+
+  sac
+
+done
+
+```
+
+```
+
+  192.168.1.*) // 이런 패턴도 가능하고
+
+  *bin/sh|*bash*) //이런 방법으로 분기도 할 수 있다
+
+```
+
+
+
+## Regular Expression 
+
+	* Bash는 특수 명령을 통해 regex를 처리할 수 있다. 주로 조건문에서 사용한다. 그걸 지원하지  않는 sh에서 쓰는 명령어
+
+```bash
+
+$ AA="foo 12345 bar"
+
+$ expr "$AA" : "foo [0-9]\+"
+
+```
+
+	* length STRING 
+
+	* index STRING CHARS 
+
+	* substr STRING POS LENGTH
+
+		* 이렇게 문자열을 처리하는데 특화
+
+	* STRING 에 예약어가 있으면 + "$STRING"
+
+* 문자열을 찾고 자르고 하는거 다 할 수 있으므로 String을 다룰때 꼭 다른 스크립트 언어를 써야한다고 생각하지 않아도 된다. 다만 다른 스크립트를 쓸때 다양한 라이브러리를 쓸 수 있으니 
+
+
+
+* 문자열을 찾아서 반환하는 테크닉
+
+```bash
+
+t="MULTI: primary virtual IP for xyz/x.x.x.x:44595: 10.0.0.12"
+
+searchstring="IP for"
+
+
+
+rest=${t#*$searchstring}  // #* 이렇게 처리하면 searching 뒤의 문자를 캐치한다.
+
+echo $(( ${#t} - ${#rest} - ${#searchstring} ))
+
+```
+
+
+
+
+
+## shift
+
+* `positional params`를 왼쪽으로 민다. `$#` 은 감소한다.
+
+* `shift $(expr $OPTIND - 1)`
+
+	* 이렇게 사용하면 $1이 무조건 타깃만 가르키도록 할 수 있다.
+
+
+
+## trap
+
+	* signal을 받았을때 처리하는 예약함수
+
+`trap 'echo try count: $count'exit ' INT    `
+
+
+
+## *dev*null
+
+* 이곳으로 다이렉트를 하면 출력을 버릴 수 있다. 굳이 화면에 보거나 저장하지 않는다면 쓰면 깔끔
+
+* 파일 설명자
+
+```
+
+0> /dev/null 	표준 입력 무시
+
+1> /dev/null 	표준 출력 무시
+
+2> /dev/null 	오류출력을 무시
+
+.sh > /dev/null			// 또는 2>&1 표준 출력과 오류출력 모두 무시
+
+```
+
+
+
+`echo HellWorld 1> ok.txt 2> fail.txt`  이렇게 하면 출력과 오류 둘다 구분할 수 있다. 
+
+(op. 파일관련 attr로 실행 중 오류를 체크하도록 활용할수 있겠다)
+
+
+
+## read
+
+* 사용자의 입력을 받음. 한번에 여러 인자를 받기 가능. 쉘을 실행한 뒤 press button 으로 같은 방법으로 응용!< tty
+
+* `-r` 옵션은 CR같은 개행문자를 그대로 받아들인다. 
+
+
+
+## stty
+
+* 터미널을 관리하는 명령어다. 암호를 입력받고 싶을때 사용하면 좋다.
+
+* `-echo` 플래그 → 출력을 끄는 옵션 (echo의 옵션도 꺼지므로 암호를 받고 다시 켜준다. (`ssty echo`)
+
+* `state=$(stty -g)`   // 현재 터미널의 설정을 저장
+
+* `stty raw`
+
+* `stty $state` 		// 터미널의 상태값 설정
+
+
+
+## dd
+
+* 블럭 단위로 파일을 복사, 변환하는 명령어.
+
+`$(dd bs=1 count=1)`// 1bs, 1번을 읽음. 이 경우 키보드의 입력을 받는다.
+
+* `dd if=dev/urandom of=tmp.dat count=1024 bs=1024` urandom은 압축률이 낮은 실제 데이터처럼 동작한다. `of`는 출력파일 `bs`는 복사할 블록크기. 즉 1024 블럭을 1024회 반복
+
+
+
+
+
+## 명령어 치환
+
+```bash
+
+message=`echo message.txt`  // 그레이브로 감싸면 이렇게 하면 출력값이 스트링을 대신한다.
+
+tty=`tty`
+
+read dir < tty
+
+이렇게 하면 터미널에서 벌어지는 입력을들 dir로 받을 수 있다.
+
+``` 
+
+
+
+## tty
+
+`*dev*ttys000`  이 경로는 터미널 가상 디바이스를 반환한다. 
+
+
+
+## loop 에 대한 리다이렉트
+
+```bash
+
+while read [라인변수]; do
+
+	[Do somthing]
+
+done < [작업대상이 개행된 파일]
+
+```
+
+* cat으로 라인 변수를 받는 방법
+
+```bash
+
+cat [파일명] | while read [라인변수명]; do
+
+	[Do something]
+
+done
+
+``` // cat을 하고 
+
+
+
+## \033
+
+* 문자, 백그라운드에 컬러부여하는게 가능하다.
+
+`echo "\033[31;31m 하이여\033[0m"` 
+
+
+
+## dialog
+
+* 볼 수 있고 GUI 프로그래밍이 가능
+
+* 라디오 체크박스, 인풋박스, 라디오, 파일선택 다 가능
+
+
+
+## pv (pipe viewer)
+
+`tar -cf file1 file2. | pv | gzip > f.tar.gz`
+
+* pv 파이프는 진행상황을 보여주는 툴
+
+	* -L : 파이프 초당 전송량에 리밋을 건다. 1g (이것도 좋네 혼자서 CPU쓰는건 최악이야)
+
+	* -s : 사용할 자원의 최대치 지정 (이건 쓸만하네 너무 큰 작업을 하지 않게!)  
+
+
+---
+
+## 매개변수 확장
+
+* 테크닉 환경변수 유무를 체크해서 초기화하기
+
+```bash
+
+// 변수 미선언 혹은 NULL일때 에만 기본값 지정, 위치 매개 변수 사용 가능(예: 
+
+echo ${string:=HELLO})
+
+```
+
+
+
+`:{$TMPDIR:=/tmp}`
+
+
+
+## `:`(null)
+
+ * 콜론도 명령어다. 이걸로 초기화도 할 수 있다.
+
+`cp file1 ${TMPDIR:=/tmp}`  이렇게 바로 인자로 쓰는 방법도 된다.
+
+
+
+## ${var:} 추가적인 문법
+
+
+
+```bash
+
+	${var:?message} // var의 값을 참조하는건데 없으면 message를 보여주고 종료
+
+	${var:+message} // var가 빈 문자가 아니면 message를 반환
+
+```
+
+
+
+
+
+## : (null)
+
+: 문자는 아무것도 안한다는 것을 명시적으로 쓰는 용도로 사용가능
+
+
+
+## "expr 변수명 : 패턴"
+
+* `String="This is a pen"`
+
+**`echo "$String" : "This is a \(.**\)."`
+
+이렇게 하면 'pen'이 결과물
+
+* expr은 패턴이 일치하면 0을 반환
+
+
+
+## 확장치환
+
+: 그레이브는 실행하고, 큰 따움표는 확장치환을 지원하고, 작은 따움표는 값을 그대로 표현한다. 스트링을 표현할때 최적화
+
+
+
+## 닷 명령어 (bash 는 source도 된다)
+
+sh ./(쓰고 싶은 쉘)이렇게만 하면 끝. 마치 소스에 붙인것 처럼 참조 및 수정 가능. 단 실행하는 쉘에선 부모 쉘을 참조할 수 없다.
+
+[ -f file] && . /env.sh
+
+
+
+* 문자열을 처리할때 항상 큰 따움표를 쓰는걸 습관을 들여야한다. (공백처리에 용이)
+
+* 변수를 쓸때는 이게 빈값을 참조하고 있을 수도 있다는걸 염두해야한다.
+
+* 중괄호참고를 통해 연속적 스트링을 표현.  "$melong haha" == "${melong} haha"
+
+	* Bash 배열의 경우 무조건 Curly braket으로 호출해야한다.
+
+
+
+## sed
+
+sed -n 출력을 따로 안한다. "s*some/thing*p" 마지막 인자로 p를 주면패턴을 찾았을때만 출력한다.
+
+sed -n "s*<code>\(.*\)><\/code>/\1*p"
+
+
+
+## eval
+
+쉘 스크립트를 동적으로 생성하는데 용이한 명령어. 메타프로그래밍. 보안에는 취약. 만약에 사용자로부터 입력을 받아 실행하는 코드가 있다면 공격코드를 실행하게 된다. OS Injection
+
+
+
+## 문자열 실수 줄이기
+
+```bash
+
+err_coint=`grep -c "ERROR" /var/log/\`host_anme\`.log`
+
+```
+
+이런식의 그레이브 문자열 처리는 실수를 유발하기 쉽다
+
+`err_count=$(grep -c "ERROR" *var/log*$(hostname).log)` 
+
+→  서브쉘을 실행시켜 결과값을 받는 구조가 더 깨끗하다.
+
+
+
+
+
+## Shell option
+
+`-u ( set -o pipefail; true|false|true); echo $?`
+
+	연결된 명령중 하나라도 false면 실패
+
+`-e`  명령이 에러로 종료하면 종료 (if, while, untill, ||, && 같은 분기문은 예외)
+
+`-v verbose`
+
+`-x`  명령 시행전에 매개변수확장, 명령치환, 산술확장이 완료된 결과를 보여줌
+
+`-f  → no glob == 와일드카드 `  표현을 사용하지 않음.
+
+
+
+## 확장도큐먼트, HERE DOCUMENT
+
+pure mode
+
+```bash
+
+cat << '__EOT__'  
+
+$변수 //$변수 출력
+
+\$변수 //이렇게 쓰면  \$변수
+
+__EOT__
+
+```
+
+
+
+## HERE STRING
+
+```bash
+
+`cat <<< "안녕하세요
+
+이런 방법도 있습니다. $hello "
+
+```
+
+→  이렇게 쓰면 EOT 없이도 확장표현을 처리할 수 있다.
+
+
+
+## 절대경로실행	
+
+`cd "$(dirname "$0")"	`	//  디렉토리까지만 반환해주는 명령어 
+
+`cd "${0%/*}"			`	//  확장쉘을 사용하여 실행 경로의 위치로 이동
+
+
+
+## basename 현재파일명을 이용하여 이식성 높히기
+
+`program=$(basename "$0")`	//  이렇게 하면 어떤 프로그램을 실행했든 유연하게 이름을 받아온다.
+
+```BASH
+
+if [ $# -ne 1 ]; then
+
+  echo "Usage : $program <string>" 1>&2
+
+  exit 1
+
+fi
+
+echo "Start: $program, arg 1: $1, Stop: $program"
+
+```
+
+`program=${0$$**}`  /* 이것도 가능하다. (확장표현인듯)
+
+
+
+* 서브쉘을 활용하면 좋은때?
+
+	* cd 처럼 실행환경을 바꾸는 일을 회피하여 독립적 작업을 구현
+
+	* 부모의 변수값을 호출 할 수 있으므로 독립성을 보장 (Write는 불가)
+
+
+
+## find
+
+`find -type [dfl]`
+
+* -type -d  할 때 찾는 디렉토리도 숫자에 포함되므로 1을 빼서 사용한다.
+
+`$dirCount=$(expr $count - 1 )`
+
+* f는 일반 파일, l은 심볼릭 링크를 의미한다.
+
+
+
+## ':' command
+
+: > now.log
+
+echo "" > now.log 보다 짧음!!
+
+touch 는 이미 파일이 있을때는 time만 갱신한다. 널 커맨드가 초기화에 최적
+
+
+
+## touch
+
+원래 타임스탬프를 수정하기 위해 쓰는게 원래 의도. 자동으로 파일을 생성하지 않기를 원한다면 -c 플래그
+
+```bash
+
+*besename [-s suffix] string *
+
+basename -s .py bear_import
+
+```
+
+-s 플래그: 확장자를 지운 값을 반환 받는다.
+
+
+
+## cat > my_file
+
+// 이렇게 하면 파일 내용을 바로 쓸 수 있게 스트림을 터미널 입력에 건다.
+
+
+
+## tree
+
+`tree [~~L] depth [~~d] [-f] path`
+
+ * 디렉토리 구조 보기 좋은 명령어, 뎁스 및 디렉토리만 보기 지원
+
+
+
+## mtime 이용한 파일시스템 운영
+
+`find $dir -mtime -3` 3일 미만으로 변경된 파일만 검색 `+3` 은 3일 초과한 `3`은 3~4일
+
+
+
+## xargs
+
+* `find $dir -mtime +364 -print | xargs ls`  이렇게 미리 어떤 명령이 실행되는지 확인해라. `rm`은 무서우니까
+
+* `find $dir -mtime +364 -print0 | xargs -0 rm ~~fv`  앞에선 구분자를 null로 하여 사용한다고 하고 , `~~print0`을 통해 구분자를 null로 하도록 파이프를 연결하면 하면 띄어쓰기 등으로 인한 예외를 처리할 수 있다.
+
+* xargs는 넘겨 받은 명령들을 운영체제에서 지정한 명령행 인수의 상한값 (`getconf ARG_MAX`) 을 넘지 않도록 알아서 나눠서 실행하는 좋은 녀석이다. `find ... -print | xargs grep "ERROR" *dev/null` 이렇게 하면 find의 결과물 내용이 길어서 에러가 나는 문제(`Argument list too long`)를 피할 수 있다. 여기서 `dev*null`이 있는건 그랩이 늘 복수개를 대상으로 실행함으로서 결과에 파일명이 나오게 하기 위함이다. (이거 좋다야). zsh에선 항상 파일이름이 표시되네
+
+
+
+## date
+
+* $( ) 명령어 치환 `$(date '+%Y%m%d%H%M.%S')` 이렇 포맷으로 쓰면된다.
+
+* 말일을 판단하기. 아래 쉘을 매일 실행하도록 cron에 등록하면 된다.
+
+```bash
+
+tomorrow=$(date "+%d" -d '1 day')
+
+// -d [날짜 지정] 는 보고 날짜를 출력한다. 
+
+if [ "$tommorow" = "01" ]; then
+
+// 이렇게 활용하면 오늘 날짜가 월말일인지 아닌지 알 수 있다.
+
+```
+
+* date를 이용하여 두 날짜의 차이를 구하는 것, 30 days ago 대신 -1 month ago 를 사용해 저번달에 해당하는 날짜를 정확히 고르는것도 가능하다.
+
+
+
+## rsync
+
+* 디렉토리의 내용을 다른 장소와 일치시키는 명령어다. 증분방식으로 작업을 하고 타임스탬프와 소유, 퍼미션을 그대로 유지하고 원격에서도 된다. 정말 유용한 명령어
+
+* `~~v -~~verbose` `~~a -~~archieve` → 메타데이터 동일하게 `~~n -~~dryrun` 테스트용 예행실행
+
+* 명령어를 지정할때 `rsync -av path*log/ /target* `이라 쓰면 log 디렉토리는 복사하지 않고 내용물만 복사한다. 주의~ 디렉토리를 복사하고 싶지 않다면 디렉토리를 지정해라. 
+
+* 원격지에 하고 싶다면 목적지 경로 앞에 `사용자명@호스트명:/TargetPath` 
+
+* 복사만 하고 원본에서 지워진 파일은 지우지를 않는다. 지우고 싶다면 `--delete` 옵션
+
+
+
+## tar
+
+* 로컬에 파일을 압축해서 넘겨주는게 아니라 바로 압축파일을 넘겨주고 싶을때가 생길것이다. (1테라 10테라 짜리를 압축해서 전송한다고 생각해보자 비용이 장난이 아니다) 유연하게 작동하게 만들기 위해 다른 호스트에 파이프라인을 꼽고 파일을 쓰는 방법을 쓰면 된다.
+
+`tar cvfz - myapp*log | ssh {$user}@{server} "cat > /backup*myapplog.tar"`
+
+1. `-` 옵션은 표준출력에 'tar 아카이브'를 출력하도록 한다.
+
+2. 아카이브가 화면에 출력되는건 목적이 아니니까. cat으로 리다이렉트 한다.
+
+3. 파일이 써진다!
+
+반대로 원격의 압축을 로컬에서 풀고 싶다면?
+
+`ssh {$user}@{server} "cat > *backup*myapplog.tar" | tar xvfz - ` 
+
+* `~~-exclude` 옵션을 이용해 원하지 않는 이름, 디렉토리를 제외할 수 있다. 리스트에서 제외하고 싶다면 `~~X`을 사용해 파일을 지정해주면 된다. 
+
+* `tar rvf $archieveFile $targetFile`  -r (append) 를 이용해 기존 아카이브에 파일을 추가할 수 있다.
+
+```diff
++ 아카이브 파일이 없으면 에러 안내고 생성하므로 주의)
+```
+
+
+
+
+## zip
+
+`zip -e -r log.zip log` 
+
+* -e 옵션으로 인해 패스를 묻게된다. `tar.gz` 가 암호를 지원하지 않는다. zip은 윈도우와도 바로 통신이 되니 굳. 암호도 호환된다. 
+
+
+
+## gizp, bzip2
+
+* 용량을 더 확보하고 싶을땐 이런걸 쓴다.
+
+`tar cf - log | gzip -9 -c > archive.tar.gz`   중간 과정을 생략하고 아카이브 + 압축
+
+옵션을 매번 주는게 귀찮으면  `GZIP='-9'; export GZIP`
+
+
+
+## cp
+
+* 그냥 하면 TimeStamp, Permission 이 명령어를 쓰는 유저의 umask 기준으로 바뀐다. 유지하고 싶다면 `-a` 옵션을 주면 된다.
+
+* `~~R -~~recursive` `~~p -~~preserve` 파일속성유지
+
+* `-L link` 심볼링 링크를 실제로 복사하고 싶을때
+
+	* 메타데이터를 유지하고 싶어도 유지못할땐 사용자의 정보로 대체된다. (root파일을 일반유저가 복사했다면)
+
+
+
+## umask
+
+* umask 값은 계정마다 설정할 수 있으며, root의 umask는 *etc*profile에서 설정
+
+* 권한은 초기 값은 파일은 666, 디렉토리는 777인데 `umask`를 빼면 실제 파일의 기본값이 된다. umask가 0002 라면 파일은 664 그룹외 리드,  디렉토리는 775 그룹외 리드 및 실행 
+
+
+
+## comm
+
+* diff 같이 파일을 비교하고 싶을때 사용
+
+* 1열에 출력되면 첫번째 파일, 2열은 두번쨰 파일, 3열은 같을때 출력된다.
+
+
+
+## du
+
+`du ~~sm ${data~~dir}/*/ | sort -rn`
+
+* mega kilo 단위로 하면 솔트가 가능하다. h 옵션은 솔트가 안됨
+
+**`-s` 서브디렉토리를 어디까지 보는지 지정한다. `/**/` 했으니 아랫쪽에   
+
+
+
+## sort
+
+`-r` 사용량이 많은것부터 정렬한다.
+
+`-n` 숫자로 문자열 정렬
+
+
+
+## strings
+
+* 스크립트 언어로 작성된 에러메시지는 바로 grep 이 가능하지만 컴파일된 바이너리는 검색이 불가능하다. 이때 strings를 사용한다. 파일에서 문자열을 출력하는 명령어를 찾아낼 수 있다. 
+
+`strings -ff *home/user1/myapp/bin** | grep "$message"`
+
+* `-f` 결과값을 출력할때 파일명도 같이 출력
+
+
+
+## od hexdump
+
+* od는 아스키 문자열로 바꿔서 바로 보여주고
+
+* hexdump는 헥사값만 보여주는데 `-c`로 아스키 문자열도 볼 수 있게 할 수도 있다.
+
+* 프로그램이 동적으로 에러 메시지를 출력할때는 바이너리 파일을 찾을 수 없다.  
+
+
+
+
+
+## 이중실행을 염두한 파일네이밍
+
+`tmpfile="tmp.$$"`
+
+이렇게 매번 실행할때 마다 자기만의 파일을 가지고
+
+sleep 하고 rm -f $tmpfile 하면 된다.
+
+`mktemp` 명령어가 이걸 하기 위해 만들어진 명령어
+
+
+
+## sed
+
+* 심볼릭 링크를 수정할때를 대비해서 옵션이 있음. 그래서 심볼릭링크를 쫒아가서 작업을 할거냐 그냥 안할거냐 구분이 가능 (그런데 이걸 어디에 쓰나)
+
+
+
+## 유닉스타임에 대해
+
+* unix time이라 부르는거 정식으로는 epoch라고 부른다.
+
+* 정수기 때문에 빼고 초로 나누면 날짜의 차이를 구할 수 있다.
+
+`day1_epoch=date -d "$day1" '+%s'`  일반적으로 쓰는 시간에서 epoch를 뽑아내는 방법
+
+
+---
+
+# 네트워크
+
+## route
+
+`Gateway=$(route -n | awk '$1 == "0.0.0.0" {print $2})'`
+
+* `-n`은 호스트네임 대신 IP를 쓰도록 한다.  
+
+* 컬럼 0.0.0.0의 두번째 칼럼을 추출하는 명령어
+
+* 이렇게 뽑아낸 게이트웨이에 `ping -c`을 보내고 $? 으로 반환값을 검사하면 된다.
+
+	* `-c [numb]` 에 인자값을 안주면 딱 한번만 보내게 한다. (중요함. 쉘 무한실행 방지)
+
+## arp
+
+`arp -an | awk “*\($target_ip\)* {print \$4}”)` → 지정한 ip에 대해 MAC을 얻는다. 이제 타겟 IP, MAC 을 echo로 출력하면 깔끔하게 맥을 얻는 명령어 마냥 동작한다. arp -an | grep ip 로 해도 비슷할듯.
+
+## host
+
+* 입력한 호스트이름에 대해 DNS반환하는 IP 주소를 모두 보여준다. 하나의 도메인에 대해 여러 서버가 서비스하는 경우가 많다보니 그걸 고려한 명령어. (DNS에 질의 하는 명령어 이므로 `*etc*host` 파일의 내용을 무시하는 점을 주의)
+
+```
+
+host ($target_host) | \ 
+
+awk '/has address/ {print $NF, “IPv4”} \
+
+/has IPv6 address/ {print $NF, “IPv4”}’
+
+```
+
+* $NF 는 마지막 칼럼을 참조한다.  Result: 한 호스트 네임을 서비스하는 모든 IP를 출력한다.
+
+* IP를 입력하면 호스트 네임을 반환한다. 따라서 IP 리스트가 담긴 파일을 넘겨주고 호스트네임을 달아주는 작업도 가능하다. 
+
+* `[리스트] | revlookup.sh` 
+
+```revlookup.sh
+
+while read ipadd
+
+  revlookup=$(host "$ipadd")
+
+  if [ -$? -eq 0 ]; then
+
+    echo "$revlookup" | awk '{print $NF}' | sed 's/\.$//'
+
+// \.$ 온점을 캐치하는 패턴이다. host 마지막 컬럼에 . 이 있는걸 제거하기 위해 사용
+
+```
+
+
+
+## nc
+
+* 서버의 개방 포트 점검 스크립트
+
+점검할 Port 리스트를 준비해놓고 
+
+`while port in 80 2777 3000`
+
+`nc -w 5 -z $ipaddr $port` 이렇게 처리하면 포트의 개방 체크
+
+`~~w` 는 응답없음에 대해 타임아웃 `~~z`은 핸드쉐이크만 하고 실제 통신을 하지 않는 옵션이다.
+
+* 간이 TCP 서비스 열어서 서비스가 동작을 흉내내기
+
+`nc -v -k -l $PORT`
+
+`—~~verbose`, `~~k`는 상태를 계속 유지하겠다는 플래그 `-l`은 듣기 플래그
+
+
+
+## FTP
+
+* ftp 동작을 스크립트로 하기. `ftp -n $server” << _***EOT******` 가 핵심. 히어 도큐먼트로 `user "$user" "$passwd"`  `binary` `get "$file"` 등등 쓰고 싶은 명령어를 쭉쭉쓰다가 `******EOT***_`를 해주면 된다. 
+
+* 이런 시크릿을 담은 스크립트는 700 권한으로 관리한다.
+
+
+
+## 통신연결 성능 테스트
+
+* `wget “ftp:*/<user>:<pw>@<host>*<path>”`
+
+* `curl -u “<user>:<pw> -0 “ftp:*/<host>*<path>”` 
+
+* `time -p ftp -n <server>` 를 이용해 시간을 측정하고 `expr` 명령어로 계산하는 방법도 있지만 wget, curl 에는 전송결과를 요약해주는 기능이 있어서 활용하면 좋다.
+
+
+
+## ssh
+
+* 원격에 로컬 스크립트를 실행시키기
+
+```
+
+cat $scirpt | ssh ${username}@${ipAdd} "sh"
+
+//...(반복), 또는 while로 처리할 수도 있겠지
+
+```
+
+* 위와 같은 실행방법은 비인터렉티브 셸이다. 
+
+
+
+
+---
+
+# 문자열처리
+
+## rev (reverse)
+
+리스트를 끝 문자로 정렬한다. 
+
+## env
+
+* 환경 변수를 키=밸류 형식으로 출력한다.
+
+`env | cut -f 1 -d "=" > env.lst`
+
+구분자를 ‘=‘으로 지정해 구부낳고 `-f`는 추출할 칼럼의 번호를 지정하기 위해 사용된다. 
+
+`grep -q “^${env_name}$”  env.lst` 의 ExitCode 를 검사해서 리스트를 검사한다. 환경변수가 똑바로 있다면 원하는 작업을 실행하도록 스크립트를 짜면된다.
+
+## head ←→ tail
+
+* `head -n 1 “$1”` 을 이용해 첫줄을 읽고 `case $headline in` 을 이용하여 분기하여 작업한다. 
+
+* 확장자가 없는 파일을 읽어서 확장자를 붙이는 작업을 셔벙(Shebang)이라고 한다.  굳이 이렇게 분기를 하지 않고 `file`명령어를 사용해 구분하는 방법도 있다.
+
+
+
+## md5sum
+
+* `echo -n “$line | md5sum | awk ‘{print $1}’ >> $tmpFile`
+
+해시값을 만들고 그중에 첫번째 컬럼 값을 저장하는 스크립트
+
+
+
+## paste
+
+* 두개의 텍스트 파일을 횡으로 연결하는 명령어, `-d` 옵션은 CSV 로 저장하도록 한다. (디폴트는 tab구분자)
+
+## cut
+
+* while 로 라인을 돌면서 `cut -f 1 ~~d ','`   `~~f 2`  `-f 3`  이렇게 하면 CSV를 간단하게 다룰 수 있다.
+
+	* 다만 구분자가 값으로 들어올 수 있는 경우라면 사용할 수 없다. 
+
+## while
+
+* CSV를 다룰때 자주 쓰는 패턴
+
+```
+
+while IFS=, data1 data2 data3
+
+do
+
+  ...(중략)
+
+fi
+
+done < "$csvfile
+
+```
+
+
+
+## awk
+
+```
+
+awk -F, ‘{sum += $3} END {print sum / NR}’ "$1" > ${filename}.avg
+
+```
+
+* `-F` 옵션(구분자)는 바로 이렇게 넣어도 되고 쉼표로 입력해도 된다.
+
+* `{code that exec each line} END {code that exec at last}` 표현이 awk출력을 좌우하게 된다. 
+
+* Useful code snippet - 최고 높은 값 기준 추출하기
+
+`max=$(awk -F, ‘{print $3}’ “$csvfile” | sort -nr | head -n 1)`
+
+like this, CALC max point
+
+`markprint $(expr $GRAPH_WIDTH \* $score/$max)`
+
+Deginate numb of * by func arg as 
+
+```markprint
+
+  do
+
+    echo -n "*" // -n 옵션은 개행을 하지 않는다.
+
+    i=$(expr $i +1)
+
+  done
+
+```
+
+
+
+* Useful Code Snippet - 컬럼 위치를 바꾸기
+
+`awk '{print $4, $5, $1}' "$1" > "{1}.lst"`
+
+	* 	$1 : target list
+
+	* {$1} : first Column in CSVps 
+
+
+
+* Useful Code Snippet - 특정 값만 취득하기
+
+`awk '$(NF-1)=404 {print $7}' "$logfile" > "{logfile}.404"` 
+
+	**{ } -> 액션,**액션값 앞에는 조건식이 올 수 있다.*
+
+
+
+
+
+* grep -v , except grep like vgrep
+
+* grep -c 라인당 해당 패턴을 한번씩 카운트, 못찾으면 1반환
+
+* [ -n ] null 이 아니면 참 
+
+
+
+## unique
+
+`sort | unique -c | sort -nr`
+
+`asd`
+
+
+---
+
+
+---
+
+
+---
+
+
+---
+
+
+---
+
+
+---
+
+
+---
+
+
+
+# 외전 
+
+## MYSQL
+
+`SELECT id FROM user info ORDER BY substring(id, -1, 1);`
+
+* 마지막 글자를 자르는 함수
+
+
+
+
+
+#Devops*language*bash
+
diff --git "a/Bear/\360\237\220\215Python lang.md" "b/Bear/\360\237\220\215Python lang.md"
new file mode 100644
index 0000000..3c3ae39
--- /dev/null
+++ "b/Bear/\360\237\220\215Python lang.md"	
@@ -0,0 +1,67 @@
+# 🐍Python lang
+
+## pyenv global 3.10.1
+
+* 가상환경을 이동하면서 디펜던시 관리가능해짐
+
+* pyenv로 설치할것!
+
+* `pyenv versions` 현재 관리중인 버전들 확인
+
+
+
+## Django Install
+
+```
+
+python -m pip install Django
+
+python -m pip install rest_framework
+
+```
+
+
+
+## @ 데코레이션
+
+* 함수를 인자로 받아 클로져처럼 동작하게 만든다. 사용자가 정의해서 사용할 수도 있다.
+
+* 함수 성능측정 같은데 쓰면 좋지 `@perf_test`
+
+
+
+## subprocesscall
+
+`subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False, timeout=None)`
+
+* args -> [] 명령행에 문자열 혹은 입력될 인자들을 공백으로 자른 결과를 넣는다. eg. If u want use next command `rsync -l ~~a`  then insert  `['rsync', ‘~~l’, '-a’]` args
+
+
+
+## a
+
+`rsync [File Name] [User]@[IP Address]:[Path]`
+
+
+
+## argparse
+
+* like SHELL getups, it provide API that controlling args.
+
+* 
+
+## 파일 시스템 순회
+
+```python
+
+for (root, dirnames, filenames) in os.walk(export_path):
+
+```
+
+
+
+
+---
+
+#Devops*language*python
+
diff --git "a/Bear/\360\237\220\266CS - INFRA basic.md" "b/Bear/\360\237\220\266CS - INFRA basic.md"
new file mode 100644
index 0000000..620e360
--- /dev/null
+++ "b/Bear/\360\237\220\266CS - INFRA basic.md"	
@@ -0,0 +1,87 @@
+# 🐶CS / INFRA basic
+
+
+
+무덤 - ~~로드밸런스의 종류와 차이~~
+
+——— 문제 ———
+
+0. 프로세스가 뭐야?
+
+0. 쓰레드의 동시성과 병렬 프로그래밍이 뭐야?
+
+0. 소켓이 뭐야?
+
+0. POSIX가 뭐야?
+
+0. 가상화 상식
+
+0. 컨테이너가 뭐야?
+
+0. HTTP/HTTPS 차이 점이 뭐야
+
+0. TLS
+
+0. SSH 운영방법
+
+0. Port Forwarding 원리 및 과정
+
+0. 포워드 프록시
+
+0. 리버스 프록시
+
+0. 캐시서버를 어떻게 쓰나요?
+
+0. 빌드를 하면 구체적으로 어떤 일이 벌어지나요? (다시)
+
+0. mutex 문제의 뜻
+
+0. semaphore 문제의 뜻
+
+0. PaaS, SaaS 차이 IaaS
+
+
+
+——— 답. ———
+
+
+
+1. 메모리에 적체되어 실행되고 있는 프로그램. new - ready - ruinning - waiting - terminated- suspend - pause state 상태값을 가진다.  ready는 CPU를 얻기위해 대기, time quantum 동안 running 그리고 다시 ready, CTRL-Z 로 발생하는 pause, 실행할 수 없는 상태일때 보류하는 suspend 
+
+2. 프로세스 안에 복수의 쓰레드를 운영하면 하나의 프로세스가 마치 두개의 프로세스처럼 동작하게 되는데 이를 동시성이라 한다. 병렬 프로그래밍은 데이터 병렬성과 작업 병렬성으로 나타난다. 데이터 병렬은 작업을 서브데이터로 쪼개어 빨리 진행하는것을 작업병렬은 서로 다른 작업을 동시에 진행하는 것을 말한다.
+
+3. 통신을 위해 OS가 제공하는 SW 인터페이스, 이것을 통해 서로 다른 OS와 통신을 할 수 있으므로 전기에서 비슷한 역할을 하는 소켓이라 이름지어졌다.
+
+4. 유닉스 간 공통된 API를 정의하여 이식성 높은 유닉스를 만들기 위해 만든 portable Operating system Interface  표준. POSIX 표준을 따르는 프로그래밍 언어나 OS에는 stdin stdout stderr 라 불리우는 프로그램과 실행환경에서 약속된 통신방법을 제공하고 이를 표준스트림이라 한다.
+
+5. A. 전가상화(Full Virtualization) = ‘하이퍼바이저’를 사용한다. 여러 종류의 OS를 사용가능하지만 성능에 불리. 
+
+B. 반가상화(Para~~Virtualization, Native~~V) 게스트 서버간 독립성 없이 상호 작용한다. 물리서버 위에 하이퍼바이저가 직접 설치. 운영체제 수준 가상화(Operating system level V) 커널에서 이루어진다. OOTB(Out of the box) 비용 절감을 통해 높은 성능 구현. 게스트는 완전히 격리되어 할당된 자원만 사용.
+
+6. 가상머신이 없고 게스트 OS도 없다. 호스트 입장에서 보면 하나의 프로세스 취급. 소프트웨어를 다른 컴퓨팅 환경으로 옮겨도 안정적으로 실행하기 위해 만들어진 기술. 리눅스이기만 하면 실행가능함.
+
+7. 문서교환시스템. SSH는 이 과정에 공개키와 대칭키를 교환하고 문서를 암호화하는 과정이 추가되는데. 이 키들을 Certification Authority 서비들이 제공하고 브라우저는 이를 신뢰함으로서 웹의 신뢰를 도모한다. 오늘날엔 http와 성능차도 거의 없어졌다.
+
+8. 상호 통신을 신뢰하기 위한 CA 네트워크망과 비대칭키 교환 프로토콜로 구성된 보안체계. openssl로 키를 발급해보자.
+
+9. 키 생성 > 상대 서버에 공개키 전송 > 쉘에 .공개키 등록
+
+10. 내부 노드에 접근을 프론트라인에서 컨트롤해주는 서비스. 외부에서 내부 구조를 알 수 없게 하고 유효한 통신을 엄격하게 컨트롤하는 점에서 보안을 확보.
+
+11. 조직내의 요청을 서버가 대신하여 외부에 요청하고 응답을 돌려주는 서비스. 외부에서 보기에 정체를 알수없고 내부의 요청을 컨트롤할 수 있고 캐시역할을 통해 네트워크 비용을 절감한다.
+
+12. 기본적으로 로드밸런싱의 역할을 한다. 그리고 내부서비스를 알 수 없게 하고 캐시 데이터를 저장함으로서 성능을 확보한다. 마지막으로 암호화 복호화하는 비용을 리버스 프록시 서버가 전담함으로서 서버의 부담을 줄인다.
+
+13. 요청 URL 기준으로 캐시확인 없으면 MISS (WAS에 요청) 디스크에 저장 > 이제부터 HIT > nignx.conf , conf.d/hostname.conf 프록시 경로, 포맷, 파일크기, expire 설정 후 restart 이제 http 요청에 x~~proxy~~cache 값의 변화를 확인할 수 있다.
+
+14. 프리프로세싱(패키지처리)~~컴파일(저수준)-어쎔블링(기계어)~~링킹(실행파일로)
+
+15. 두쓰레드간 동기적 작업을 보장할 필요가 있는경우 값을 참조 변경하지 못하도록 처리할 필요가 있다. 이때 mutex를 걸고 해체하는 방법을 말한다. 
+
+16. 세마포어는 한정된 숫자에게만 지원할 수 있는 자원을 컨트롤하는 방법이다. 각 언어마다 이 세마포어를 컨트롤 할 방법을 제공한다. 
+
+17. PaaS (구글 앱엔진, AWS 람다). 처럼 인프라부터 실행환경까지 전부 구성해주고 사용자는 어플리케이션 로직만 짜면 되는 서비스, SaaS는 어플리케이션을 통째로 제공한다. 그게 RDBMS면 RDS, MQ면 AMQP, 그냥 가상화된 서버만 빌리면 IaaS
+
+
+
+#Devops/OS
\ No newline at end of file
diff --git "a/Bear/\360\237\221\237Go.md" "b/Bear/\360\237\221\237Go.md"
new file mode 100644
index 0000000..4852ed8
--- /dev/null
+++ "b/Bear/\360\237\221\237Go.md"
@@ -0,0 +1,327 @@
+# 👟Go
+
+#Devops*language*go
+
+## Golang 특징
+
+* Communicating Sequential Processes
+
+	* Go의 Concurrent 컴포넌트
+
+	* 채널을 통해 메시지 교환
+
+	* 실행순서
+
+		* 루틴을 시작하더라도 메인루틴이 끝까지가고 끝이 나면 서브루틴들이 메모리를 참고하여 작업을 시작한다.
+
+* 상속이 불가능하다. 대신 embedding 을 사용해 조합, 재사용가능한 구조를 짠다. 굳이 거창한 키워드를 안쓰고 상속을 한다.
+
+* 중앙관리식 패키지관리를 사용하지 않고 실행할때 통신하여 가져온다. 
+
+
+
+## 프로젝트 파일 및 패키지
+
+* 프로젝트
+
+	* bin: 컴파일된 실행파일(바이너리)가 생성되는 DIR
+
+	* pkg: 패키지를 컴파일한 라이브러리 파일이 생성되는 DIR {운영체제}_{아키텍쳐}
+
+	* src: 작성한 소스 파일과 인터넷에서 다운로드한 소스 파일이 저장
+
+*  import를 하면 src를 기준으로 상대경로 찾아본다. 
+
+	* `GOROOT*src/, GOPATH/src*, [C.W.P]*src* `
+
+* Package
+
+	* GOROOT, GOPATH, STD 패키지, 3rd P 패키지, Identifier (대문자/소문자)
+
+
+
+
+
+## 타입
+
+* Back Quote ``  → Raw String Literal	
+
+* Interpreted String Literal `“ ”`  개행 및 + 사용해서 표현
+
+* Type Conversion 가능
+
+* Uint	+ 정수 (x2 +1 길이)
+
+* Array - 배열의 타입은 밸류다.
+
+
+
+## 배열
+
+* 배열을 슬라이스 [1:5] 처럼 표현하면 처음 인덱스는 Inclusive 이며, 마지막인덱스는 Exclusive이다 (주: Python과 동일).
+
+* 슬라이스 타입: 동적으로 커지는 배열
+
+var a = []int
+
+a = []int{1,2,3}
+
+
+
+## 반복문
+
+* goto, continue (나머지 실행안하고 다음 실행), break 반복 종료
+
+* Label ( L1:) 을 통해 break L1 처럼 실행순서를 컨트롤 할 수 있다. (C++ 에서 봤던거네)
+
+
+
+## pass by value, pass by reference, 
+
+* Valiadic function ( 인자를 가변적으로 받을 수 있는 함수)
+
+**`**string` 처럼 레퍼런스 변수를 함수에서 인자로 정의할 수 있다. 그리고 사용할때는 `Test_func(*msg msg)`  처럼 표시를 해서 포인터가 가리키는 값을 바꿀 수 있다. 이걸 dereferencing(역참조)라고 한다.
+
+
+
+## 타입 (2)
+
+* type문을 사용한 함수 원형 정의
+
+	* 원형을 정의하고 타 메서드에 전달하고 리턴받는걸 Delegate 라 한다.
+
+* ***Zero base array, 배열크기가 다르면 다른 타입으로 취급***
+
+* 컬렉션 
+
+	* slice (it did not specify lenth, capacity), NIL(nothing), 내부적으로 보면 처음엔 사이즈가 0인데 증설할때마다 새로운 array를 생성하고 복사를 한다.
+
+	* MAP 
+
+	make() NIL 변수를 초기화해서 포인터 반환, 
+
+		* key 가 존재하지 않으면 NIL, 또는 제로 반환 (레퍼런스/ 밸류)
+
+* Golang 자료형 타입
+
+1. **Value Type**
+
+	* Stack 안에 실제 데이터가 있다.
+
+	* struct int
+
+2. **Reference Type**
+
+	* Stack (주소) → Heap (실제 데이터)
+
+	* Map Slice string
+
+
+
+## STRUCT
+
+* `person, Person` 의 차이? → Public
+
+* auto deference. 
+
+	* 스트럭처 포인터라도 그냥 변수처럼 쓴다.  ***arg로 넘기면 call by value가 된다. call by ref 를 원하면 포인터로 명시해서 넘긴다.***
+
+* 생성자 정의 함수를 구성해서 사용( ≈ js's CONSTRUCTOR)
+
+* struct 의 receiver
+
+	* Value 로 STR 을 받을지 Pointer로 받을지 메서드에서 정의하는대로 가능
+
+	* (와.. 마음대로 정의할 수 있는게 짱이네, js 지옥 끝)
+
+
+
+## interface
+
+	****필드의 집합 구조체, 메서드의 집합 인터페이스*
+
+	* `interface type = empty` 
+
+	* `interface = dynamic type = java object` 와 비슷..
+
+	* Type Assertion .  a.(int) 같은 패턴을 통해 a를 검증하는 확인(assert) 여기서 a가 int가 아니면 런타임에러
+
+* Error
+
+	* interface를 구현하여 case 문법으로 에러를 처리가능 (유용한 내용이다 추천)
+
+* 에러처리
+
+	* defer: 마지막에 실행(ex: clean up)
+
+	* panic(): defer만 실행하고 콜스택 타면서 종료 후 에러
+
+	* recover()
+
+
+
+## 루틴 (go routine)
+
+	* 논리적 스레드 ( 1개의 OS 쓰레드는 여러개 고루틴 처리가능)
+
+	* 익명함수에 사용
+
+	* 기본적인 이 go는 동시성처리
+
+	* 하지만 rollingUpdatentime. 으로 Parallel(병렬)도 지원.
+
+
+
+### 채널
+
+	* 송신자와 수신자가 존재하도록 구성
+
+	**수신이 될때까지 기다리는**언버퍼 채널**, 버퍼에 저장하고 바로 일하러 가는**버퍼채*널
+
+	* 함수의 파라미터로 쓸때 송신 채널인지 수신 채널로 쓸건지 정하고 그대로 써야함
+
+	* ***채널을 닫아도 송신은 된다. 새로운 메시지를 거부하는거지 송신은 된다고 생각해***
+
+	* `for` 와 `select` 로 각 채널의 송신에 대한 이벤트를 계속 제어할 수 있다 . 송신 채널이 없는데 default 가 있으면 그걸 무한으로 하게 된다
+
+
+
+### 패키지
+
+* go mod init {pack_name}
+
+	* GOPATH 밖에 있어도 알 수 있게 컨트롤 해줌.
+
+	* mod 파일은 모듈의 루트에만 존재
+
+	* mod 실행시 현존 모든 경로의 DIR을 정리해 임포트(mod 명세 파일을 만든다) (디렉토리만든다고 또 실행할 필요없다.)
+
+	* `tidy`        add missing and remove unused modules
+
+
+
+```
+
+mod init 하기전 테스트
+
+ok      _/Users/kth/Code/Go_1_package_test      0.244s
+
+mod init 후
+
+ok      github.com/lecture      0.352s
+
+```
+
+* go 커맨드는 sum 파일로 섬체크를 한다. (악의적 변경 우발적 변경을 방지)
+
+* go.mod 파일
+
+	* (여기서 indirect 표시는, 직접적으로 이 패키지를 사용하지 않는다는 표시이다)
+
+
+
+## Go 관리 명령어
+
+```
+
+go list -m -versions  [rsc.io/sampler](http://rsc.io/sampler) 
+
+	버전출력
+
+go get  [rsc.io/sampler@v1.3.1](http://rsc.io/sampler@v1.3.1) 
+
+go get rsc.io/quote/v4
+
+go list -m rsc.io/q...
+
+```
+
+* 고는 시맨틱 임포트 버저닝을 한다
+
+* 시멘틱 버전, 1.2.3. 순으로 메이저, 마이너, 패치를 의미한다.
+
+	* 호환되지 않는 패키지 (주요 버전이 다른 패키지)에 다른 이름을 부여합니다.
+
+	* 메이저 단위로 같은 모듈이라도 다른 경로를 쓴단거!
+
+* 같은 메이저 안에서 빌드를 두번할 순 없다.
+
+* 지원하는 함수 확인..
+
+	`go doc  [rsc.io*quote/v3](http://rsc.io/quote*v3) `
+
+* list, tidy
+
+```
+
+go list -m all
+
+ 현재 프로젝트에서 사용하는 의존성 전부 확인
+
+go mod tidy
+
+	사용하지않는 deployment pack 제거
+
+```
+
+
+
+* main 은 인자가 없지만 실행시 os 라이브러리로 주고 받을 수 있음.
+
+* 전통적인 커맨드라인 인자말고도 ‘-f=test.csv’와 같은 플래그도 받을 수 있다. 와 이거 좋다.. 일단 고 실행환경만 갖춰 놓으면 어디서든 유연하게 쓸 수 있겠다. 매번 os 환경변수 라이브러리로 호출하는 것도 일인데 바로바로 동작한다니
+
+* list 는 타입에서 자유롭다. interface 의 후손
+
+
+
+## Castring(convert)
+
+* 형변환해야할때 아구가 안맞으면 에러
+
+* 데이터를 깨지 않는선에서 형변화가 가능. 다르게 할려면 
+
+
+
+type 정의의 형식은 정해져있다
+
+```
+
+type [name] struct {}
+
+type [name] func() {}
+
+type [name] interface {}
+
+```
+
+
+
+* IMPORT 기능 연구
+
+```
+
+import [nick] [path]
+
+import (“lib”;”lib2”) 이렇게 가능
+
+```
+
+
+
+import(
+
+“GIN~~FIRST~~PROJECT*src*dataRepo"
+
+이렇게 모듈 + root로부터 상대경로 이렇게 임포트하고
+
+
+
+사용할때는 
+
+
+
+* 고랭으로 프로그램 짤때 쓸 수 있는 SOLID 원칙(DIP)
+
+	* 모듈 > 추상체 > 구현체 순으로 코드의 커버리지가 크다. 이때 상위 개념은 하위개념을 호출하면 안된다. 하위가 상위의 인터페이스를 구현해야한다.
+
+	* 이 말은 Deploymentendency Inversion PrinClusterIPle (의존성 역전원칙)으로서 많은 객체지향언에서 지향하는 원칙이다.
\ No newline at end of file
diff --git "a/Bear/\360\237\222\245\353\254\270\354\236\245\354\235\230 2\354\260\250 \354\240\200\353\245\230\354\247\200.md" "b/Bear/\360\237\222\245\353\254\270\354\236\245\354\235\230 2\354\260\250 \354\240\200\353\245\230\354\247\200.md"
new file mode 100644
index 0000000..9b69b61
--- /dev/null
+++ "b/Bear/\360\237\222\245\353\254\270\354\236\245\354\235\230 2\354\260\250 \354\240\200\353\245\230\354\247\200.md"	
@@ -0,0 +1,42 @@
+# 💥문장의 2차 저류지
+
+**저류지를 통해 새겨듣고 기억할 말을 기록하는 노트입니다.**
+
+1. 희망은 만드는 것이다. 희망은 선택하는 것이다. 믿는 대로 살게 된다.
+
+2. 미래를 바꾸기 위해선 못생기고 지저분한 현재를 인정하고 개선의 꿈을 품고 견뎌내는 시간이 필요하다. 평생을 견딜 수는 없게지만 성과를 낼때까지는 인내해야한다.
+
+3. 엄격하게 개념을 말을 정의하고 논리를 쌓아 올려서 그 안에서 사고해야 헤매지 않는다. 모호하게 생각하는건 죄다.
+
+4. 사람은 잘 지내고 있을때는 '왜?'라고 질문하지 않는다 힘들 때 왜를 생각한다. 그렇기 때문에 '왜?' 라는 질문은 무용 할 수도 있다. 힘든을 수용하고 쉬고 개선할 방법을 찾을 시기란 것이다.
+
+5. 탐험. 인간의 뇌는 타고난 탐험가들이다. 관찰 가설 실험 결론. 과정을 통해 세계를 배워나간다. 이 모델을 우리 인생 전체에 적용해나가야 한다. 이건 성공한 사람들의 수사가 아니라, 우리 모두의 삶 전체에 필요한 덕목. 선천적 후천적인것을 우리는 구분할 수 없다. 계속해서 부딪치고 나아가라.
+
+6. 사람의 많은 부분은 환경으로 결정된다. 노는공간과 쉬는 공간을 충분히 단절시켜놔야한다.  시간, 장소 ,사람을 컨트롤 하는게 최고의 방법이다.
+
+7. 생명보험회사가 좋아할만한 짓을 하지 말자.
+
+8. 셀프, 트러스트는 신념을 뜻한다. 신념이 없으면 무너진다. 그러나 신념에 너무 얽매이면 부러진다.
+
+9. 스스로 하는 짓에 의미를 부여하는게 정말 정말 정말 중요하다.
+
+10. 스스로 믿는 것과 행동하는 것을 일치시켜야 한다.
+
+11. 문제를 회피하는 쪽으로 마음먹으면 organize되는건 도피처. 현실은 방치.
+
+12. 흥미롭지 않아 보였던 산에 길을 만드는 남자
+
+13. 축적의 시간이 미래다, 천재는 잊어라"
+
+14. 노예의 태도 주인의 마음을 알려하지 않고 두려워하기에 일함. 주인은 주인은 주인의 마음을 알려한다 스스로 일한다. 세상을 지배하려고 한다. 세상을 피하려고 하지 않는다.
+
+15. 보고 또 보아야 애정이 생긴다. 영원한 것은 관념 뿐이며 불안과 한계가 가득한 유한한 현실이 유일하게 평생을 바칠수 있는 인생의 놀이터
+
+16. 하늘 아래 새로운게 없다. 새로운걸 찾기보다 이미 알고 있고 것들에서 꾸준함과 인내를 통해 감동을 끌어내는게 살아가야 할길
+
+17. 고상하고 싶은 마음만 남아선 안된다. 넌 지금은 왕자가 아니야. 왕자가 되려면 인정받을때까지 박치기하고 떄론 피가 흘러야해. 싸움터에서 인정받아야 왕국의 전통을 이을 수 있는 자격이 주어진다.
+
+
+---
+
+#living/sentence
\ No newline at end of file
diff --git "a/Bear/\360\237\222\263FinanceMainline.md" "b/Bear/\360\237\222\263FinanceMainline.md"
new file mode 100644
index 0000000..193d2cb
--- /dev/null
+++ "b/Bear/\360\237\222\263FinanceMainline.md"
@@ -0,0 +1,114 @@
+# 💳FinanceMainline 
+
+#Business&Finance 
+
+
+---
+
+## 자산의 가격
+
+: 자산의 가격은 시장이 정한 합리적 가격이 아니다. 누군가는 경영권을 위해 자산을 사고 누군가는 변동성의 리스크를  가짐으로서 수익을 얻기위해 산다. 고로 가격은 저평가 고평가 될 수도 있다.
+
+## 전략에 대한 조언 LIST
+
+1. 하락장, 보합이 예상되면 동적자산배분으로 가고 상승장이 예상되면 자산배분으로 가고
+
+2. 금리가 인상되면 기존 채권은 할인된다. (이자를 더 못받으니)
+
+장기채를 찾는 사람이 적어진다.(호황) 이자 금리가 올라간다.
+
+장기채를 찾는 사람이 많아진다.(불황) 이자 금리가 떨어진다.  채권가격은 올라간다.	 
+
+3. 프리마켓 18:00 (제일 빠른 증권사) ~ 11:30 
+
+4. 경제 안정기 도입 > `성장주, ETF` 모멘텀 
+
+경제 불안성 증가 불황예상 > `현금화, equity, 리버스, 선물 ` 모멘텀 
+
+경제 불안성과 안정기 과도기 > `배당주, 가치주` 모멘텀
+
+## 대전환 유튜브 감상
+
+* 피터틸 이야기를 해서 이책을 추천하셨나 시장경제에 대해 생각을 다시해보기위해. 토리파가 주도한 침니액트가 있었음에도 철의여인은 사회가 없다고 말했단건가.. 정말 명쾌한 이론이다. 상품이 견인하는 사회해체. 사회해체에 대항하기 위한 사회라는 실체의 전환. 고전적 자유주의로 흘러가는 운명밖에 없다고 생각했는데. 어쩌면 이 세계는 희망이 있을지도 모른다
+
+## 공포에 대한 생각
+
+공포의 얼굴이 똑같이 오면 가격은 떨어지지 않는다.
+
+얼굴이 따르게 올때 공포라 느끼고 실제 가격이 떨어진다.
+
+그래서 공포에 사는게 힘들다.
+
+## 180. 대하락장에서 나 혼자 버는 방법 
+
+1. 절대 모멘텀으로 리버스(1, 3모멘텀 사용)
+
+2. 금은 대하락장에 수익 굳. 일반장에 안좋음 (장기보유만 안하면 되겠다)
+
+## 장단기 금리가 역전하면 주식시장에 벌어지는 일
+
+*  10년채에서 금리가 올라간다는건 장기적으로 경제가 좋아 금리가 올라갈거란 기대가 있는것이다. 
+
+* 경제침체가 예상된다. →  채권 사려는 사람이 많다 →  채권가격이 올라간다 → 금리가 떨어진다. 
+
+* 금리가 인하되면 과거에 발행된 채권들에겐 호재 (금리 인하로 인해 가격 상승)
+
+* 금리가 인상되면 과거에 발행된 채권들에겐 악
+
+* 반면 단기채권은 물가에 연동되서 이율이 오르고 내린다.
+
+* 2년 채권이 10년 채권 보다 이익이 높다는건 물가도 오를거고 경기도 안좋을것이다. 
+
+* 18년도 9월에 역전 됐다가 코로나 양적완화로 미뤄졌던 금리조슈카식 설명. 10년 20년 채권은 금리를 빨리 올리면 역전이 일어나거나 장기채사는 사람들이 많압지면 (경제가 망할것 같아서) 사기 시작한다. (경제가 어려워지면 금리가 떨어지고 들고 있는 채권가치가 올라간다)
+
+## 7월 2일 시장분석
+
+* 10년 미국채와 QQQ가 상관관계도가 높게 나타나다가 그 추세가 꺽였다. 20년권은 여전히 떨어지고 있다. 
+
+eq가 꺽이자 채권을 사려는 사람이 많아졌다. → 가격상승에 따라 TTT 하락
+
+## 시장의 바닥?
+
+나쁜 소식에 반응하지 않을때 하지만 이건 예상한 나쁜 소식일때. 모두가 불활을 예측할때 입을 다물고 있던 연준의장이 인정할때. 이걸 호재라고 생각하고 베어마켓 패턴이 시작됐지만 이번에도 꼴아박았다.
+
+## 인더스트리 
+
+반도체는 경기에 민감하다. 마이크론, 테슬라 같은 성장주가 나스닥을 좌우한다.
+
+하락장에도 올라갈 종목은 올라간다.
+
+# 템플턴
+
+알았으면 제발 그대로 기계적으로 해라 감정에 휩쓸리지 말고 
+
+# 인플레가 잡힌다.
+
+침체가 올수도 있고 인플레를 종언하고 롱이 올수도 있다.
+
+# 관세를 매기는건
+
+* 자국의 물건을 비싸게 사라는 거다. -> 즉 비싼만큼 자국 물건에 보조금을 대주는건데 그 재원이 국민의 가처분 소득이다. 가처분 소득을 빼앗는건 자본축적을 방해한다는 뜻이고 손안대고 재산을 강탈하고 정부 관료들의 주판에 따라 자본을 이전시키는 행위. 자동차 업계가 혜택을 보고 우리는 비싼쌀을 먹음으로서 한국 농업에 보조금을 대고 
+
+## 23년 3월까지 매입하라
+
+연준이 금리인하를 했제하는건 미리 준비를 하란 메시지. 금리인하를 하면 그땐 다시 렐리가 시장된다. 따라서 내 숏포지션도 3개월 이내엔 청산하고 현금모드로 들어가야한다.
+
+## 하락장에서의 투자심리의 모습
+
+악재가 좀 없다 싶으면 이래서 올라가고 이래서 매집해야하고 이거 찐반등인데?
+
+호들갑을 하다가 예정되어있던 악재가 재 알람이 시작되면 호다닥 도망감
+
+데일리 트레이더의 호들갑 및 먹이감을 불러오는 전략
+
+## 달러는 언제 약세로 돌아갈까?
+
+1) 석유 가격이 안정화되면
+
+2) 침체 리스크가 사라지면
+
+## 스타트업에 투자하는 방법 
+
+* 서비스: 엔젤리그, 버드 
+
+* 특징: 투자금 회수 어려움, 양도소득세 (10%~20%), 결제 사고 가능성, 100% 소득공제 (3천만원)
\ No newline at end of file
diff --git "a/Bear/\360\237\222\273MAC.md" "b/Bear/\360\237\222\273MAC.md"
new file mode 100644
index 0000000..ad6696f
--- /dev/null
+++ "b/Bear/\360\237\222\273MAC.md"
@@ -0,0 +1,162 @@
+# 💻MAC
+
+#Devops/OS
+
+
+---
+
+### 공통
+
+`CTL + CMD + SPACE`  → 이모지콘
+
+`CMD-SFT+Arrow` 커서에서 라인 끝까지 블럭
+
+`CMD-Arrow` 라인 끝으로 커서 이동
+
+전체 캡처 `F13`, 선택 캡처 `CMD+F13`, 레코딩 `CMD+SHIFT+F13` (또는 F6)
+
+	if u want capture to clipboard press `CTL` with above shortcuts.
+
+`CMD + Tab`
+
+	CMD+TAB 한뒤에 CMD를 누르고 있는 상태에서
+
+		 ` : 역방향 이동
+
+		`q`: 선택된 앱 종료
+
+		`[cmd → opt]` / `[opt + Click]` → 최소화된 창 보이게 하기. 
+
+`CMD + CTL + D` 사전 팝업1
+
+`CTRL+OPT+CMD+P` - SLEEP
+
+`CMD OPT H` -> 액티브 빼고 다 최소화
+
+`Force 1 tap` - 데이터 탐색 (사전)
+
+
+---
+
+## VS (VisualStudio)
+
+`Shift + Alt + (↑, ↓)` ->  한줄 복사
+
+`ALT + (↑, ↓)` ->  한줄 이동
+
+`CTL + SHIFT`  -> 한줄 삭제 
+
+`CMD + KF` —> 코드 정렬
+
+`cmd+k cmd+0` -> FoldAll
+
+`cmd+k cmd+j` -> Unfold All
+
+`SHIFT + click`  -> Unfold recursive
+
+`CMD+SHIFT+B` -> beauty extension
+
+`CMD+SHIFT+O` -> Symbol find (변수 및 펑션 검색)
+
+## Sapari
+
+Customizing key (not work other env)
+
+`OPT + P`  자바스크립트 정지
+
+`OPT + S`  open this site at chrome
+
+Vanilla
+
+
+
+
+---
+
+### Customized Key
+
+F6을 F13으로 쓰기로 함. 프린트는 그걸로 하면된다.
+
+
+---
+
+### shottr
+
+customizing key (not work other env)
+
+`F13` 액티브 창 캡처
+
+`CMD + F13` 아레나 캡처
+
+`SHIFT + F13` 풀스크린 캡처
+
+`CTRL + F13` 스크롤 캡처
+
+`CTRL + CMD + SHIFT + F13` 복합 캡처 모드
+
+
+---
+
+### MAC notes
+
+opt + 7 → 블릿
+
+`opt + shift + 7`  → 블릿 포맷
+
+`ctl + alt + tab`  → TAB 
+
+
+
+### FINDER
+
+`Cmd + SHIFT + G` 이동
+
+`CMD + OPT + DEL` 바로 삭제
+
+
+
+처음 작업을 시작할때 파일 제목 리스트를 생성하고 (스페이스는 _로 치환) 제목을 찾지못하면 그냥 파싱을 포기하고 그대로 출력하는것도 나쁘지 않을듯
+
+
+
+## KeyBoard
+
+`fn + arrow`  →  home up and end
+
+Global icon →  Fn
+
+## GIT
+
+커밋 메시지 수정 `git commit --amend -m "commit_message"`
+
+gc 제일 강하게 git gc —aggressive —prune=now
+
+
+
+
+---
+
+## Reminder
+
+`CMD + ] ` → make subtask. only work list screen not work other view like schedule, today.
+
+
+---
+
+## 아톰
+
+`CTL + SHIFT + M` 마크업 미리보기.
+
+
+---
+
+## Brew
+
+* brew tap → Add Repository 
+
+
+---
+
+## Crome
+
+`shift + Scroll`-> 좌우 스크롤
\ No newline at end of file
diff --git "a/Bear/\360\237\222\276 Linux.md" "b/Bear/\360\237\222\276 Linux.md"
new file mode 100644
index 0000000..fd0ac47
--- /dev/null
+++ "b/Bear/\360\237\222\276 Linux.md"	
@@ -0,0 +1,155 @@
+# 💾 Linux
+
+# 리눅스를 부팅하면 내부에서 어떤 과정을 거치는가?
+
+`BIOS > bootloader > linux kernel > initramfs (램기반FS) > init (systemd) > Init.d (*etc*init.d)`
+
+* init.d 시스템 부팅 후 첫 프로세스 init 이 사용하는 스크립트들을 담고 있음. 서비스에 대한 start reload 컨트롤하는 스크립트 가짐.
+
+**`*etc*init` 이 디렉토리는 Upstart가 사용하는 설정파일들을 담고 있음. Upstart가 서비스 start reload 컨트롤하는 설정.**Upstart 는 systemd로 대체 예정 (ubuntu 12, cent7 부터는 systemd를 쓴다)*
+
+
+
+# 프로세스 컨트롤 hot-key
+
+	* CTRL+C 
+
+	* CTRL+Z
+
+	* fg %{PID}
+
+		* 이걸로 정지된 프로세스 재개 가능
+
+		* fg = foregrond
+
+	* bg %{PID}
+
+		* Background 로 보내기
+
+
+
+# 파일 시스템
+
+* *proc*
+
+	* 리눅스의 커널과 사용자 영역 사이에 일어나는 통신 채널로 사용하는 가상 파일 시스템
+
+* /opt 
+
+	* 사용자가 설치하지 않은 하지만 시스템 기본 프로그램도 아닌것이 깔린다.
+
+* *dev*
+
+	* 디바이스 (리소스)
+
+
+
+# Shell
+
+* 정의
+
+	* 사용자와 커널 사이의 인터페이스를 감싸는 층이라서 붙은 이름
+
+	* NT는 CMD.EXE, Linux는 bash 가 기본
+
+* LoginShell 
+
+	*  .profile .bashprofile 이 해당
+
+	* .bash_profile  .profile 은 매번 로그인할때 한번 실행
+
+* Non Login Shell 
+
+	* ssh 접근 후 bash를 실행하거나 GUI세션에서 여는 경우, su 같은 상황을 말함.
+
+	* 맥은 모든 쉘을 LoginShell 취급함. 이 말은 일반 POSIX는 아니란 거고 Profile의 내용이 잘 적용되지 않을 수 있단 이야기.
+
+	* .bashrc는 로그인한 상태에서 새 터미널 열때마다 실행
+
+* bash 관리 정석
+
+	* [관리자환경파일] *etc*profile
+
+		* .profile 은 환경변수 등
+
+	* [사용자환경파일] ~/.bash_profile
+
+	* [사용자환경파일] ~/.bashrc
+
+		* .~rc파일에 alias , 함수등 정의 (run configuration)
+
+* ~/. 에서 설정하는 것들은 사용자에게만 한정된다. 다른 사용자에게 영향 없음.
+
+
+
+# systemd
+
+	* systemd : init 데몬
+
+	* systemd-journald : 다른 데몬(프로세스)들의 출력(syslog, 표준, 에러 출력), 로그 저장 데몬
+
+	* systemd-logind : 사용자 로그인, 세션 등 관리 데몬 
+
+	* systemd-udevd : 장치 관리자 데몬
+
+	* systemd-networkd : 네트워크 관리 데몬. DHCP 뿐만 아니라 Virtual Lan 설정까지 가능
+
+	* systemd-resolved : DNS 해석 데몬
+
+	* systemd-timesyncd : NTP로 컴퓨터 시간 동기화 데몬
+
+	* systemd-boot : UEFI 부트로더
+
+	* systemd 의 시대로 오면서 systemctl 명령어로 데몬을 컨트롤하기만 하면 되는구조로 바뀜
+
+
+
+ssh-keygen -t rsa
+
+ssh~~copu~~id -i [공개키] [키를 받을 호스트] 이렇게 하면 ssh 비번없이 된다. 키만 준다고 될게 아니다. sshd 를 다시 불러오는 방법도 있다.
+
+
+
+리눅스의 파일시스템. 디바이스 > 파티션 > 마운트
+
+버전마다 같은 명령어라도 출력 포맷이 다르다.. awk 를 잘 써야함.. 뭔가 스마트한 방법 없나
+
+
+
+
+
+# /proc
+
+## *[pid]*fd
+
+### 여기서 열려있는 심볼링 링크들이 
+
+`9999 -> pipe:[numbers]` 이렇게 표현되는데 numbers는 inode다. `find / -inum 아이노드번호 2>*dev*null` 검색이 필요할땐 이렇게
+
+
+
+## iNode 100% 문제
+
+1. `df -l`
+
+2. `*var/log` `var*spool’` 에서 많은 숫자의 파일을 생성했을때 증상이 발생한다.
+
+3. 지우거나 옮기고 심볼릭을 건다
+
+```
+
+sudo mv /var/log/* /home/사용자명/log
+
+sudo ln -s /home/사용자명/log /var/log
+
+```
+
+4. `’*var/spool/mail*`의 파일을 지우거나 다른 곳에 백업해준다. (스풀은 발송하지 못한 메일이 쌓이는 곳이며 어디서 쏘는지 알아내서 막으면 된다)
+
+
+
+
+
+
+
+#Devops/OS
\ No newline at end of file
diff --git "a/Bear/\360\237\223\222IT Mainline.md" "b/Bear/\360\237\223\222IT Mainline.md"
new file mode 100644
index 0000000..025209a
--- /dev/null
+++ "b/Bear/\360\237\223\222IT Mainline.md"	
@@ -0,0 +1,317 @@
+# 📒IT Mainline
+
+WEB - Nginx
+
+WAS - 톰캣/서블릿 등 앱(로직)=컨테이너를 가동해주는 서비스
+
+Cache by AWS lightsail -  [https:*/blog.lael.be/post/7605](https://blog.lael.be/post*7605) 
+
+APM Application Performance Management
+
+
+
+나도 디버깅 실력이 죽긴했구나
+
+* 왜 함수가 실행안되나 의아해 하고 있었는데
+
+* 프로미즈에서 에러가 나서 플러그인 전체가 작동안하고 있었음.
+
+* 에러가 나는걸 자세히 안읽은게 문제
+
+
+
+
+
+멀티태스크 - 여러개의 프로세스. 컨텍스트는 독립.
+
+멀티쓰레드 - 프로세스가 여러개의 쓰레드를 가짐. 컨텍스트를 공유함. 비용적음
+
+
+
+세션은 Redis로 하는게 정석
+
+
+
+유닉스 계통은 crash 명령어로 리포트를 볼 수 있음
+
+ADG DR ( Ative Data Guard Disaster Recovery)
+
+: 디비의 동기화 시스템을 끊어서 잘못된 반영의 확산을 방지
+
+
+
+⎯⎯⎯⎯⎯⎯- 단어 뜻 찾기 ⎯⎯⎯⎯⎯⎯ 
+
+**Amazon Machine Image**
+
+
+
+MyO
+
+파게이트 관리할때 인스턴스 갯수 뿐만 아니라 Cpu 갯수도 관리할 수 있다면 굉장히 저렴하게 관리할 수 있지 않을까.
+
+피크 타임이 아닐때 최소 2개를 남겨 둔다면 한개씩 롤링으로 vCPU를 줄여서 재기동. 하여 비용을 최대로 낮추기
+
+2대가 불안하다면 임시로 3대를 켜서 롤링업데이트  
+
+* 루센트때 서버비용이 엄청 비싼게 게이트웨이 + 파게이트 였다
+
+
+
+스탭 펑션 플로우를 보고 느낀점
+
+* My Opinion> 이게 프로그래밍의 미래인가 미쳤다.. 플로우 차트에 드래그를 하면 서비스가 되네
+
+
+
+
+
+퀀트킹처럼 리소스사용에 대해서도 최적화 툴를 개발할 순 없을까. 사용량과 구성을 입력하면 시나리오 출력
+
+
+
+내가 테스트코드를 어떻게 짰어야했을까 뭐가 잘못됐지? 익스프레스 테스트 코드를 확인해보자 깃헙에
+
+
+
+Grave `
+
+Aposterophe ' 어퍼스트로피
+
+앵글 브라켓, 틸드~ ^카렛, 이퀄사인, 콜론, 세미콜론, 
+
+
+
+NAT Gatewaya 켜놓기만 했는데 한달에 36달러 나왔다..
+
+다 배움이다. 수업비용 치곤 싼거야.. 절대로 테라폼 없이 하지 말자..;; ㅠㅠ
+
+→ 별 트래픽이 없는데 비용이 청구되면 미리미리 알람을 주는 서비스 있으면 좋겠다! 내가 만들면 어떄!?
+
+
+
+포트란의 for ···   do ···  에서 유래했다.
+
+
+
+
+
+Git을 통해 DevOPS를 하는걸 말한다. (엄밀히 말하면 Devops는 문화고 Git은 CD 방법론)
+
+
+
+
+
+
+
+SVN
+
+
+
+And don't worry if you forgot to tag—you can always specify an older revision and tag anytime:
+
+$ svn copy -r 11 file:*//var/svn/repos/test*trunk \
+
+           file:*//var/svn/repos/test/tags*0.6.32-prerelease \
+
+           -m "Forgot to tag at rev 11"
+
+
+
+Committed revision 13.
+
+SVN copy는 url to url Working to URL 등의 방법으로 활용한다. 태그를 남길때 추천하는 방법
+
+
+
+
+
+The xattr command can be used to display, modify or remove the extended attributes of one or more files
+
+
+
+
+
+docker run ~~d -~~name my-nginx nginx
+
+→ 깔끔하게 컨테이너들을 실행하고 끝내자!
+
+
+
+
+
+IT메인스트림: 네임스페이스. 단일 클러스터 리소스 그룹 격리 메커니즘. 리소스의 이름은 네임스페이스 내에서 유일해야함, 네임스페이스 간은 독립성 보장을 한다.  다만 네임스페이스 기반 스코핑은 네임스페이스 기반 오브젝트 (예: 디플로이먼트, 서비스 등) 에만 적용 ←→ 클러스터 범위의 오브젝트 (예: 스토리지클래스, 노드, 퍼시스턴트볼륨 등) 에는 적용 불가능
+
+
+
+"APA Style에 따르면 줄임말은 문장에서 처음 등장할 때 한 번 풀어서 설명하고, 이후부터는 줄임말만 사용하라고 줄임말 표기 원칙을 제시하고 있습니다."
+
+
+
+k8s Node 는 다른 레플리카셋을 크로스하게 가진다. 
+
+
+
+
+
+*var/spool*clientmqueue
+
+메일 서비스를 꺼놓으면 큐가 차오르게 된다. 매일을 누가 보내는지 알아내서 처리해야한다.
+
+serivce sendmail status
+
+
+
+템플릿 리터럴 (확장표현, 문자열 치환) `${var}`
+
+
+
+
+
+언어를 배울때는 문법은 대충보고 퀴즈푸는게 최고다...
+
+
+
+20220629 휴먼에러 방지 교육
+
+오프스택 운영에 대한 이야기. 이중화 그룹명이 입력안된채로 운영중..?? 이라고 한다. 
+
+클라우드스택 237, 젠서버 79, 오픈스택 IPC2.0 	
+
+VM 대신 IPC 포탈에서도 재기동을 할 수 있게 해놓았고 그걸 권장한다. 프로세스를 지켜..(..??) 그래야 IPC팀에서 그걸 고친데! 종합장애 관리 대시보드란게 있는데 각 장애에 대해 영향도를 평가할 수 있는 공간이 있다.
+
+def ilaya1():
+
+    current***func***name = sys.***getframe().f***code.co_name
+
+    print ("The current running function name : {}".format(current***func***name))
+
+
+
+
+---
+
+## 프로그래머의 경제적 해자
+
+Q) 어떻게 해야 연봉 5억을 받을 수 있을까요?
+
+A) 회사에서 일하는 두가지 사람
+
+양동이를 들고 열심히 퍼나르르는 타입 1
+
+삽을 들고 수로를 파는 타입 2
+
+두 사람이 평가받는 방식은 다르다. 예측된 리스크는 리스크가 아니다. 삽을 들고 수로를 판다는건 무한한 카오스의 세계에 진입하는 것이다. 그렇게 진입해서
+
+
+
+1. 회사의 초창기부터 중요한 핵심 가치를 만들어내는 책임을 졌거나,
+
+2. 사이드 프로젝트로 새로운 뭔가를 만들어냈는데 이게 우연히 가치있는 것이라는 사실이 밝혀졌거나,
+
+3. 가치를 만들어내는 스타트업으로 인정받고 인수되었거나,
+
+4. 가치의 흐름에 대한 독점적인 지식을 어떤 식으로든 가지고 있다거나 (잘 없습니다)
+
+
+
+위의 사람들이 5억을 받습니다. 리스크를 지지 않으면 타입2는 없다. 페이스북에 떨어져 와츠앱을 창업하여 페이스북에 회사를 판 개발자의 사례
+
+
+---
+
+## Lens 서비스를 보고 난 뒤 느낀점
+
+뭔가 렌즈까지 오니 내가 원숭이가 된 기분이네.. 데브옵스에 미래긴 있긴 한거야? 시간 더 지나면 앱만 구성하면 노DevOps 패러다임도 나오겠다. 실제로 렌즈 서비스의 캐치프레이즈가 No Devops 
+
+
+
+# 함수 네이밍
+
+check → return True or False
+
+is -> return True
+
+
+
+# 임포스터 증후군
+
+내 실체가 들통나고 말것이다. 58~70%가 이걸 겪는다. 
+
+19년차인데 아마존 이직해서 이런 느낌을 받는다. 결국 네가 영향르 미칠 수 있는 일에만 신경을 써야할때가 올거야~
+
+방대한 지식이 필요하다. 리더십 및 커뮤니케이션, 영어 뛰어난 사람이란 편견
+
+나를 선배라고 부르는 사람들로부터 임포스터 감정을 느낀다. 영어 환경도 개발 문화도.. 과연 ..? 자격이..? CTO와 개발 회의를 하면 한없이 작게 느껴질때 가면증후군을 느끼게 된다.
+
+어떻게 이것을 극복할것인가. 몇일간 준비한 발표를 끝나고 여어로 하고 매니저한테 물어봤데. 제임스가 너무 잘해서 긴장됐어! 그런데 제임스는 몇일동안 저것만 했어.. 넌 일도 했고. 우리는 다른 사람들의 하이라이트만 본다
+
+성장차이를 가르는 팁
+
+1. 가면 증후군이 있게 70% 이상이 겪는다. 이를 인지한다. 저 친구가 더 뛰어난것 같아. 이런 내면의 목소리가 증후군임을 인지한다. 감정에 휘둘리지 말고 그게 왜 그랬는지를 객관적으로 바라본다. 
+
+2. 나는 항상 다른 사람의 하이라이트 순간을 보고 있다. 저 사람이 저렇게 빠르게 하기 까지 얼마나 했을지 고민해보자. 얼마나 많은 연습을 했길래..? 물어보자 타고났다가 아니라 노력을 했다고 생각해보라. 고난이 있었을거라 생각하라.
+
+ Fixed mindset vs Growth Mindset. 픽스드 되면 똑똑한 것에 집착하고 성장에 방해된다. 그 어떤 것들도 충분히 지속적으로 노력하면 개발해나갈 수 있다. 이렇게 믿으면 실패를 두려워하지 않게 된다. 피드백을 받는걸 두려워하지 않게 된다. 
+
+3. 모든걸 다 아는 완벽한 전문가가 될 수 없다. 너무 분약가 많잖아. 이걸 인정해 .T자로 경력을 관리하라는게 그래서 추천하는것이다. 분야, 실무 사이드에 필요한지 중요도와 우선순위를 결정해라. 그리고 당당하게 말해라. 내 분야도 사이드 프로젝트도 중요도도 높지 않다고 말해라. 수요가 높은걸 픽해서 공부해 그냥! 
+
+4. 나의 강점이 뭔지 분석해 본다. 내 가 취약하다고 느끼는 부분을 분석해본다. 언제 임포스터에 사로잡히나 언제 퍼포먼스가 떨어지는가? 그걸 분석한다. 모든걸 잘할 필요는 없다. 정말 치명적인거 하나씩만 공략한다. 장점을 강화하는게 우선이고
+
+5. 성장의 길을 택하자. 분명 타고난 사람도 있겠지만 아닌 사람이 대부분은 조금씩 성장하는 사람이다. 하이라이트를 바라보고 있다는걸 생각하고. 컴포트존에 있는데 익숙해지면 안된다. 그래야 두려움이 줄어들고 많이 배운다. 
+
+![](/BearImages/9D09741D-6EA2-4B72-A42F-6636453091EC-41471-000012A921C3C386/4860BEF0-93D1-4EE9-A44C-8FECC4B55007.png)
+
+두려움을 성장통이라고 생각할 수 있다. 게임하는것처럼 어제보다 나은 오늘의 나를 그려보자. 
+
+
+
+## Bold Italic Underline의 의미
+
+Bold 의미 강조, Underline 교정의 의미, Italic 일반텍스트와 구분, 
+
+bring attention to, unarticulated annotation, idiomatic text
+
+그래서 언더라인은 별로 쓸일이 없다.(하이퍼텍스트와 햇갈릴 수 있다) 빨간줄을 통해 철자가 틀린 텍스트를 나타내거나 중국어 고유명사를 표시할 수 있습니다
+
+
+
+ 요소는 텍스트에서 어떤 이유로 주위와 구분해야 하는 부분을 나타냅니다. 기술 용어, 외국어 구절, 등장인물의 생각 등을 예시로 들 수 있습니다. 보통 기울임꼴로 표시합니다.
+
+
+
+##  사업가 및 개발자로서의 커리어에 대한 세션 정리
+
+* 모두가 창업을 할 필요는 없지만 창업가 정신은 필요하다. (능동적인 태도는 생동감있느 삶과 즐거움의 원천)
+
+* 창업을 나중에 하고 싶다면 기술적으로 뛰어나야한다. 최소한 매니징을 할 줄알아야지.
+
+* 창업에 관심이 없다면 사업과 경영과 리더십에 관심을 가져야한다.
+
+* 90%가 스타트업에 취직을 한다. 그런 회사들은 모두 기업가 정신을 품은 회사다. 일반적인 대기업과 다르다. 개발자들이 CEO의 생각에 대해 자신도 관점을 가져야한다. 작은 조직에 있으면 의사결정에 참여하게 된다.
+
+* 어느 쪽을 가든 사이드프로젝트를 해야한다.
+
+* 패인킬러 vs 비타
+
+* 문제를 상상하면 안된다. ~면 좋을것 같아. 술자리에서 나오는 사업
+
+* 피드백을 받기도 어렵고 상황을 설명하기도 어렵다. 스티븐 잡스는 비타민 그렇다고 내가 비타민을 강요하지는 않을것. 하지만 대개 비타민은 성공하기 힘들다. 비타민같지만 패인킬러인것도 있다.
+
+* 2주만에 만들고 2주동안 파인하게 만드는것도 가능하다.
+
+* 사용자가 있는 포트폴리오는 의미있다. 돈 받으면 더 가치있고
+
+* 데모사이트 만들어놓고 사전예약처럼 이벤트 받아서 처리한다. 관심을 확인하는게 창업의 첫순서. 요즘은 이렇게 사업이 변했다.
+
+* 수익구조가 심플해야한다. 간단하게 설명할 수있어야 좋은 아이디어. 위대한 아이디어는 설명해도 모른다. 잘되는 사람은 자신을 매니페스트하는데 두려움이 없다. 계속 노출시킨다. 잘되는 사업도 그렇다. 노출시키고 빠르게 피드백을 받아서 개선시킨다. 빅피쳐보다는 고객의 관심이 답이다.
+
+* 어찌되든 사이드프로젝트는 하고 공개해야한다. 그리고 남들이 쓰게해야한다. 개발주기는 짧게 해야한다.
+
+* 제너랄한걸 노려도 되고 니치한걸 노려도 되고 돈을 안벌어도 인수되는 방법도 있다.
+
+
+
+
+
+#devops/Mainline
\ No newline at end of file
diff --git "a/Bear/\360\237\223\226IT concept dictionary.md" "b/Bear/\360\237\223\226IT concept dictionary.md"
new file mode 100644
index 0000000..e3a4ad6
--- /dev/null
+++ "b/Bear/\360\237\223\226IT concept dictionary.md"	
@@ -0,0 +1,83 @@
+# 📖IT concept dictionary
+
+#devops/Mainline
+
+
+
+* 프로퍼티 = 필드
+
+* PEM (Privacy Enhanced Mail)은 Base64 로 인코딩한 텍스트 형식의 파일
+
+```bash
+
+
+-----BEGIN OPENSSH PRIVATE KEY-----
+
+```
+
+이런 파일유형 구문을 사용한다. 
+
+* compliance - 준법감시, 내부통제
+
+* ALM application Lifecycle Management 더 광범위한 소프트웨어 관리 (Cm의 상위) + 품질관리
+
+* WIP : Work in Progress 
+
+
+
+
+
+## makefile
+
+* make 명령에 따라 실행할 스크립트를 명세한 파일 네이밍 컨벤션
+
+```makefile
+
+upgrade-eks:
+
+	helm upgrade -i aws-load-balancer-controller \
+
+		-n kube-system \
+
+		-f values-eks.yaml \
+
+		.
+
+
+
+delete:
+
+	helm delete -n kube-system aws-load-balancer-controller
+
+
+
+//일반적으로는 다음의 구조를 가진다. 
+
+CC = gcc  // 매크로 정의
+
+target1 : denpendency1 denpendency2
+
+	command1
+
+  command2
+
+// 타겟절(clause), 의존성, 명령
+
+```
+
+* 따라서 이런 구조일 때 `make upgrade-eks`으로 명령어를 실행시켜주는 명령어라고 보면된다. 
+
+* make -> The purpose of the make utility is to determine automatically which pieces of a large program need to be recompiled, and issue the commands to recompile them
+
+* 그래서 그냥 세부 스크립트를 직접 실행해도 결과는 같다.
+
+
+---
+
+
+
+
+
+# Math
+
+* 분위수 (Quantile), 확률분포에서 구간을 나누는 기준이 되는 수. 이분위수는 중앙값(median), 삼분위수(textiles), 2/3를 2삼분위수라고 읽음. 넷으로 나누면 사분위수(quartile)
\ No newline at end of file
diff --git "a/Bear/\360\237\223\232\353\260\260\354\233\200\354\235\230 \354\212\244\355\202\254 \360\237\216\226Be professional.md" "b/Bear/\360\237\223\232\353\260\260\354\233\200\354\235\230 \354\212\244\355\202\254 \360\237\216\226Be professional.md"
new file mode 100644
index 0000000..b3cc78a
--- /dev/null
+++ "b/Bear/\360\237\223\232\353\260\260\354\233\200\354\235\230 \354\212\244\355\202\254 \360\237\216\226Be professional.md"	
@@ -0,0 +1,4 @@
+# 📚배움의 스킬 🎖Be professional
+
+#living* 요즘 세대는 금방 검색으로 해결하려고 한다. 무슨무슨 운동법 무슨무슨 공부법. 손쉽게 해내려는 심리를 이용해 컨텐츠를 파는 사람들. 그런데 특별한 방법은 없다. 해내는 프로들은 일반인들보다 훨씬 강도높게 한다. 그뿐이다. 새로운 방법론을 고민 할 시간에 내가 열심히 했는지 의심해라.* 외국어를 배울때는 감정이 동하는 모든 수단을 동원해라.* 야생동물이 사육된 동물보다 훨씬 더 똑똑하다.* 감정적인 (슬픔, 좌절감, 심지어 열등감까지) 요인이 우리의 뇌학습을 견인한다.* 스스로 완벽해야한다는 관념이 너무 강해서 말을 하는 과정중에도 자신에 대한 사고를 하는것이다. 이런 관념을 내려놓을 필요가 있다. 스스로 기능을 방해하는 신념. 일단 믿고 틀리면 그때 고치면 된다는 마인드셋이 유연하면서도 강하다.* 뭔가를 배우다가 재미를 잃는 순간이 위험하다. 꾸준히 즐길 방법을 찾아봐라.* 메모학	* 에디톨로지. 		* 편집을 하는 과정에서 창조적 힘이 발휘된다.		* 편집을 염두하고 메모를 카테고리로 나눠서 작성하고 생각노트로 전자화		* 한다음 최종적으론 항상 볼 수 있는 형태로 출력한다.		* 생각노트로 전환하는 과정에선 버리는 것도 필요하다.	* 메모학2		* 핵심키워드만 2개쓰기		* 버리는 용기		* 자기성찰 5카테고리 습관 파티션		* 자기화 		* 책을 볼땐			* 순간 생각 5번하고 생각이음 			* 이때 안보고 메모 			* 읽은책을 분류해 놓으면 기억에 남는다 			* 연습하면 누구나 80%는 기억한다		* 요약과 분류. 다 적는게 문제		* 유능감을 느낄 수 있다 		* 일을 할때는?			* 상사의 내재적 의도 + 일의 최종 목표.		* 필요한 노트는			* 만능노트 (+분류노트)## 사이버 강의를 제대로 활용하는 방법1) 일부러 현실공간처럼 사이버 강의 공간을 꾸며야한다. 서서듣고 출입증 찍고 손으로 메모하고2) 어릴수록 S를 봤다고 하고 나이 먹으면 H라고 답한다. 너묵 구체적인 것부터 시작하려고 하지 말자 나이를 먹을수록. 맥락에서 시작해서 스페시픽한 방법으로 접근하자.3) 어색하더라도 3개월이 지나면 습관이란 플랫폼에서 몸이 우리를 단련시켜준다.## 최재천 "독서는 일이어야 한다"1. 제목이 중요하다. 데이터만 중요한게 아니다.2. 인생에 글을 쓰는 것만큼 중요한게 없다.3. 시인이 되기 위해 살다가 솔제니친의 개미에 대한 묘사와 이기적인 유전자의 결합으로 인생이 바뀜4. 제자를 위해 연구를 포기한것이 큰 아픔이었고 콤플렉스였지만 그것으로 인해 600명이 참가하는 백과사전의 편집장이 되는 영광을 얻었다.5. 변죽을 울리지 말고 핵심을 먼저 제시한다.6. "교수님 저는 그렇게 쓰고 싶었는데 그렇게 안됬네요." "그럼 그렇게 쓰지?" 3시간쯤 그걸 고치다보면 자기글이 너무나 놀랍다.7. 글쓰는데 많은 힘을 쓴다. 숨이 차는 문장도 쳐낸다. 고치고 또 고친다. 글을 잘 쓰는 편은 아니다. 치열하게 쓸뿐.8. 연필로 쓰는 사람 컴퓨터로 쓰는 사람 다양하다9. 많이 읽은 사람이 잘쓰고 많이 쓴다.10. 기획독서, 책이란것은 내가 모르는 분야를 알기 위해 누군가 써놓은것 독서는 취미가 아니어야 일이어야 한다. 그저 즐기는거라면 클럽에 가는게 낫다. 어렵더라도 한권 두권이 되고 지식의 영토를 늘려나가게 된다. 그렇게 100세 시대에 살아가는것이다.## 황상민 "전문가가 된다는 것"1. 필드에서 살아남고 사람과 부딪치고 생각과 부딪치는 만큼 내공이 생긴다.2. 질문하는 만큼 생각의 깊이가 생긴다.3. 문제를 자신의 프레임으로 해석## 도파 선생님1. "전 개인적으로 강사로 일할 떄 경험으로 느낀건데 가르쳐도 젤 안 느는 사람은 아무것도 모르는 사람이 아니라 깊이 없이 넓게 아는 사람들임 뭔가를 알려줘도 아 그건 아는건데 하는 생각으로 대충 듣고 자기가 아는것만 확인하고 넘어가서 중요한 요소를 많이 놓침 지금  상태가 딱 그래!## 나라는 선생님* 검색되는 지식 / 검색되지 않는 지식 / 머신러닝으로 정복되지만 검색은 되지 않는 지식 / 그럼에도 정복되지 않는 지식. 오늘 나는 무슨 지식을 공부했는가?## 정승제 선생님이 사회는 경쟁사회가 아니다. 경쟁은 10%만 한다. 나머지는 전문가가 되는 길을 귀찮아한다. 원래 그런거야. 그 한마디. 전문가가 되고 싶다면 블랙존을 향해 나가야한다.## 인강듣는법* 강의 내용을 적는것 보다 내 생각을 더 혼합해서 내 기억과 짬뽕하는게 더 중요하다.* 필기, 듣기, 복습. 시뮬레이션을 해본다. (과연 나라면 어떻게 이걸 강의를 이야기할까?→ 능동적으로 해볼려는 과정에서 내께 된다.) * 나는 이렇게 생각했는데 강사는 저렇게 했네하고 비교한다. * 듣고 나면 나의 과거랑 비교해서 이걸 어떻게 달라질까를 생각하고 사용한다.* 업그레이드하도록 경험을 이용한다.  프로그래밍은 도구다. 도구를 사용할때 가장 기억을 하게 하된다. ## 드림코딩 - 인강효율 200% 팁* 목표를 확실하게 설정한다. → 얻고자하는게 뭔지 내가 뭘 어떻게 할지 능동적으로! 생각* 끝까지 하고 난 다음에 목표에 대해 판단한다. * 노트에 작성하면서 듣는다. (필요할때마다 검색하고, 링크를 계속 추가한다.) * 직접 정리하고 찾아보면서 배운다. (추가로 공부하고 참조 사이트를 뒤져보고)* 퀴즈나 과제는 직접 해보고 결과를 확인한다. 자신과 어떻게 다른지 아는게 중요하다. 코드를 적는게 아니라 내 언어로 바꾸는 과정에서 ‘뜨악한 느낌’이 중요해.* 책을 사서 끝까지 다 본다. 이건 바보같은 전략. 개념과 맥락을 느끼는게 더 중요하다. 바로 실전이 굳. 똑똑한 엔지니어들에게 배우는게 제일 좋다. 못하면 블로그에서 깃헙에서 배우든가!## 수학적 사고력은 왜 전이되지 않을까?* 형식도야식 공부법 (학습자의 정신적 능력을 기르는 데에 중점을 두는 교육 방법)의 효능에 대한 의구심. 이건 전이를 전제한 방법론이다. 이건 특정과제를 ‘훈련시키는 것’보다 광범위하게 ‘가르치는 것’을 믿는다. 예를 들어 수학을 공부하라는것 처럼* 이런 학교학습에 반대되는 것이 야생학습은 대부분 협력적이고, 비순차적이다.* 그럼에도 일반적인 지능은 존재했다. IQ 그런데 저자는 수학과 영어 1등급, 동생은 수학 영어 9등```결정적 분기는 중학생 때였습니다. 저는 당시 열정적인 담임 선생님을 만났는데. 이 분이 공부법에 관심이 많고, 학생 한 명 한 명 멘토링을 해주셨어요. 물론 과학적으로 올바른 방법은 아니었지만. 저는 선생님과 같이 영어 공부를 시작했고, 열심히 교과서를 무식하게 통째로 외웠습니다. 시험은 어찌어찌 잘 봤고. 그 후로 영어 공부를 계속해나갈 수 있었어요.```* 저자 주장의 핵심은 핵심은 전이나 IQ가 아니라 메타학습능력과 동기* 더 열심히 하기보다 다르게 하는법을 아는게 더 중요하다.* 열심히 숫자를 외울 수 있었던 스티븐펠룬은 다르게 하는 법을 배움으로서 엄청난 성장을 했지만 전이는 일어나지 않았다. 그 분야를 제외하곤 그렇게 멋진 기억력을 활용할 순 없었다* 90cm 던지기 연습을 한 그룹보다 더 나은 성적을 거둔 60cm + 120cm 혼합연습 그룹. … 에스페란토를 먼저 1년 배우고 프랑스어를 나중에 1년 배운 학생들이, 프랑스어만 2년 공부한 학생보다 성적이 좋았습니다.* 비슷하게 C와 Python을 같이 배운 학생들이, 같은 시간 동안 하나만 집중해서 배운 학생보다 프로그래밍을 잘 했습니다.```여기에 힌트가 있습니다. 수학이나 논리학을 공부하면 자연스럽게 문제해결능력이 길러질거라는 건 환상입니다. 그보다는 실제로 내 업무 속에서 논리적이거나 추상화해서 해결해야하는 문제를 찾고, 나름대로 정식화해서 해결하는 연습을 해보는 게 좋습니다. 그러면서 수학이나 논리학을 공부하다가 '연결'할 수 있거나 '통찰'을 찾아서 빌려올 수도 있겠죠. 그러다보면 수학 공식을 하나도 쓰지 않고도 '수학적'으로 문제해결을 할 수 있을지도 모릅니다.```* 전이는 전이를 염두해둔 학습에서만 일어난다. “지금 너희는 이것을 이해하지 못하겠지만, 나중에 이것는 너희에게 매우 중요할 것이다.”라는 충고는 적절성을 인지 못하게 하고 동기가 떨어지고 기억 재분류 작업에 비효율성을 도래한다.* 철수와 영희가 나오는 이상한 실생활 응용문제를 만들어야 한다는 게 아닙니다. 진짜 문제를 풀어야한다는 거죠.```저는 고등학생 분을 코칭한 적이 있습니다. 이 분은 인공지능을 배우고 싶어했는데요. 딥러닝 책을 공부하고 실습하는데 시그모이드 함수가 나왔습니다. 잘 모르면 시그모이드 함수가 매우 무서울 수 있죠.하지만 저는 같이 numpy와 matplotlib로 지수함수를 그려서 보여줬습니다. x 값이 변화함에 따라서 y 값이 변하는 걸 짚어주고. 이제 1 / e^x 의 그래프와 1 / 1 - e^x 그래프를 차례대로 그려보고요. 기울기나 상수를 바꿔가면서 그래프 모양이 변하는 과정을 관찰했습니다. 동시에 이런 게 머신러닝 모델을 학습시키는데 어떤 의미가 있는지 이야기해봤습니다.저는 블럭코딩으로 거북이를 움직이거나 알고리즘 퀴즈를 푸는 것보다, 이런 게 진짜 코딩 교육이 아닐까 싶습니다. 수학이 쓸모 있는 부분에서 쓸모를 찾고, 실제 상황에서 써보는 겁니다.```* 앞서 자동차 공장 사례에서 보신 것처럼 야생에서는 중요한 기술이 더 많습니다. 그리고 통찰이 꼭 수학에서만 오리라는 법도 없습니다.## How to ask - Code session**Tips***  질문하기 위해 글로 적는게 문제를 분해하는 방법이다.* 좋은 질문을 만들어내는게 능력.* 다른 사람이 하는 검색의 방법도 알아야 한다.* 묻는 사람에게 무엇을 검색 및 시도했는지 히스토리를 트래킹해서 전달한다.**Stack Overflow에 질문을 해보자**1. 키워드를 정확히하는게 핵심.2. 질문이 배척받아도 결국 하는 사람이 이긴다.	* 어떻게 설명할지 모른다. 무엇을 모르는지 모른다.	* 질문을 읽는 사람이 읽고 싶은 글을 써야한다 .How to Ask. 질문의 퀄리티를 올려야 한다.	* 그럼에도 미움받을 용기3. 질문의 첫번쨰 조건은 좋은 제목4. 바쁜 동료에게 하는 질문처럼 정리5. 당신이 처해있는 정보를 다른 사람이 재연할 수있도록 정보를 제공 (호브에 코드를 올리기)
+---#living
\ No newline at end of file
diff --git "a/Bear/\360\237\224\220\353\263\264\354\225\210.md" "b/Bear/\360\237\224\220\353\263\264\354\225\210.md"
new file mode 100644
index 0000000..4124e2f
--- /dev/null
+++ "b/Bear/\360\237\224\220\353\263\264\354\225\210.md"
@@ -0,0 +1,17 @@
+# 🔐보안
+
+## 인풋 박스 시나리오
+
+* SQL 공격에 사용될 수 있는 패턴 
+
+```html
+
+<img src=“image.gif” onerror=“prompt(‘으아’)”>
+
+```
+
+* innerHTML을 사용하지 않도록 한다. ContentsText가 브라우저에서 성능도 좋으니까 그거 쓰자.
+
+
+
+#Devops/security
\ No newline at end of file
diff --git "a/Bear/\360\237\224\226 \354\235\270\354\203\201\354\240\201\354\235\270 \353\213\250\037\037\354\226\264.md" "b/Bear/\360\237\224\226 \354\235\270\354\203\201\354\240\201\354\235\270 \353\213\250\037\037\354\226\264.md"
new file mode 100644
index 0000000..10ae690
--- /dev/null
+++ "b/Bear/\360\237\224\226 \354\235\270\354\203\201\354\240\201\354\235\270 \353\213\250\037\037\354\226\264.md"	
@@ -0,0 +1,10 @@
+# 🔖 인상적인 단어
+
+#Culture&Sense #blog
+
+
+---
+
+위상: 주기 별로 같은 함수의 그래프를 가지는 파형에서, 첫 시작점 또는 어느 한순간의 위치
+
+쌍방성
\ No newline at end of file
diff --git "a/Bear/\360\237\226\214\354\213\244\354\232\251, \354\235\230\353\257\270, \354\247\204\353\263\264 \354\262\240\355\225\231.md" "b/Bear/\360\237\226\214\354\213\244\354\232\251, \354\235\230\353\257\270, \354\247\204\353\263\264 \354\262\240\355\225\231.md"
new file mode 100644
index 0000000..6124828
--- /dev/null
+++ "b/Bear/\360\237\226\214\354\213\244\354\232\251, \354\235\230\353\257\270, \354\247\204\353\263\264 \354\262\240\355\225\231.md"	
@@ -0,0 +1,74 @@
+# 🖌실용, 의미, 진보 철학
+
+#mind
+
+
+---
+
+**의미와 예술**
+
+0. 아름다운 몸도, 맛있는 음식도, 훌륭한 노동의 결과 마저도 의미다. 그것이 빛나고 있다해도 부정적으로 보기로 한 사람은 그것을 순식간에 부정적으로 볼 수 있다. 언제든지 프레임을 바꿈으로서 부정해낼 수 있다. (그 반대도 가능하다.) 그 충동적인 부정의 순간을 얼마나 잘 방어할 수 있느냐에 따라 인간은 자신을 긍정하며 삶을 꾸밀수도 있고 그걸 방어하지 못하면 평생 자기를 부정하면서도 삶을 주체적으로 받아들이지를 못한다. 이런 방어가잘된다면 그 의미는 견고하다고 할 수 있다. 절대무적의 체계는 없지만, 견고한 체계는 존재한다. (블랙스완 저자가 말했던 견고함과도 관계된 개념이기도 하다)
+
+1. 견고한 서비스를 만들고 싶어하는 회사(오너)의 입장에선 모든 회사의  일이 예술적이다. 채용도 코드도 회의도 모두 예술이다.
+
+2. 자본주의를 비판하고 회사와 개인을 구분하려는 프레임을 쓰면 회사에 충실하려는 프레임을 무너트린다. 피동적이니까. 하지만 사람과 회사의 관계가 꼭 그래야만 한다는 법은 없다. 끌려온 노예의 마음이니까 그 프레임이 틀리지 않는 것이다.
+
+
+
+**내 문제를 해결할 방법 찾았다!**
+
+* 추상적인 단어 속에서 마음을 잃지 마라. 당장 내가 해야할 일과 만나는 사람과 내게 주어진 환경에 집중해도 할일은 충분하다.
+
+* 극복하는 마인드, 자신의 삶을 필연으로 여기는 마인드에 힘을 줘라. 한계를 찾는 마인드, 무작위의 삶, 평균을 염두하는 삶은 무기력하다. 
+
+
+
+**내 마음의 구조**
+
+* 어떤 계기로 자극받아서 긴장되고 목적의식을 가지고 사는 A
+
+* 사회적 상황에 과잉 자극 받아서 모든 것으로 부터 도망치기만을 기도하는 B
+
+* 이것이 모두 힘들어질때 그저 모든 문제를 흐트려놓아서 문제와 해결 방법으로부터 완전히 떨어져버리려는 C
+
+* 스트레스 상황을 현실을 받아들이는 내 마음을 컨트롤 할 수 있다고 말하는 D
+
+
+
+**진보 신학**
+
+* 보수는 벽 옆의 계단을 뚜벅뚜벅 이 악물고 올라야 하고
+
+* 진보는 벽에 여념치 않고 그저 날아올라야 한다. 보수의 레토릭에 지지말고 초월해야한다.
+
+* 예수 성공요인. 참신한 사회해석. 당돌한 락스타같은 통전성. 시인같은 표현능력. 
+
+
+
+**한박수**
+
+*  현실을 그대로 살지 않는 진보의 길. 그게 쉽다고 하면 거짓말 그런데 힘든건 결국 도움이 된다.
+
+
+
+불교 공부
+
+* 불교에서 자살을 반대하는 한가지 논리는 아직 그가 성불을 하지 못해 윤회의 운명을 벗어날 수 없는 상태에서 자살은 허물이라고 보기 때문이다.
+
+* 한편으로는 윤회에 대해 어느정도 인정한 붓다덕에 현대 불교는 윤회를 강조하고 이때문에 윤회를 부정하는 현대적 해석도 존재한다.
+
+* 업과 자아는 양립하기 힘들다. 자아를 부정하는 불교가 업을 강조하면 자아는 뚜렷해지기 때문이다.
+
+* "본질과 가치를 이해하고 매 순간 좋은 생을 살아야 근본이 변한다"
+
+
+
+금융과 투자
+
+* 투자는 예술이다. 세계에 대한 종합적 탐구와 해석, 그리고 실천의 종합격투기.
+
+
+
+유명인사의 덕담
+
+ * 플레임 - 아무일도 없었던것도 감사해야한다.
\ No newline at end of file
diff --git "a/Bear/\360\237\232\231\354\227\254\355\226\211\352\263\204\355\232\215.md" "b/Bear/\360\237\232\231\354\227\254\355\226\211\352\263\204\355\232\215.md"
new file mode 100644
index 0000000..edfa13b
--- /dev/null
+++ "b/Bear/\360\237\232\231\354\227\254\355\226\211\352\263\204\355\232\215.md"
@@ -0,0 +1,33 @@
+# 🚙여행계획
+
+# 평택 시내여행
+
+* 더샵지제역 부근 호수→ 통북시장 (평택역 옆)→ 평택 남쪽 원평나루→ 소사벌 레포츠(평화의상)→ 평택시 청→ 용죽공원 → 배다리 저수지 (평택 중앙) → 스타필드 안성
+
+
+
+* 서울숲공원
+
+* 별마당도서관
+
+* 광장시장
+
+* 남산타워 전망대 + 해질때가보는것도 좋겠다
+
+* 이태원
+
+* 익선동 한옥거리
+
+* 여의나루역
+
+* 남대문시장
+
+* 갈치골목
+
+* 롯데월드
+
+* 더현대서울
+
+
+
+#Dream&Bucket
\ No newline at end of file
diff --git "a/Bear/\360\237\233\240Command Tools.md" "b/Bear/\360\237\233\240Command Tools.md"
new file mode 100644
index 0000000..44f358c
--- /dev/null
+++ "b/Bear/\360\237\233\240Command Tools.md"	
@@ -0,0 +1,253 @@
+# 🛠Command Tools
+
+## wc (단어 세기)
+
+* return num
+
+
+
+## grep (단어 찾기 return string)
+
+`fgrep	(fixed)` ≡ grep -F	정규식을 배제
+
+`egrep	(extended)` ≡ grep -E 확장정규식을 위해 사용 escape 생략 가능
+
+
+
+## awk	특정 칼럼을 출력  
+
+* `awk ‘패턴{action}’ target` 개발자이름인데 
+
+* Aho. 산술, 비교, 논리 연산을 하고 출력 칼럼을 선택가능. retrun string
+
+
+
+## uniq	중복라인을 제거
+
+## sed	Stream editer 	
+
+`$ sed 's*KING/yyy*' emp.txt`
+
+→  emp.txt 를 출력할 때 KING 을 yyy 로 변경해서 출력한다. 데이터는 변경 안한다.
+
+* 원본 데이터는 변경하지 않은채 명령어로 VIM편집을 한것과 같은 결과를 낸다. (굉장히 고급스럽고 깔끔하네)
+
+* `sed ’s*trunk/‘${proejct}’\//*‘ result.txt > modified`
+
+
+
+## cut	
+
+* 바이트 문자열 필드 구분자 NUL 을 기준으로 문자열을 잘라내는 명령어
+
+
+
+## fmt	
+
+* 파일을 보기 좋은 포맷으로 바뀐다. 옵션 없으면 한문장으로 압축함
+
+	
+
+## tr  
+
+* 넘겨받은 문자열을 치환하거나 삭제. 굉장히 유연하고 광범위한 치환을 지원. 
+
+예제 `tr “1234” “abcd”` `tr “[a~~z]” [“A~~Z”]`
+
+
+
+## chage 
+
+**사용자의 패스워드 만기 정보를 변경 및 설정하는**명령어*이다
+
+
+
+## 프로세스 모니터링
+
+* PID
+
+* PPID parent
+
+* UID
+
+* GID
+
+* file descriptor
+
+
+
+## ps 자주 쓰는 옵션
+
+* ps 			사용자가 실행한 프로세스만
+
+* ps -ax		모든 프로세스
+
+* ps -aux	모든 프로세스의 자원 점유율까지
+
+* ps -ef		ppid를 포함한 조회
+
+
+
+리소스 소모를 체크할땐 ps 보다 htop 이 특화. atop은 과거 이력을 조회할때 유용
+
+kill은 프로세스 신호를 보내는게 원래 취지. -9  SIGKILL -15 SIGTERM 
+
+백그라운드는 & 간단~
+
+
+
+nmap - 포트 탐지
+
+tcpdump - tcp 사용 데이터
+
+mtr : ping + traceroute
+
+dig: domain information grouper
+
+airmon, airodump : wireless network scan
+
+iptables: linux firewall setter
+
+netstat: monitoring Port Status
+
+
+
+nmon: 로컬 시스템의 통계를 대화식으로 보여주고 통계를 기록함.
+
+iostat: 디스크 입출력 성능 분석
+
+sar : system activity report. 시스템 자원 사용률 이력을 저장하고 레포팅한다.
+
+vmstat: CPU, MEMORY 리소스를 종합적으로 확인(이게 직빵)
+
+
+
+strace: 실행가능한 바이너리를 추적하고 시스템콜도 보여줌
+
+dtrace: 시스템 정보 및 이벤트를 표시
+
+systemtop: 커널의 특정 정보들을 수집해 문제해결에 사용. 시스템콜에 handler를 다는 느낌
+
+du -sh : 디렉토리 사용량 분석
+
+uname: 시스템 정보 출력
+
+
+
+lsof	[List Open Files] 시스템에 열린 파일 목록을 알려줌. 파일을 지정하면 파일을 사용중인 프로세스를 알 수 있음.
+
+	특정 포트를 사용도 체크가능 lsof - i TCP:22
+
+	lsof -c httpd		해당 서비스가 사용중인 파일 정보출력
+
+	파일 기준으로 정보 탐색할때 유용
+
+
+
+
+
+find . -name “*log”
+
+
+
+$PATH 같은 시스템 변수는 어딜가든 동일하게 적용 (로그인쉘, 서브쉘)
+
+다만 이건 부모 프로세스가 같을때만 적용된다…;;
+
+
+
+<<VIM>>
+
+undo U
+
+undo undo  ^+R 
+
+
+
+
+
+rm -rf `cat [지울 파일이 개행된 파일]`로 한번에 지울 수 있다.
+
+basename 경로를 지우고 순수한 파일명을 리턴
+
+
+
+
+
+find . -name “some” -pirint0
+
+* 기본 플래그는 -print 0을 하면 각 결과가 \0으로 끝난다. 
+
+
+
+xargs 는 입력되는 문쟈열을 trim 하고 각각에 대해 명령을 내릴수 있다. 
+
+
+
+
+
+## Docker
+
+* 태그가 떨어진 (최근꺼만 lastest를 달고 있다) 이미지 삭제
+
+docker rmi -f $(docker images -f "dangling=true" -q)
+
+
+
+* 도커 localhost
+
+도커 안에서 localhost 주소를 쓰게 되면 app 돌아가는 프로세스 내의 localhost를 지칭하게 된다.
+
+개발 컴퓨터의 Localhost를 따로 지정해주려면 'host.docker.internal'를 쓴다.
+
+
+
+sed 명령어
+
+s*old/new*g
+
+s*old/new*gi
+
+
+
+chmod +x
+
+chomd 700
+
+
+
+readlink - 전체 주소반환
+
+baseline
+
+
+
+'cd -' 뒤로가기
+
+'cd .' 새로고침
+
+
+
+file - 해당 파일의 포맷을 출력 (csv, tar 등등)
+
+
+
+우왓!!
+
+cat > filename	// 이렇게 하면 입력파이프를 걸어놓을 수 있고 이때 붙여넣기든 뭐든 하면 vi 안하고도 파일 생성이 가능
+
+
+
+
+
+grep -efv
+
+grep -EV 
+
+grep Hello a |grep -Ev 'apple|orange|banana'
+
+
+
+
+
+#Devops
\ No newline at end of file
diff --git "a/Bear/\360\237\245\246 Diet.md" "b/Bear/\360\237\245\246 Diet.md"
new file mode 100644
index 0000000..12580cd
--- /dev/null
+++ "b/Bear/\360\237\245\246 Diet.md"	
@@ -0,0 +1,44 @@
+# 🥦 Diet
+
+#living/Diet
+
+
+---
+
+# 다이어트 관련 지식
+
+### 린매스 정리공간
+
+* 린매스업 식사량 - (자극 정도에 따라 유지칼로리 1.0 ~ 1 .1배 섭취)
+
+
+
+### 리피드 
+
+* 일주일에 한번 24시간~48시간 시간 동안  유지칼로리를 섭취해주는 전략. 이때 더 먹는 칼로리는 탄수화물로만 채운다. 
+
+
+
+### 다이어트 브레이크 
+
+* 3주 다이어트를 진행했다면 1주는 유지 칼로리를 먹되 추가되는 칼로리는 오직 탄수화물로만 섭취 (지방 20%, 단백 2.2g는 보장할것)
+
+
+
+### 운동회복이론
+
+* 최대회복볼륨(MRV): 최대량은 정해져있고 부위마다 MRV가 있다. 때문에 MRV가 큰 곳은 휴식이 더 길어야한다.
+
+* 디로딩: 4~6주에 한 번 완전히 쉬거나 낮은 수준의 운동(실패지점까지 하지 않는)으로 휴식을 가지면서 중추신경계의 피로를 제거하는 과정
+
+* 운동일지를 통해 컨디션을 체크하면 디로딩의 필요성을 알 수 있게 된다. 퍼포먼스의 급격한 약화가 오면 디로딩을 하면 된다.
+
+
+
+### 아나볼릭이론
+
+* 커팅 - 바디 리컴포지션 - 린매스업 - 벌크업 이런 순으로 많은 칼로리 섭취에 따른 아나볼릭 전략이 존재한다.
+
+* 특별히 바디 리컴포지션이라고하여 별도의 행동을 하는것 아니다. 어떤 상태에 있는 사람들 특히 초심자들은 활동칼로리 정도를 먹거나 덜 먹더라도 근육양이 증가하는 것을 발견하기 때문에 바디 리컴포지션이라는 이름을 붙여준것이다. 이런 효과를 기대할 수 없는 사람들 (특히 식단을 잘 관리해온 고급자)들은 활동칼로리 만큼만 먹는 전략보다 조금식 지방을 늘려나가는 전략이 유효하다.
+
+* 운동을 하면 그날 운동이 잘되든 안되든 집중력을 잃는다. 때문에 집중력을 잘 활용하기 위해 한번에 볼륨을 넣을 수 있는 복합다관절 운동이 내츄럴한테 유용하다.
\ No newline at end of file
diff --git "a/Bear/\360\237\245\260Beauty.md" "b/Bear/\360\237\245\260Beauty.md"
new file mode 100644
index 0000000..9ef87c1
--- /dev/null
+++ "b/Bear/\360\237\245\260Beauty.md"
@@ -0,0 +1,78 @@
+# 🥰Beauty
+
+#living/beauty
+
+
+---
+
+# 뷰티 관련 유튜브 지식 아카이브
+
+## "피부과 망하게 하는 팁"
+
+* 자외선 무조건 차단. 약먹고 그냥 손만 노출시켜도 D생산은 충분해.
+
+* 보습이 부족하면 주름이 생긴다. 화장품 바르고 일주일에 두번 마스크팩.
+
+* 비타민C 마구 마구 발라
+
+* 비타민A 마구 마구 발라. 
+
+	* 주로 쓰는 약은 스티바A, 익숙해 지게 되면 C랑 같이 바르기. 
+
+	* 처음에는 극소량으로 일주일에 한번으로 시작했다가 점진적으로 늘려 일 2회까지 증량 한다. 
+
+	* 농도는 궁극적으로 0.1% 쓰면 된다. 처음엔 0.01 제품은 뭐든 비슷하다. 
+
+	****피지가 부족한 쪽은 양을 줄여야 한다.*(목, 눈가)
+
+	* 레티노산 연고(스티바A, 레틴 A)는 개봉한뒤에 공기와 빛에 노출되지 않도록 빨리 바른다~
+
+
+
+## "스크럽 사용"
+
+* 물이 충분한 상태에서 부위당 스크럽 10번씩 문지른다. 일주일 두번 하고 나서 진정제를 사용한다.
+
+
+
+## "자외선의 개요, 피부가 검어지는 원리"
+
+* 자외선A, 자외선B(비타민합성 관여) 두가지가 존재한다. 차단제를 바른다고는 하지만 엄청 많이 바르지 않는 이상 선크림이 합성에 영향을 미치지는 않는다. 
+
+* 유리를 지나면 각 자외선은 1/4로 줄어든다. ***유리만 믿고 있다간 매일 2시간 반 썬텐한 효과를 받게 된다.***
+
+* 멜라토닌 물질은 피부 깊숙이 있고 점차 퍼지고 각질까지 올라온다. 
+
+* 멜라토닌은 자외선을 받거나 산화를 통해서 (술먹으면) 검게 변하고 외부로 확장한다. ***산화된걸 돌아오라고 하는게 비타민C의 효능, 이렇게 검어지는 걸 예방하는데는 자외선 자단체가 갑. 한번 검어진 표피가 갈리는데 걸리는 시간은 한달.***
+
+
+
+
+
+## "물세안 할까 말까?"
+
+* 1) 물세안 안해야 되는 사람 - 각질이 있는 사람, 클렌징하면 피부가 땡기는 사람, 개기름 없는 사람, 화장품 단계가 짧은 사람(뭐 바르는게 없는 사람)
+
+* 2) 일반 세안을 해야하는 사람 - 모공이 넓은 사람, 개기름 산유국, 저녁에 스킨~~로션-크림~~에센스 각종 화장품 중 오일리한 것을 바르는 사람
+
+* MyTest 결과. 저녁에 쓰는 폼클렌징의 1/3양으로 T존 쓱싹쓱싹하고 나머지는 가볍게 해도 충분하다. 뽀득거리면 피부막이 무너지는 징후
+
+
+
+## 마스크팩
+
+* 15분에서 20분 만 팩하면 된다. 눈썹 주변에 기포 안생기게 잘 눌러주고 숟가락으로 쓱싹 
+
+* 나머지는 몸에 바르고 누워 있는다. 
+
+* 세안하러가기 전에 냉장고에 넣으면 된다 항시보관 X
+
+* 그걸로도 부족하면 보습제 더 발라도 된다 번들거리면 손으로 톡톡
+
+
+
+## MTS
+
+* EGF 재생앰플 바르고 히알루론산 앰플도 좋다.
+
+* 일주일에 한번씩 해도 되지만 휴지기를 가질것
\ No newline at end of file
diff --git "a/Bear/\360\237\247\230\342\200\215\342\231\202\357\270\217 \354\213\254\353\246\254.md" "b/Bear/\360\237\247\230\342\200\215\342\231\202\357\270\217 \354\213\254\353\246\254.md"
new file mode 100644
index 0000000..3b4ea9a
--- /dev/null
+++ "b/Bear/\360\237\247\230\342\200\215\342\231\202\357\270\217 \354\213\254\353\246\254.md"	
@@ -0,0 +1,187 @@
+# 🧘‍♂️ 심리
+
+* 좋아함과 까탈스러움이 둘다 나와야 적성이다
+
+* 만약 당신에게 욕망이 있다면 욕망은 협상의 대상이 아니다. 그것이 당신을 이끌것이다. 성공으로
+
+* 의미없는 짓을 반복하는 인간 = 시지프스
+
+	* 먹고 살기 위해서 라고만 생각하면 시지프스 상태가 될 수 밖에 없다. 
+
+	* 의미를 찾고 방법을 강구해야한다. 이 게임의 룰은 자기가 정하는거다. 
+
+	* 아무도 어떻게 돌을 올리라고 강요한적 없다.
+
+* 상담이란것은 문제를 없애는게 아니라 문제를 바라보는 시선을 바꾸는것이다.
+
+* 뭘 자기를 바꿀 필요는 없다. 내가 뭘 원하는지만 알면된다. 그리고 행동이 바뀌면 된다.
+
+* 자존감
+
+	* 스스로를 인정하는 자신의 성취를 스스로 인정하지 않는게 문제다. 
+
+	* 자신의 잘한것도 못한것도 인정안하고 냉정하게 자학을 하면 내가 더 나아 멋지게 질거라고 착각하게 된다. 
+
+	* 이런 작용은 자신의 마음이 어디있는지 알 수 없게 된다. 
+
+	* 그런 맥락에서 자학을 동반하는 완벽주의는 허구이고 일을 망친다. 솔직하게 자기를 인정하는게 더 나은 미래를 만든다.
+
+
+
+## 
+
+* 회의같은 장소에서 긴장되는 마음을 그대로 표현하고 일을 할 때는 내 느낌을 살리고 사람들이 좋아하는 모습을 골라서 보여줘라.
+
+* 주변 환경을 관리하고 통제하고자 하는 의지, 규범과 틀을 중요시하고 새로운 상황에 대한 유연함이 부족한 태도는 도움이안된다.
+
+* 자신에게 보상을 약속했으면 꼭 지켜라. 사정이 변했다고 자신을 배반하지마라. 자기자신이 인생의 가장 큰 파트너다.
+
+
+
+## 잘 실행하기
+
+* 계획을 완전히 쪼개라. 목표=계획, 언제든지 몇 %라고 말할 수 있게
+
+* 완전히 다른걸 받아들이는것은 어렵만 조금 다른걸 받아들이는건 쉽다.
+
+* 계획에서 시간을 다루면 질이 떨어진다. 명사는 인지적인 절약을 위한 꼼수
+
+
+
+## 게임 피드백과 인간의 성장
+
+1. 내가 어디에 있고 얼만큼 했고 얼마나 해야하는지 모른다. 피드백이 없는 상태. 나쁜 게임.
+
+2. 끝없이 스코어를 주는게 게임. 즉 새로운 목표를 주는 게임이 좋은 게임.
+
+3. 10kg 뻇는데도 비만인 BMI 시스템. 다이어트에 어울리는 체중계가 필요하다.
+
+4. 더 이상 우리는 택시를 기다리지 않는다. 
+
+5. 의지력으로 밀어 붙이지 말고 주변과 통신을 해라. 금연의 방법을 이야기하면 피드백이 오가게 된다.
+
+6. 너 오늘 어디서 공부할거야? (너 오늘 언제 공부할거야? X) 전략에 대해 이야기하자.
+
+7. 게임의 피드백 시스템을 잘 이해한 사람은 일상생활에서 더 나은 길을 선택할 수 있다. 시스템을 이해못하고 마냥 두려워 할 수 밖에 없는 사람과 룰을 알고 대처방법을 찾는 사람의 차이다.
+
+
+
+
+
+
+
+불안에 대한 영상 정보 정리
+
+1) 안에 물이 차오른 상태에서 누가 누르면 짜증.
+
+2) 물이 넘치면 불안 (이때는 수행능력이 떨어짐)
+
+3) 누군가 슈퍼맨을 요구하고 그걸 해야겠다고 생각하면 불안하고 예민해짐
+
+4) 불안의 이유는 예민해야할필요가 있다고 인식하기 때문이다. 때문에 불안을 줄이는 비법은 정상의 범위를 넓히는것 (체지방량 10% 가 아니면 난 안되! => 체지방량 15%까지도 괜찮아) 
+
+5) 욕구와 욕망을 분리해야한다.. 욕구가 해결되고 있으면 안전한거다. 밥먹고 집있고 필요하면 택시타고. 이걸 조정하지 못하는 사람들이 감옥에 간다. 계속 돈을 벌려는 욕망에 휘둘려 하루 1억씩 써도 될것같은 재벌들이 돈때문에 감옥간다. 욕망을 채우지 못해도 내 삶은 잘못되지 않는 다는 확신만 있으면 이 불안은 해결될 수 있다.
+
+6) 과거를 보는게 우울의 근거다.
+
+7) 미래에서 유발되는게 짜증 (불안)
+
+8) 비교는 자신의 좌표를 확인하기 위해서 쓰면 좋지만 욕망을 선정하는데 사용하면 문제
+
+9) 세상에는 슈퍼맨같은 에너지를 가지고 사는 사람도 있지만 보통의 짜증을 안고 사는 사람들이 대다수다. 그 사람을 따라가려고 하지 마라.
+
+
+
+## 불안에 대한 동영상 정리 (2)
+
+1) 불안의 신호를 아는게 중요하다. 신호가 오면 여러가지 방법으로 대처를 할 수 있다. 
+
+완벽하게 준비하기
+
+미리 많이 걱정하기(최악의 상황을 계속 걱정하기)
+
+최선을 다해 노력하기, 열심히 하면 됩니다. 일단 해라, 그리고 짜증은 나를 쉬게 하려는 내 몸의 신호. 이 이후에는 불안의 단계에 들어가므로 쉬어라. 짜증이라는걸 잘 알면 후회나 괴로움을 줄일 수 있다. 짜증은 나한테 그만해라고 보내는 신호다. 
+
+2) 정상의 범위를 넓혀가라. 조금씩
+
+3) 사람은 진짜로 접싯물에 빠져 죽기도 한다. 접싯물에 빠져죽는이유. 주변 사람들과의 비교에서 오는 열등의식. 
+
+4) 삶의 네 가지 선택의 원칙은 다음과 같다. (최선, 차선, 차악, 최악)
+
+5) 최선의 선택을 아이 하지 말자 (착해요 키커요 시부모님이 미국에 살아요..)
+
+6) 최선의 선택에는 비용이 크다. 최악은 제쳐놓고 생각하자.
+
+7) 완벽한 관계는 없다. 완벽한 거리도 없다. 사람들마다 컵의 사이즈가 다르고 변하지도 않는다.
+
+8) 불안은 사라지지 않고, 없으면 위험하다. 불안은 다스릴 수 있고, 삶의 태도를 통해 조절해야한다.
+
+9) 애매한 상황을 통제하려하지 말고 견뎌라. 작지만 반복되는 행복을 찾고. 삶에대해 불완전성에 대한 인정을 해라. 다른사람과 연대하면 이겨내는 힘이 된다.
+
+10) 자신의 몸의 반응을 잘못 이해하면 안된다. 심장박동~ 혈압.. 느낌
+
+
+
+## 편집본 들으면서 정리된 내용
+
+1. 내가 다른 사람과 다른 것은 무엇인가 치열하게 고민. 이걸 매일 매일 느끼지 못하면 지쳐서 포기한다.
+
+2. 내가 공부하는건 지식인가 지혜인가. 지혜는 소통과 현실에서 나오는 실천적인 것이다.
+
+3. 독창적인 것을 하는 것이 바로 이해받을 수는 없다. 아무리 빨라도 3년 길면 10년까지 수련의 시간이 필요하다.
+
+4. 무엇을 위해사는가 = 무엇을 좋아하는가 = 무엇이 나를 살게 만드는가
+
+5. 관점의 이동. 이걸 하려면 세계가 무엇이고 나는 어떻게 세계를 보는지 명확히 규정하고 있어야 가능하다. 흐릿하게 정의하면 넥스트 스탭을 알 수 없다.
+
+6. 자신의 운명을 찾기위해 노력했는가
+
+7. 메뉴얼. 사회에서 말하는 정답. 당위적인 것들에 자신이 따라야한다는 믿음. 이것들에 매달리면 안정될거라 믿고 싶을지도 모르지만 오히려 매달릴수록 더 취약해지고 위기에 빠진다.
+
+8. 너 자신의 문제는 무엇인가. 답을 찾기 전에 질문부터 제대로 해야한다.
+
+9. 과거의 삶에서 일관되게 드러나는 나의 취향, 경향성은 무엇인가?
+
+10. 중대한 선택의 시점에서 무엇을 근거로 판단했는가 그 결과는 어땠는가 철저히 반성
+
+11. 삶은 진화한다. 그 진화 과정에서 어떤 맥을 찾는건 각자에게 달려있다.
+
+12. 맹목적이어선 안된다. 매일 자신의 목적을 상기해야한다.
+
+13. 관계의 문제를 내 문제라고 생각하면 안된다. 자신의 문제를 알지 못할때 쉽게 자기가 제일 못하는걸 문제라고 진단해버린다. 잘못된 처방전을 반복해서 먹지마라.
+
+14. 자신이 한 일에 대해 가장 먼저 스스로가 인정할 수 있어야 한다. 과도한 목표나 기대감은 가져선 안된다. 오히려 방해다.
+
+15. 자원보존이론. 자원을 보충 및 획득하는 양이 자원을 소모하는 속도를 따라가지 못하면 소진은 불가피하다.
+
+16. 소진(burnout) 상태에 이를 수록 직무효능감, 성취감을 못느끼게 되고 냉소적인 태도를 견지하게 된다. 황박사가 차별성을 강조하는 이유는 이 사회에서 잘하지 못하는걸로 방어전을 벌이기 보다는 자신에게 힘을 주는 장점을 바탕으로 공격전을 벌이라는 뜻으로 해석된다. 
+
+
+
+* 근본적으로 회피하는 것은 낮은 자존감이 원인이다. 누적되어온 불안과 괴로움에 의해 습관화된 대응이 회피다.
+
+* 미룬다는 것은 사실 자신에게 거짓말을 하는 거죠.
+
+* 자존심을 잘 활용해라. 스스로 갈고 닦을 이유가 생긴거 아닌가?
+
+* 진심으로 대하게 되면 그 사람을 내 사람으로 두게되면 그 사람을 책임져야 하지 않을까 두려워할 수도 있다. 하지만 진짜로 나쁜일은 생기지도 않았고 나 혼자만 하는것도 아니잖아.
+
+* 진심으로 하게되면 무조건 잘 해야하야한다고 믿으면 두려움이 커져 일을 제대로 하기 힘들다. 못할 수도 있다. 그걸 인정하면 더 잘 할 수 있다.
+
+* 에너지를 아껴서 뭐하냐. 하룻밤 자고 나면 내일이면 어제 무슨일이 있었는지 모든걸 기억하진 않을텐데.
+
+
+
+[삶의 기본적 태도]
+
+* 탐험. 인간의 뇌는 타고난 탐험가들이다. 
+
+* 관찰 가설 실험 결론. 이런 과정을 통해 세계를 배워나간다. 이 모델을 우리 인생 전체에 적용해나가야 한다. 
+
+* 배우고 스스로의 정체성을 확장하라는 이 요구는 성공한 사람들의 수사가 아니라, 재미있는 삶을 살고 싶은 모두를 위한 덕목이다. 
+
+* 선천적 후천적인것을 우리는 구분할 수 없다. 계속해서 부딪치고 나아가라.
+
+
+
+#mind
\ No newline at end of file
diff --git "a/Bear/\360\237\247\251Dict - Concept.md" "b/Bear/\360\237\247\251Dict - Concept.md"
new file mode 100644
index 0000000..37acd7a
--- /dev/null
+++ "b/Bear/\360\237\247\251Dict - Concept.md"	
@@ -0,0 +1,28 @@
+# 🧩Dict & Concept
+
+#Business&Finance
+
+
+---
+
+# 참고할만한 정보들
+
+## VIX 지수
+
+## 현금흐름할인법(Discounted Cash Flow,DCF)
+
+## RP
+
+## 수시 RP
+
+## 약정식 RP
+
+## 베어마켓렐리
+
+약세장(베어마켓)이 진행되는 도중에 일시적으로 주가가 반등하는 현상을 말한다. 정부가 경기부양을 위해 유동성(자금)을 대거 풀어서 시중에 유동성이 넘치거나, 주가가 지나치게 하락했다고 투자자들이 판단할 때 발생
+
+
+
+주가심리학
+
+* 미리 악재가 반영된다면 최악의 사태가 오면 반등이 시작된다. 이제부터 오르막길이 끝이라고 생각하니까.
\ No newline at end of file
diff --git "a/Bear/\360\237\247\253Wish \354\230\201\355\231\224, \354\261\205, \353\223\234\353\235\274\353\247\210, \354\225\240\353\213\210.md" "b/Bear/\360\237\247\253Wish \354\230\201\355\231\224, \354\261\205, \353\223\234\353\235\274\353\247\210, \354\225\240\353\213\210.md"
new file mode 100644
index 0000000..cc7271c
--- /dev/null
+++ "b/Bear/\360\237\247\253Wish \354\230\201\355\231\224, \354\261\205, \353\223\234\353\235\274\353\247\210, \354\225\240\353\213\210.md"	
@@ -0,0 +1,183 @@
+# 🧫Wish 영화, 책, 드라마, 애니
+
+#Culture&Sense #Dream&Bucket #book
+
+
+---
+
+## Comics and Anime - Ent
+
+-	[ ] 테크노라이즈 (메카)
+
+-	[ ] 그대가 바라는 영원
+
+-	[ ] 블랙불릿
+
+-	[ ] 보쿠라노 (메카, 아포)
+
+-	[ ] 전 여친과 현여친과 나 (모바일 추리 게임)
+
+-	[ ] 테카맨 블레이드 (메카, 고전)
+
+-	[ ] 반딧불이의 숲으로 (단편, 극장 45분)
+
+-	[ ] 도쿄 매그니튜드 8.0
+
+-	[ ] 도쿄 리벤져스
+
+-	[ ] 신부이야기
+
+-	[ ] 바이올렛 에버가든 극장판
+
++	[x] Honzuki S3 (8, 9, 10 , 11, 12)
+
++	[x] 콜레트는 죽기로 했다. (17~20)
+
++	[x] 하나노이군과 상사병
+
+-	[ ] 8월의 끝은 분명 세계의 끝과 닮아 있다. (118/200)
+
+
+---
+
+## BOOK - MyPick
+
+****문학*
+
+-	[ ] 월든
+
+-	[ ] 시지프스신화
+
+-	[ ] 카라마조프가의 형제
+
+	* 솔제니친
+
+		- 이반 데니소비치 수용소의 하루
+
+		- 수용소군도
+
+****추리*
+
+-	[ ] 살육에 이르는병
+
+****투자*
+
+-	[ ] 현명한투자자(로버트 그린)
+
+-	[ ] 화폐전쟁
+
+****거시경제, 인류사학, 문명*
+
+	- 돈의 탄생
+
+	- 움직이는 세계질서
+
+	- 거대한 전환
+
+	- 레이달리오의 금융템플릿
+
++	[x] 위대한 탈출
+
+****사회학*
+
+-	[ ] 남자, 다시 찾은 진실
+
+-	[ ] 직업의 지리학
+
+-	[ ] 대한민국 대전환
+
+****채용 및 커리어*
+
+-	[ ] 글로벌 기업은 성적표를 보지 않는다
+
+****신학*
+
+	* 칼바르트
+
+		- 칼 바르트의 신학: 20세기 최고의 신학이 교부
+
+		- [칼 바르트](https:*/www.aladin.co.kr/shop*wproduct.aspx?ItemId=36241113)
+
+****철학 & 의미론*
+
+-	[ ] 빅터프랭클린의 [삶의 의미를 찾아서 (양장)](https:*/www.aladin.co.kr/shop*wproduct.aspx?ItemId=590290)
+
+-	[ ]  [의미의 지도](https:*/www.aladin.co.kr/shop*wproduct.aspx?ItemId=282714243)  8월 구매
+
+****심리*
+
+-	[ ] 생각에 대한 생각
+
+
+---
+
+## BOOK - Tech career
+
+-	[ ] 실용주의 프로그래머 7월 구매
+
+-	[ ] 테스트 주도개발 8월 구매
+
+-	[ ] 프로그래밍 패턴 9월
+
+-	[ ] 클라우드 네이티브 애플리케이션 디자인 패턴 10월 
+
+-	[ ] 맨먼스 미신 11월
+
+-	[ ] 리펙토링 12월 
+
+-	[ ] 헤드퍼스트 디자인 패턴 1월
+
++	[x] 소프트웨어 장인
+
+
+---
+
+BOOK - RED PILL Sensei
+
+-	[ ] 세이노의 가르침
+
+-	[ ] 로버트그린 책
+
+-	[ ] 결정 (흔들리지않고 마음먹는대로)
+
+-	[ ] 마스터리의 법칙
+
+-	[ ] 안티프레질
+
+-	[ ] Appearance of power
+
+-	[ ] 책: 세상을 움직이는 100가지 효과
+
+
+---
+
+BOOK - G Sensei
+
+-	[ ] 결국 당신은 이길것이다
+
++	[x] 퀀트투자
+
++	[x] 거인의 포트폴리오
+
+
+---
+
+추천 받은 영화 영화 + 내가 픽한거
+
+-	[ ] 파니핑크
+
+-	[ ] 버질런트
+
+-	[ ] 핵사고지
+
+-	[ ] 리멤버 타이탄
+
+-	[ ] 우리는 동물원을 샀다
+
+
+---
+
+드라마
+
+-	[ ] 모래시계
+
diff --git "a/Bear/\360\237\247\271\354\262\255\354\206\214 \353\260\217 \354\202\264\353\246\274.md" "b/Bear/\360\237\247\271\354\262\255\354\206\214 \353\260\217 \354\202\264\353\246\274.md"
new file mode 100644
index 0000000..242c8a5
--- /dev/null
+++ "b/Bear/\360\237\247\271\354\262\255\354\206\214 \353\260\217 \354\202\264\353\246\274.md"	
@@ -0,0 +1,93 @@
+# 🧹청소 및 살림
+
+# 청소 (리마인더 참고)
+
+## 냄비뚜껑 청소하는 방법1
+
+냄비뚜껑: 과탄소소다 2큰술 손잡이 풀고 뜨거운물 잠길정도로. 스텐 플라스틱만 넣어야한다. 쇠-알루미늄은 상한다. 행굴때는 식초를 넣어서 행군다. (중화) 중성세제로 마무리
+
+## 거울 닦는법
+
+거울 닦는법: 식초를 스프레이로 뿌린다. 그리고 화장지로 접착 시킨 후 더 뿌린다. (충분히) > 거울닦이 스펀지로 중간중간 식초 뿌리면서 닦기
+
+## 전자렌지 청소방법
+
+렌지닦는법: 가스렌지 받침대는  과탄산에 담그고(30분)  알루미늄 부품은 별도로 청소.렌지에도 과탄산뿌리고 칫솔로 골고루 적셔준다. (5분) 칫솔로 쓲쓱해주면 다 밀려나감, 손잡이도 분리된다. 가스렌지를 들면 여기도 닦을 곳이 있다. 담궈둔것도 행주로 닦아주고, 중성세재로 닦아서 끝. 과탄산에 넣지 않은 알루미늄 헤드는 첫수세미로 청소한다.
+
+## 테이프 자국 지우기
+
+테이프 자국 지우기: 솜에 알코올을 묻혀 문지르면 자국이 말끔히 제거, 모기약으로도 제거. 식용유, 베이비 오일, 유분기 있으면 된다.
+
+
+---
+
+# 세탁기 청소
+
+ * 관리에서 제일 중요한건 평소에 적정세제, 적정유연제를 사용하기
+
+# 냉장고 관리
+
+* 냉장고 청소
+
+	* 일단 행주로 다 쓸어주고 베파 묵힌 행주로 쓸어주고 냉장고 옆은 매직블럭
+
+* 냉장고 소음 줄이기
+
+	* 온도를 올리고 물건을 80%정도 채우면 콤프의 잦은 동작을 줄일 수 있다.
+
+	* 고무패킹(가스켓)의 정상적인 동작을 확인
+
+	* 냉장고 소음 날때 밀어서 수평을 확인
+
+	* 냉장고 아래를 눌러주면 공명이 줄어든다.11
+
+	* 좌우 5~~10cm, 상단 30cm, 뒷면 5~~10cm 여유공간을 확보한다.
+
+	* 냉장고 후면 흡입구의 먼지를 잘 제거해야 열교환 효율이 좋아지고 콤프의 동작 횟수를 줄일 수 있다.
+
+
+---
+
+* 과탄산소다는 강알칼리, 세탁세제는 보통 약알칼리 옷의 소재에 주의한다.
+
+
+
+# 빨래 지식
+
+
+---
+
+* 습한 상태에서 빨리 못말리면서 세탁기 안의 세균이 증식하는게 냄새의 원인. 세균을 없애거나 빨리 말리거나 과탄산을 넣거나 햇빛에 말리거나 할 수 있는걸 하면된다.
+
+
+
+# 유틸리티 비용 절감
+
+### 전기
+
+* 실외기의 열전달에 문제가 생기면 전기 과사용의 원인이 된다. (에어로드같은 아이템도 있다)
+
+* 밥솥: 1458와트 한달 7655원
+
+* 처음 5분은 강하게 튼다. 송풍모드 1시간 쓰기. 
+
+* 에어컨을 중간에 껐다 켜는 것 보다 3시간 정도는 오히려 그냥 계속 켜두는 게 전력소비를 줄일 수 있다는 사실이 확인됐습니다. 24도에서 26도로 올리면 한달 1만7320원의 요금 차이, 26도에서 28도로 하면 더 아낄 수 있다. (열전도차이가 있으니)
+
+* 정속형은 희망온도에 도달하면 외부가 멈춘다. 온도가 높아질때 마다 계속 최고 출력을 반복하게 되고 그래서 효율이 안좋다. 차라리 온도를 더 낮추고 주기적으로 끄는게 이득. 그리고 소음문제만 아니라면 그냥 강풍을 항상 쓰시라. 빨리 온도 낮추고 빨리 끄고 이득. 어차피 실외기는 똑같이 돈다.
+
+
+
+### 수도
+
+* 헤드의 압력 낮추기, 변기 벽돌넣기(물 내리는 압력이 떨어짐)
+
+
+---
+
+# 재료보관
+
+* 지퍼백, 플라스틱 토에 소분하면 벌레가 안생긴다.. 으악.. 이걸 알았어야 헀는데
+
+
+
+#living
\ No newline at end of file
diff --git "a/Bear/\360\237\251\264Javascript.md" "b/Bear/\360\237\251\264Javascript.md"
new file mode 100644
index 0000000..f054399
--- /dev/null
+++ "b/Bear/\360\237\251\264Javascript.md"
@@ -0,0 +1,74 @@
+# 🩴Javascript
+
+#Devops/language
+
+
+---
+
+## this bind
+
+* 화살표함수, bind -> call, apply -> 나머지 우선순위로 this가 바인딩 된다.
+
+* 즉 순위가 높은건 유저가 지정한다고 확신할 수 있는 케이스다.
+
+* 잡아먹는다는 것이고 낮은건 엔진이 스스로 지정하는 경우다.
+
+
+
+## SCOPE
+
+* 함수단위로 scope가 생겨나고 ARemoteRepositoryow를 하면 현재 함수만을 보게 된다. ≡ 딴데 가서 호출되어도 this를 새로 할당 받지 않는다. ≡  이미 바인드 되었다.
+
+```
+
+var obj {
+
+  c: function() {
+
+    console.log(this)
+
+}
+
+```
+
+**객체가 어떻게 되든 c가 함수스코프가 되고**this**는**obj* 가 된다. 그래서 메소드호출은 언제나 객체가 this가 된다. 대신 객체 안이라도 => 익명함수가 되면 스코프가 생겨나지 않고 생겨나지 않으면 기본은 window.
+
+* 즉 다르게 말하면 애로우를 작성하면 함수가 작성된 시점의 스코프로 고정된다. 안바뀐다. 애로우로 안하면 실행되는 시점에서 함수스코프다 >> 객체는 스코프를 만들지 않는다. 그걸 생각해라.
+
+
+
+## Instance 
+
+* Instance를 만들어 낼 수 있는 객체(new 키워드를 를 쓸 수 있는)만 construct 를 가진다. 예를 들어 math는 construct가 없다. 계산만을 위해 존재하는 것.
+
+* 부모의 컨스트럭터를 실행하는게 super 키워드 → 명시적 실행. ES6 부터는 없어도 실행된다. 바벨 옵션에 따라 없어도 알아서 수행된다. create~~react~~app에는 옵션이 적용되어 있다.
+
+
+
+## 인스턴스 메서드
+
+-	[ ] 다시 확인
+
+## 프로토타입 메서드
+
+-	[ ] 다시 확인
+
+
+
+## 프로토타입 표현
+
+`_***proto***_` 은 `[[prototype]]` 과 같다. 표기방식이 다른거다. 두가지가 읽는건 프로토타입체인,프로토링크
+
+`super` 키워드로 부모에 접근
+
+
+
+## 브라우저에서 사용가능한 HTML REQUEST
+
+* async 는 `AJAX` 의 핵심단어. DOM과는 독립적으로 HttpRequest 객체로 데이터를 처리한다. 페이지속도가 빨라지고 로드를 처리하는게 부드러워진다.
+
+* `XMLHttpRequest`가 자바스크립트가 HTML요청을 처리하기 위한 객체이고 jQuery로도 다룰 수도d있다.
+
+* `Fatch` 좀더 최신의 API
+
+* `URI` (Uniform Resource Identifier) ≈ URL
\ No newline at end of file
diff --git "a/Bear/\360\237\253\230JAVA.md" "b/Bear/\360\237\253\230JAVA.md"
new file mode 100644
index 0000000..d1bbca9
--- /dev/null
+++ "b/Bear/\360\237\253\230JAVA.md"
@@ -0,0 +1,50 @@
+# 🫘JAVA
+
+ [Java 제네릭(Generics)이란?](https:*/gangnam-americano.tistory.com*47) 
+
+# Generic 제너릭 `<>` 
+
+* <T>, <String>, <Obejct String> 같은 패턴 모두에 해당한다.
+
+`ArrayList<String> arrList = new ArrayList<String>();`
+
+	****이렇게 배열안에 사용할 타입을 선언하는 것을 칭함*
+
+	* 필요성 (1) 제너릭을 쓰면 입력시 형변환이 필요없고 (2) 코드의 안정성을 확보할 수 있다.
+
+
+
+* 클래스를 다음과 같은 구조라면
+
+`class Soccer extends Sports{}`
+
+Array, List 같은 자료형(컬렉션)에만 국한되는게 아니라 다양하세 사용가능. **예를 들어 클래스도 가능**
+
+다형성(*알고리즘을 건드리지 않고 그대로 유지하면서 뮤테이트*)을 지원하기 때문에
+
+부모의 제너릭에 자녀 제너릭을 저장할 수있다. (다만 다시 자녀의 타입으로 저장하려면 형변환이 필요하다) 
+
+ `Soccer mySoccer = (Soccer) arrList.get(1);`
+
+
+
+```java
+
+ArrayList<?> arrList // 아무 타입이나 사용가능
+
+ArrayList<? extends Skating> arrList		// Skating과 자녀 클래스만 사용가능
+
+ArrayList<? super Golf> arrList		// 골프와 그 부모만 사용가능
+
+
+
+class Player<T, S>{ public T team, public S name }
+
+→ 이렇게 복수의 제너릭을 선언할 수도 있다.
+
+```
+
+
+
+#Devops*language*java
+
